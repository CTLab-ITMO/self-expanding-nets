{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I1fFZaT5f8dR"
      },
      "outputs": [],
      "source": [
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.optim as optim\n",
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "from copy import deepcopy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "housing = fetch_california_housing()\n",
        "\n",
        "scaler = StandardScaler()\n",
        "X = scaler.fit_transform(housing.data)\n",
        "y = housing.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
        "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
        "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
        "\n",
        "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
        "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
      ],
      "metadata": {
        "id": "rvjazlWwiwzU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleFCN(nn.Module):\n",
        "    def __init__(self, input_size=8):\n",
        "        super(SimpleFCN, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_size, 16)\n",
        "        self.fc2 = nn.Linear(16, 8)\n",
        "        self.fc3 = nn.Linear(8, 1)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x\n",
        "\n",
        "input_size = X_train.shape[1]\n",
        "model = SimpleFCN(input_size)"
      ],
      "metadata": {
        "id": "Y5Ndc5TRixFr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
        "\n",
        "def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
        "    model.train()\n",
        "    for epoch in range(num_epochs):\n",
        "        running_loss = 0.0\n",
        "        for inputs, targets in train_loader:\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            running_loss += loss.item()\n",
        "\n",
        "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
        "\n",
        "def evaluate_model(model, test_loader, criterion):\n",
        "    model.eval()\n",
        "    total_loss = 0.0\n",
        "    with torch.no_grad():\n",
        "        for inputs, targets in test_loader:\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            total_loss += loss.item()\n",
        "\n",
        "    avg_loss = total_loss / len(test_loader)\n",
        "    print(f'Evaluation Loss: {avg_loss:.4f}')\n",
        "    return avg_loss\n",
        "\n",
        "num_epochs = 20\n",
        "train_model(model, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
        "evaluate_model(model, test_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jwjrdKmkizg5",
        "outputId": "2b29daee-1d9e-423c-d9cc-7cd1c0546a88"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 2.2121\n",
            "Epoch [2/20], Loss: 0.6129\n",
            "Epoch [3/20], Loss: 0.4882\n",
            "Epoch [4/20], Loss: 0.4379\n",
            "Epoch [5/20], Loss: 0.4162\n",
            "Epoch [6/20], Loss: 0.4020\n",
            "Epoch [7/20], Loss: 0.3917\n",
            "Epoch [8/20], Loss: 0.3831\n",
            "Epoch [9/20], Loss: 0.3732\n",
            "Epoch [10/20], Loss: 0.3655\n",
            "Epoch [11/20], Loss: 0.3556\n",
            "Epoch [12/20], Loss: 0.3501\n",
            "Epoch [13/20], Loss: 0.3425\n",
            "Epoch [14/20], Loss: 0.3375\n",
            "Epoch [15/20], Loss: 0.3326\n",
            "Epoch [16/20], Loss: 0.3296\n",
            "Epoch [17/20], Loss: 0.3268\n",
            "Epoch [18/20], Loss: 0.3220\n",
            "Epoch [19/20], Loss: 0.3197\n",
            "Epoch [20/20], Loss: 0.3171\n",
            "Evaluation Loss: 0.3235\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.3234672683935899"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "eps = torch.tensor([1e-10])"
      ],
      "metadata": {
        "id": "WDrvz-WKkcKX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.enable_grad()\n",
        "def evaluate_sensitivity(model, dataloader, loss_function):\n",
        "\n",
        "    sensitivity = {}\n",
        "\n",
        "    for data, target in dataloader:\n",
        "\n",
        "        model.zero_grad()\n",
        "\n",
        "        output = model(data)\n",
        "        loss = loss_function(output, target)\n",
        "        loss.backward()\n",
        "\n",
        "        for param_name, p in model.named_parameters():\n",
        "            if \"weight\" in param_name:\n",
        "\n",
        "                if param_name in sensitivity.keys():\n",
        "                    sensitivity[param_name] = sensitivity[param_name] + torch.abs(p).detach().cpu()\n",
        "                else:\n",
        "                    sensitivity[param_name] = torch.abs(p).detach().cpu()\n",
        "\n",
        "    for k in sensitivity.keys():\n",
        "        sensitivity[k] /= len(dataloader)\n",
        "        sensitivity[k] /= torch.max(torch.max(sensitivity[k], eps))\n",
        "\n",
        "    return sensitivity\n"
      ],
      "metadata": {
        "id": "KUqaes5Ji2bp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def do_pruning(model, pruning_type=\"Random\", **kwargs):\n",
        "    prune_model = deepcopy(model)\n",
        "\n",
        "    amount = kwargs.pop('amount', 0.3)\n",
        "    logs = kwargs.pop('logs', False)\n",
        "    sensitivity = kwargs.pop('sensitivity', {})\n",
        "    counter = list(sensitivity.keys())\n",
        "\n",
        "    def apply_l1_pruning(module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
        "            if logs:\n",
        "                print(f\"Применен L1 прунинг к слою: {module}\")\n",
        "                print(f\"Маска:\\n{module.weight_mask}\\n\")\n",
        "\n",
        "    def apply_random_pruning(module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            prune.random_unstructured(module, name='weight', amount=amount)\n",
        "            if logs:\n",
        "                print(f\"Применен Random прунинг к слою: {module}\")\n",
        "                print(f\"Маска:\\n{module.weight_mask}\\n\")\n",
        "\n",
        "    def remove_pruning(module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            if hasattr(module, 'weight_mask'):\n",
        "                prune.remove(module, 'weight')\n",
        "                if logs:\n",
        "                    print(f\"Удалена маска прунинга в слое: {module}\")\n",
        "\n",
        "    def zero_weights_by_mask(module):\n",
        "        if isinstance(module, nn.Linear):\n",
        "            if hasattr(module, 'weight_mask'):\n",
        "                with torch.no_grad():\n",
        "                    module.weight.data *= module.weight_mask\n",
        "                    if logs:\n",
        "                        print(f\"Обнулены веса по маске в слое: {module}\")\n",
        "                        print(f\"Текущие веса:\\n{module.weight.data}\\n\")\n",
        "\n",
        "\n",
        "    def apply_sensitivity_pruning(module):\n",
        "        nonlocal counter\n",
        "\n",
        "        if isinstance(module, nn.Linear):\n",
        "            param_name = counter.pop(0)\n",
        "            if param_name in sensitivity:\n",
        "\n",
        "                sens_tensor = sensitivity[param_name]\n",
        "\n",
        "                flat_weights = module.weight.view(-1)\n",
        "                flat_sensitivity = sens_tensor.view(-1)\n",
        "\n",
        "                num_params_to_prune = int(amount * flat_sensitivity.numel())\n",
        "                _, indices = torch.topk(flat_sensitivity, k=num_params_to_prune, largest=False)\n",
        "\n",
        "                mask = torch.ones_like(flat_weights)\n",
        "                mask[indices] = 0\n",
        "\n",
        "                prune.custom_from_mask(module, name='weight', mask=mask.view_as(module.weight))\n",
        "\n",
        "                if logs:\n",
        "                    print(f\"Применен Sensitivity-based прунинг к слою: {module}\")\n",
        "                    print(f\"Маска:\\n{mask.view_as(module.weight)}\\n\")\n",
        "\n",
        "    apply_func = None\n",
        "    if pruning_type == \"L1\":\n",
        "        apply_func = apply_l1_pruning\n",
        "    elif pruning_type == \"Random\":\n",
        "        apply_func = apply_random_pruning\n",
        "    elif pruning_type == \"Remove\":\n",
        "        apply_func = remove_pruning\n",
        "    elif pruning_type == \"SensitivityBased\":\n",
        "        apply_func = apply_sensitivity_pruning\n",
        "\n",
        "    if apply_func:\n",
        "        prune_model.apply(lambda module: apply_func(module))\n",
        "        prune_model.apply(lambda module: zero_weights_by_mask(module))\n",
        "        prune_model.apply(lambda module: remove_pruning(module))\n",
        "\n",
        "    return prune_model\n"
      ],
      "metadata": {
        "id": "XVDzDFpkkgt_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pruned_model = do_pruning(model, pruning_type=\"L1\", amount=0.75, logs=False)"
      ],
      "metadata": {
        "id": "WFU3ShYGnRDX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate_model(pruned_model, test_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PjaoCtvxncn_",
        "outputId": "c5c8d4e6-6375-493e-e40c-32d7e04914c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation Loss: 4.3000\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4.299985500482412"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def dense_to_sparse(dense_tensor):\n",
        "    indices = dense_tensor.nonzero(as_tuple=True)\n",
        "    values = dense_tensor[indices]\n",
        "    indices = torch.stack(indices)\n",
        "\n",
        "    sparse_tensor = torch.sparse.FloatTensor(indices, values, dense_tensor.size())\n",
        "    return sparse_tensor"
      ],
      "metadata": {
        "id": "iMl8XMQqn3HU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseLinear(nn.Module):\n",
        "    def __init__(self, weight, bias):\n",
        "        super(SparseLinear, self).__init__()\n",
        "\n",
        "        self.weight_indices = weight.coalesce().indices()\n",
        "        self.weight_values = nn.Parameter(weight.coalesce().values())\n",
        "        self.weight_size = list(weight.coalesce().size())\n",
        "\n",
        "        self.bias_indices = bias.coalesce().indices()\n",
        "        self.bias_values = nn.Parameter(bias.coalesce().values())\n",
        "        self.bias_size = list(bias.coalesce().size())\n",
        "\n",
        "    def forward(self, input):\n",
        "        sparse_weight = torch.sparse.FloatTensor(self.weight_indices, self.weight_values, self.weight_size)\n",
        "        sparse_bias = torch.sparse.FloatTensor(self.bias_indices, self.bias_values, self.bias_size).to_dense()\n",
        "\n",
        "        output = torch.sparse.mm(sparse_weight, input.t()).t()\n",
        "        output += sparse_bias.unsqueeze(0)\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "7Rw6XsnopuCK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# import torch\n",
        "# import torch.nn as nn\n",
        "\n",
        "# class SparseLinear(nn.Module):\n",
        "#     def __init__(self, weight, bias):\n",
        "#         super(SparseLinear, self).__init__()\n",
        "\n",
        "#         self.weight = nn.Parameter(weight.to_dense())\n",
        "#         # self.bias = nn.Parameter(bias)\n",
        "\n",
        "#     def forward(self, input):\n",
        "\n",
        "#         output = torch.sparse.mm(self.weight, input.t()).t()\n",
        "#         # output += self.bias\n",
        "\n",
        "#         return output"
      ],
      "metadata": {
        "id": "XvKLVJ1q8d3S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def convert_dense_to_sparse_network(model):\n",
        "    new_model = model.__class__()\n",
        "\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Linear):\n",
        "            sparse_weight = dense_to_sparse(module.weight.data)\n",
        "            sparse_bias = dense_to_sparse(module.bias.data)\n",
        "\n",
        "            setattr(new_model, name, SparseLinear(sparse_weight, sparse_bias))\n",
        "        else:\n",
        "            setattr(new_model, name, convert_dense_to_sparse_network(module))\n",
        "    return new_model"
      ],
      "metadata": {
        "id": "VLdl2c52pvmy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_model = convert_dense_to_sparse_network(pruned_model)"
      ],
      "metadata": {
        "id": "cwBysM73pNx9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for param in sparse_model.named_parameters():\n",
        "    print(param[0], param[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I4NBXt3R6t4p",
        "outputId": "8ccc585d-7a2f-40c1-be86-2ceae5dc14af"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1.weight_values torch.Size([32])\n",
            "fc1.bias_values torch.Size([16])\n",
            "fc2.weight_values torch.Size([32])\n",
            "fc2.bias_values torch.Size([8])\n",
            "fc3.weight_values torch.Size([2])\n",
            "fc3.bias_values torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for param in model.named_parameters():\n",
        "    print(param[0], param[1].shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OuqItk0hmdtV",
        "outputId": "cf0f2f44-4894-4892-c519-dad7e870216d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1.weight torch.Size([16, 8])\n",
            "fc1.bias torch.Size([16])\n",
            "fc2.weight torch.Size([8, 16])\n",
            "fc2.bias torch.Size([8])\n",
            "fc3.weight torch.Size([1, 8])\n",
            "fc3.bias torch.Size([1])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.AdamW(sparse_model.parameters(), lr=0.001)\n",
        "# optimizer = optim.SparseAdam(sparse_model.parameters(), lr=0.001)\n",
        "num_epochs = 20\n",
        "\n",
        "train_model(sparse_model, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
        "evaluate_model(sparse_model, test_loader, criterion)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 443
        },
        "id": "fmx8bHqfxuLl",
        "outputId": "3d5c5520-1314-4755-d4c6-206a7a5a8529"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/20], Loss: 3.5410\n",
            "Epoch [2/20], Loss: 2.7627\n",
            "Epoch [3/20], Loss: 2.3026\n",
            "Epoch [4/20], Loss: 1.9679\n",
            "Epoch [5/20], Loss: 1.7301\n",
            "Epoch [6/20], Loss: 1.5679\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-38-f595630e14e5>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0mevaluate_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-24-3b75b2ca9990>\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, train_loader, criterion, optimizer, num_epochs)\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0mrunning_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m         \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    699\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    700\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 701\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    702\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    703\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    755\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    756\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 757\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    758\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    759\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, index)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mtuple\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, module in sparse_model.named_children():\n",
        "    if isinstance(module, SparseLinear):\n",
        "        print(module.weight_indices)\n",
        "        print(module.weight_values)\n",
        "        print(module.weight_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n8WeZlp68Gl8",
        "outputId": "b7fb7f3b-8217-4a3f-e698-23ef1c39c397"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0,  0,  1,  1,  1,  2,  2,  3,  3,  3,  4,  5,  5,  6,  7,  8,  9,  9,\n",
            "         10, 10, 11, 11, 11, 11, 12, 12, 13, 13, 14, 15, 15, 15],\n",
            "        [ 0,  7,  5,  6,  7,  6,  7,  2,  3,  5,  2,  1,  3,  1,  2,  5,  0,  5,\n",
            "          2,  5,  2,  3,  5,  6,  0,  2,  3,  7,  1,  5,  6,  7]])\n",
            "Parameter containing:\n",
            "tensor([-0.5490, -0.0094, -1.4751, -0.2817, -0.6310, -1.0393, -0.7908, -1.0391,\n",
            "         0.4169, -0.4048,  0.4887,  0.3577, -0.3371,  0.4536,  0.5027, -1.5247,\n",
            "         0.4702, -1.1093,  0.2888, -0.6178,  0.0719, -0.0153, -1.4159, -0.4777,\n",
            "        -0.5847, -0.4861,  0.3875, -0.3778, -0.3593, -2.6192, -0.5686, -0.4481],\n",
            "       requires_grad=True)\n",
            "torch.Size([16, 8])\n",
            "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  2,  2,  2,  2,  3,\n",
            "          3,  3,  3,  4,  4,  5,  5,  5,  5,  7,  7,  7,  7,  7],\n",
            "        [ 0,  1,  3,  5,  7,  8, 10, 15,  0,  1,  8, 11, 15,  2,  3, 10, 15,  0,\n",
            "          6, 11, 15,  0,  9,  1,  3, 10, 15,  1,  2,  8,  9, 15]])\n",
            "Parameter containing:\n",
            "tensor([-0.4336,  0.4035,  0.3199, -0.3887,  0.3066,  0.3547,  0.3521,  0.4640,\n",
            "        -1.3784,  0.7040,  0.7325,  0.3715,  0.7447,  0.7602,  0.6404,  0.3242,\n",
            "         0.7653, -0.2980,  0.3732,  0.3584,  0.6758, -0.3654, -0.3375,  0.2917,\n",
            "         0.5028,  0.4043,  0.5221,  0.3143, -0.3650,  0.5843, -0.2831, -0.6602],\n",
            "       requires_grad=True)\n",
            "torch.Size([8, 16])\n",
            "tensor([[0, 0],\n",
            "        [1, 2]])\n",
            "Parameter containing:\n",
            "tensor([1.1821, 0.6819], requires_grad=True)\n",
            "torch.Size([1, 8])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Define a simple sparse neural network\n",
        "class SparseNet(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SparseNet, self).__init__()\n",
        "        self.fc1 = nn.Linear(10, 5)  # Input layer\n",
        "        self.fc2 = nn.Linear(5, 1)    # Output layer\n",
        "\n",
        "        # Set weights to be sparse\n",
        "        self.fc1.weight.data = torch.nn.functional.dropout(self.fc1.weight.data, p=0.8, training=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = torch.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Sparse Adam optimizer\n",
        "class SparseAdam(optim.Adam):\n",
        "    def __init__(self, params, lr=1e-3):\n",
        "        super(SparseAdam, self).__init__(params, lr=lr)\n",
        "\n",
        "    def step(self, closure=None):\n",
        "        # Custom step logic can be added here for sparse optimization\n",
        "        return super(SparseAdam, self).step(closure)\n",
        "\n",
        "# Training loop\n",
        "def train(model, optimizer, criterion, data_loader, epochs=5):\n",
        "    model.train()\n",
        "    for epoch in range(epochs):\n",
        "        for inputs, targets in data_loader:\n",
        "            optimizer.zero_grad()  # Clear previous gradients\n",
        "            outputs = model(inputs)  # Forward pass\n",
        "            loss = criterion(outputs, targets)  # Compute loss\n",
        "            loss.backward()  # Backward pass\n",
        "            optimizer.step()  # Update weights\n",
        "\n",
        "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Create synthetic data\n",
        "    inputs = torch.randn(100, 10)\n",
        "    targets = torch.randn(100, 1)\n",
        "\n",
        "    # Create a data loader\n",
        "    dataset = torch.utils.data.TensorDataset(inputs, targets)\n",
        "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
        "\n",
        "    # Instantiate model, optimizer, and loss function\n",
        "    model = SparseNet()\n",
        "    optimizer = SparseAdam(model.parameters(), lr=0.001)\n",
        "    criterion = nn.MSELoss()\n",
        "\n",
        "    # Train the model\n",
        "    train(model, optimizer, criterion, data_loader, epochs=5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u1a-vgx__Imm",
        "outputId": "b1055b75-ab16-47a0-c509-cf99137cdf59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch [1/5], Loss: 0.9319\n",
            "Epoch [2/5], Loss: 1.7572\n",
            "Epoch [3/5], Loss: 0.4295\n",
            "Epoch [4/5], Loss: 1.8499\n",
            "Epoch [5/5], Loss: 1.3668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NUODn6KW_JIQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}