{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPdzrZyCcsX1"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBZya_BRPBUo",
        "outputId": "6b5eb546-f233-46f7-e3d5-9cad2d1083c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.10/dist-packages (0.18.7)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.25.5)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb) (2.19.2)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.10/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.10/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.11)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.0.0->wandb) (2024.8.30)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install wandb"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "cBDk7-o1PE1V",
        "outputId": "0c2cfae6-a851-4776-ede4-d9f9629462b3"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.18.7"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20241217_170658-l4c3xsp5</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/down-shift/self-expanding-nets/runs/l4c3xsp5' target=\"_blank\">upbeat-surf-4</a></strong> to <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/down-shift/self-expanding-nets/runs/l4c3xsp5' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets/runs/l4c3xsp5</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/down-shift/self-expanding-nets/runs/l4c3xsp5?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7ff1e1aad000>"
            ]
          },
          "execution_count": 108,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(project=\"self-expanding-nets\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0vPMyO9csX2"
      },
      "outputs": [],
      "source": [
        "from abc import abstractmethod, ABC\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "SEED = 8642\n",
        "torch.manual_seed(8642)\n",
        "\n",
        "device = 'cpu'"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mfiox0_FcsX2"
      },
      "source": [
        "## Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A3tEl4wpcsX2"
      },
      "outputs": [],
      "source": [
        "class SparseModule(ABC, nn.Module):\n",
        "    def __init__(self, weight_size):\n",
        "        super(SparseModule, self).__init__()\n",
        "        self.weight_indices = torch.empty(2, 0, dtype=torch.long)  # TODO\n",
        "        self.weight_values = nn.Parameter(torch.empty(0))\n",
        "        self.weight_size = list(weight_size)\n",
        "\n",
        "    def add_edge(self, child, parent):\n",
        "        new_edge = torch.tensor([[child, parent]], dtype=torch.long).t()\n",
        "        self.weight_indices = torch.cat([self.weight_indices, new_edge], dim=1)\n",
        "\n",
        "        new_weight = torch.empty(1)\n",
        "        nn.init.uniform_(new_weight)\n",
        "        self.weight_values.data = torch.cat([self.weight_values.data, new_weight])\n",
        "\n",
        "    def create_sparse_tensor(self):\n",
        "        return torch.sparse_coo_tensor(self.weight_indices, self.weight_values, self.weight_size)\n",
        "\n",
        "    @abstractmethod\n",
        "    def replace(self, child, parent, iteration, n_neurons):\n",
        "        pass\n",
        "\n",
        "    def replace_many(self, children, parents, iteration=None, n_neurons: int = 2):\n",
        "        for c, p in zip(children, parents):\n",
        "            self.replace(c, p, iteration, n_neurons)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WMNx7g_xcsX3"
      },
      "outputs": [],
      "source": [
        "class EmbedLinear(SparseModule):\n",
        "    def __init__(self, weight_size, activation=nn.ReLU()):\n",
        "        super(EmbedLinear, self).__init__([0, weight_size])\n",
        "        self.child_counter = 0\n",
        "        self.activation = activation\n",
        "\n",
        "    def replace(self, child, parent, iteration=None, n_neurons: int = 2):\n",
        "        for i in range(n_neurons):\n",
        "            self.add_edge(self.child_counter + i, parent)\n",
        "        self.weight_size[0] += n_neurons\n",
        "        self.child_counter += n_neurons\n",
        "\n",
        "    def forward(self, input):\n",
        "        sparse_embed_weight = self.create_sparse_tensor()\n",
        "        output = torch.sparse.mm(sparse_embed_weight, input.t()).t()\n",
        "        return torch.cat([input, self.activation(output)], dim=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CBMh3pHscsX3"
      },
      "outputs": [],
      "source": [
        "class ExpandingLinear(SparseModule):\n",
        "    def __init__(self, weight: torch.sparse_coo_tensor, bias: torch.sparse_coo_tensor):\n",
        "        super(ExpandingLinear, self).__init__(weight.size())\n",
        "\n",
        "        self.weight_indices = weight.coalesce().indices()\n",
        "        self.weight_values = nn.Parameter(weight.coalesce().values())\n",
        "\n",
        "        self.embed_linears = []\n",
        "\n",
        "        self.bias_indices = bias.coalesce().indices()\n",
        "        self.bias_values = nn.Parameter(bias.coalesce().values())\n",
        "        self.bias_size = list(bias.coalesce().size())\n",
        "\n",
        "        self.last_iteration = -1\n",
        "\n",
        "    def replace(self, child, parent, iteration, n_neurons: int = 2):\n",
        "        if iteration > self.last_iteration:\n",
        "            self.last_iteration = iteration\n",
        "            self.embed_linears.append(EmbedLinear(self.weight_size[1]))\n",
        "\n",
        "        matches = (self.weight_indices[0] == child) & (self.weight_indices[1] == parent)\n",
        "\n",
        "        self.weight_indices = self.weight_indices[:, ~matches]\n",
        "        self.weight_values = nn.Parameter(self.weight_values[~matches])\n",
        "\n",
        "        max_parent = self.weight_indices[1].max().item() + 1\n",
        "        for i in range(n_neurons):\n",
        "            self.add_edge(child, max_parent + i)\n",
        "        self.weight_size[1] += n_neurons\n",
        "        self.embed_linears[iteration].replace(child, parent, n_neurons=n_neurons)\n",
        "\n",
        "    def forward(self, input):\n",
        "        for i in range(self.last_iteration + 1):\n",
        "            input = self.embed_linears[i](input)\n",
        "\n",
        "        sparse_weight = self.create_sparse_tensor()\n",
        "        sparse_bias = torch.sparse_coo_tensor(self.bias_indices, self.bias_values, self.bias_size).to_dense()\n",
        "\n",
        "        output = torch.sparse.mm(sparse_weight, input.t()).t()\n",
        "        output += sparse_bias.unsqueeze(0)\n",
        "\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5du0GTQ_csX3"
      },
      "outputs": [],
      "source": [
        "def dense_to_sparse(dense_tensor: torch.Tensor) -> torch.Tensor:\n",
        "    indices = dense_tensor.nonzero(as_tuple=True)\n",
        "    values = dense_tensor[indices]\n",
        "    indices = torch.stack(indices)\n",
        "\n",
        "    sparse_tensor = torch.sparse_coo_tensor(indices, values, dense_tensor.size())\n",
        "    return sparse_tensor\n",
        "\n",
        "\n",
        "def convert_dense_to_sparse_network(model: nn.Module) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Converts a given dense neural network model to a sparse neural network model.\n",
        "\n",
        "    This function recursively iterate through the given model and replaces all instances of\n",
        "    `nn.Linear` layers with `SparseLinear` layers\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The dense neural network model to be converted.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: A new neural network model with sparse layers.\n",
        "    \"\"\"\n",
        "    new_model = model.__class__()\n",
        "\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Linear):\n",
        "            sparse_weight = dense_to_sparse(module.weight.data)\n",
        "            sparse_bias = dense_to_sparse(module.bias.data)\n",
        "\n",
        "            setattr(new_model, name, ExpandingLinear(sparse_weight, sparse_bias))\n",
        "        else:\n",
        "            setattr(new_model, name, convert_dense_to_sparse_network(module))\n",
        "    return new_model\n",
        "\n",
        "\n",
        "def get_model_last_layer(model):\n",
        "    return model if isinstance(model, SparseModule) else list(model.children())[-1]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abCa34mWcsX3"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UM_B9qUcsX3"
      },
      "outputs": [],
      "source": [
        "class NonlinearityMetric(ABC):\n",
        "    def __init__(self, loss_fn):\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    @abstractmethod\n",
        "    def calculate(self, model, X_arr, y_arr):\n",
        "        pass\n",
        "\n",
        "\n",
        "# Метрика 1: Средний градиент для каждого ребра\n",
        "class GradientMeanEdgeMetric(NonlinearityMetric):\n",
        "    def calculate(self, model, X_arr, y_arr):\n",
        "        model.eval()\n",
        "        model.zero_grad()\n",
        "\n",
        "        y_pred = model(X_arr).squeeze()\n",
        "        loss = self.loss_fn(y_pred, y_arr)\n",
        "        loss.backward()\n",
        "\n",
        "        last_layer = get_model_last_layer(model)\n",
        "\n",
        "        # Градиенты для разреженных весов\n",
        "        edge_gradients = last_layer.weight_values.grad.abs()\n",
        "        model.zero_grad()\n",
        "        return edge_gradients\n",
        "\n",
        "\n",
        "# Метрика 3: Чувствительность к возмущению для каждого ребра\n",
        "class PerturbationSensitivityEdgeMetric(NonlinearityMetric):\n",
        "    def __init__(self, loss_fn, epsilon=1e-2):\n",
        "        super().__init__(loss_fn)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def calculate(self, model, X_arr, y_arr):\n",
        "        model.eval()\n",
        "\n",
        "        # Оригинальный вывод модели\n",
        "        original_output = model(X_arr).detach()\n",
        "\n",
        "        last_layer = get_model_last_layer(model)\n",
        "        sensitivities = torch.zeros_like(last_layer.weight_values)\n",
        "\n",
        "        # Возмущение каждого веса\n",
        "        for idx in range(last_layer.weight_values.size(0)):\n",
        "            with torch.no_grad():\n",
        "                original_value = last_layer.weight_values[idx].item()\n",
        "                last_layer.weight_values[idx] += self.epsilon\n",
        "\n",
        "                # Пересчет модели с возмущением\n",
        "                perturbed_output = model(X_arr)\n",
        "                sensitivity = (perturbed_output - original_output).abs().mean().item()\n",
        "                sensitivities[idx] = sensitivity\n",
        "\n",
        "                # Восстановление оригинального значения\n",
        "                last_layer.weight_values[idx] = original_value\n",
        "\n",
        "        return sensitivities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NENK8UZ1csX4"
      },
      "outputs": [],
      "source": [
        "class EdgeFinder:\n",
        "    def __init__(self, metric: NonlinearityMetric, dataloader, device=torch.device('cpu')):\n",
        "        self.metric = metric\n",
        "        self.dataloader = dataloader\n",
        "        self.device = device\n",
        "\n",
        "    def calculate_edge_metric_for_dataloader(self, model, categorical_label: bool = True):\n",
        "        accumulated_grads = None\n",
        "        for data, target in self.dataloader:\n",
        "            data, target = data.to(self.device), target.to(self.device)#.to(torch.float32)\n",
        "\n",
        "            if not categorical_label:\n",
        "                target = target.to(torch.float32)\n",
        "\n",
        "            metric = self.metric.calculate(model, data, target)\n",
        "\n",
        "            if accumulated_grads is None:\n",
        "                accumulated_grads = torch.zeros_like(metric).to(self.device)\n",
        "\n",
        "            accumulated_grads += metric\n",
        "\n",
        "        return accumulated_grads / len(self.dataloader)\n",
        "\n",
        "    def choose_edges_top_k(self, model, top_k: int):\n",
        "        avg_metric = self.calculate_edge_metric_for_dataloader(model)\n",
        "        sorted_indices = torch.argsort(avg_metric, descending=True)\n",
        "        last_layer = get_model_last_layer(model)\n",
        "        return last_layer.weight_indices[:, sorted_indices[:top_k]]\n",
        "\n",
        "    def choose_edges_top_percent(self, model, percent: float):\n",
        "        percent = min(max(percent, 0.0), 1.0)  # percent in [0, 1]\n",
        "        avg_metric = self.calculate_edge_metric_for_dataloader(model)\n",
        "        k = int(percent * avg_metric.numel())\n",
        "        sorted_indices = torch.argsort(avg_metric, descending=True)\n",
        "        last_layer = get_model_last_layer(model)\n",
        "        return last_layer.weight_indices[:, sorted_indices[:k]]\n",
        "\n",
        "    def choose_edges_threshold(self, model, threshold):\n",
        "        avg_metric = self.calculate_edge_metric_for_dataloader(model)\n",
        "        mask = avg_metric > threshold\n",
        "        last_layer = get_model_last_layer(model)\n",
        "        return last_layer.weight_indices[:, mask.nonzero(as_tuple=True)[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "g_BtC_0XQ1nB"
      },
      "outputs": [],
      "source": [
        "def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric,\n",
        "                           edge_replacement_func=None, logging=True,\n",
        "                           expansion_criterion=None):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss_history = []\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for inputs, targets in tqdm(train_loader):\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_targets = []\n",
        "        all_preds = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = accuracy_score(all_targets, all_preds)\n",
        "        loss_history.append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        if logging:\n",
        "            wandb.log({\"val_accuracy\": val_accuracy, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
        "\n",
        "        # if edge_replacement_func and epoch % 5 == 0 and epoch != 0:\n",
        "        if edge_replacement_func and epoch >= n_prev_epochs and expansion_criterion:\n",
        "            if expansion_criterion(loss_history, n_prev_epochs, delta_threshold):\n",
        "                edge_replacement_func(model, optimizer, epoch // 5 - 1, val_loader, metric)\n",
        "                print(\"Replacement done\")\n",
        "            else:\n",
        "                print(\"Replacement denied\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tDo5IlbScsX4"
      },
      "source": [
        "## Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hQLNdkBcsX4"
      },
      "outputs": [],
      "source": [
        "class SimpleFCN(nn.Module):\n",
        "    def __init__(self, input_size=100):\n",
        "        super(SimpleFCN, self).__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(input_size, 50)\n",
        "        self.fc2 = nn.Linear(50, 50)\n",
        "        self.fc3 = nn.Linear(50, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x00Sjsa5csX4"
      },
      "outputs": [],
      "source": [
        "def edge_replacement_func_new_layer(model, optim, epoch, val_loader,\n",
        "                                    metric, verbose: bool = False,\n",
        "                                    n_neurons: int = 5):\n",
        "    layer = model.fc3  # TODO: address layer by index\n",
        "    start_indices = layer.weight_indices.clone()\n",
        "    ef = EdgeFinder(metric, val_loader, device)\n",
        "    chosen_edges = ef.choose_edges_top_k(model, 4)\n",
        "    if verbose:\n",
        "        print(\"values:\", ef.calculate_edge_metric_for_dataloader(model))\n",
        "        print(\"choose:\", chosen_edges)\n",
        "    layer.replace_many(*chosen_edges, epoch, n_neurons=n_neurons)\n",
        "    optim.add_param_group({'params': layer.embed_linears[-1].weight_values})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDO_k3hPcsX4",
        "outputId": "9e41667b-ec25-4c4c-e3f0-c0999cb484ee"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0.1206,  0.0075, -0.0142,  0.1125,  0.0116,  0.0212,  0.0825,  0.0726,\n",
              "         -0.1308,  0.1234]], grad_fn=<AsStridedBackward0>)"
            ]
          },
          "execution_count": 119,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "model = SimpleFCN(input_size=784)\n",
        "sparse_model = convert_dense_to_sparse_network(model)\n",
        "sparse_model.forward(torch.zeros(1, 784))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "a7Uo5MKUcsX5"
      },
      "outputs": [],
      "source": [
        "# Dataset and Dataloader\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))\n",
        "])\n",
        "\n",
        "# Load dataset and split into train/validation sets\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uNksB54oWHEo"
      },
      "outputs": [],
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "ef = EdgeFinder(GradientMeanEdgeMetric(criterion), val_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UxNGM2rbuIGT",
        "outputId": "7a1810d8-7670-4c45-fe99-c59b0e497fb8"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
              "          9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,\n",
              "          9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  9],\n",
              "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
              "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
              "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])"
            ]
          },
          "execution_count": 122,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer = sparse_model.fc3\n",
        "layer.weight_indices[:, -50:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "nWYkBjujgEIc",
        "outputId": "d5220c3a-2034-45d4-ae66-16b203b851d0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "choose: tensor([[ 6,  0,  0,  2],\n",
            "        [ 9, 16,  9,  9]])\n"
          ]
        }
      ],
      "source": [
        "# print(\"values:\", ef.calculate_edge_metric_for_dataloader(sparse_model, categorical_label=True))\n",
        "chosen_edges = ef.choose_edges_top_k(sparse_model, 4)\n",
        "print(\"choose:\", chosen_edges)\n",
        "layer.replace_many(*chosen_edges, 0, n_neurons=10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JmrH062JuYVB",
        "outputId": "cc511cf5-4a20-4d2f-af11-00531b9df50b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 9,  9,  9,  9,  9,  9,  9,  9,  9,  9,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "          0,  0,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  6,  6,  6,  6,  6,  6,\n",
              "          6,  6,  6,  6,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
              "        [40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57,\n",
              "         58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75,\n",
              "         76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89]])"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "layer.weight_indices[:, -50:]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3mVYwPRDubtc",
        "outputId": "f9eedb40-1f2a-4cb7-bab3-0bec678516c6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[-2.9399e-01,  1.6933e+01,  4.6140e+00, -3.3177e-01,  7.1464e-01,\n",
              "          5.1115e-01,  9.1954e-02,  4.1119e-01, -3.2533e-01,  6.7962e-01,\n",
              "         -4.2472e-02,  2.7728e-02,  2.7565e-01, -9.0941e-01, -6.9789e-02,\n",
              "         -4.2414e-02,  5.8177e-01, -8.4837e-01, -1.5170e+00, -1.1026e+00,\n",
              "          4.0978e-01,  4.1890e-02, -6.9281e-01,  4.1541e-02,  4.8347e-01,\n",
              "         -3.9879e-01,  4.1967e-01, -1.1426e+00,  2.1671e-02, -7.9159e-01,\n",
              "          1.8321e-01, -9.5565e-02, -5.2445e-02, -9.3179e-01,  7.1504e-01,\n",
              "         -4.2011e-01,  2.8803e-01, -1.5787e+00,  3.4729e-01,  1.1853e+00,\n",
              "         -7.8380e-01, -3.8235e-01,  1.5167e-01,  6.9604e-02, -4.4337e-02,\n",
              "         -8.1914e-03,  6.9524e-01,  2.4938e-02, -7.0610e-01, -6.9268e-02]],\n",
              "       grad_fn=<AsStridedBackward0>)"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# layer(torch.randn(1, 784))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EEgNzOkYd1Hm"
      },
      "source": [
        "## Dynamic sublayer size adjustment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oIjl-M2WeSfo",
        "outputId": "708edfbd-0a8b-4360-ceec-a646e117e9a1"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[ 0,  0,  0,  0],\n",
              "        [ 3, 10, 23, 59]])"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "ef.choose_edges_top_k(sparse_model, 4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 304
        },
        "id": "bnmbsMWOfLfO",
        "outputId": "f06e62c7-8e23-4fe5-ae18-51eeac9c2b32"
      },
      "outputs": [
        {
          "ename": "RuntimeError",
          "evalue": "addmm: Argument #3 (dense): Expected dim 0 size 55, got 50",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-135-b3926d7b2b70>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# METRIC_THRESHOLD = 0.05\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mef\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mchoose_edges_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-115-a1801221e0d8>\u001b[0m in \u001b[0;36mchoose_edges_threshold\u001b[0;34m(self, model, threshold)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mchoose_edges_threshold\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mavg_metric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_edge_metric_for_dataloader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0mmask\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_metric\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mthreshold\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m         \u001b[0mlast_layer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_model_last_layer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-115-a1801221e0d8>\u001b[0m in \u001b[0;36mcalculate_edge_metric_for_dataloader\u001b[0;34m(self, model, categorical_label)\u001b[0m\n\u001b[1;32m     13\u001b[0m                 \u001b[0mtarget\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m             \u001b[0mmetric\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0maccumulated_grads\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-114-922acd9cdf5a>\u001b[0m in \u001b[0;36mcalculate\u001b[0;34m(self, model, X_arr, y_arr)\u001b[0m\n\u001b[1;32m     14\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m         \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     17\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_arr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-117-c40f3b61aab7>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m         \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc3\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1734\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1735\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1736\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1737\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1746\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1747\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1748\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-112-d946dba3d94e>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0msparse_bias\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse_coo_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_indices\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_dense\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msparse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmm\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msparse_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0msparse_bias\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mRuntimeError\u001b[0m: addmm: Argument #3 (dense): Expected dim 0 size 55, got 50"
          ]
        }
      ],
      "source": [
        "ef.choose_edges_threshold(sparse_model, threshold=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dV8tpx0od9J4"
      },
      "outputs": [],
      "source": [
        "# def calculate_sublayer_size_threshold(sparse_model, ef, top_k: int = 5) -> int:\n",
        "#     ef.choose_edges_top_k(sparse_model, top_k)\n",
        "#     meow;\n",
        "#     pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "njwWBVmllEIs",
        "outputId": "c1e601e6-052a-4227-f26a-ab9efdf2723f"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([0.1 , 0.1 , 0.1 , 0.37])"
            ]
          },
          "execution_count": 105,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arr = np.array([0.1, 0.2, 0.3, 0.4, 0.77])\n",
        "deltas = np.array([arr[i + 1] - arr[i] for i in range(len(arr) - 1)])\n",
        "deltas"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VIJhPLang7Af"
      },
      "outputs": [],
      "source": [
        "def get_expansion_criterion(loss_history, n_prev_epochs: int = 3, delta_threshold: float = 0.3) -> bool:\n",
        "    \"\"\"\n",
        "    Idea: extend layer if mean of [|∆loss_i|] over n previous epochs\n",
        "    is smaller than delta_threshold\n",
        "    \"\"\"\n",
        "    arr = np.array(loss_history[-n_prev_epochs:])\n",
        "    deltas = np.array([arr[i + 1] - arr[i] for i in range(len(arr) - 1)])\n",
        "    return np.mean(np.abs(deltas)) < delta_threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VNiU14OwlyPc",
        "outputId": "4f442dbf-4956-4959-c69d-a3d512205cd9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 129,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "get_expansion_criterion(arr)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "krPGhnTzZ0TQ"
      },
      "source": [
        "## Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0o6BD4zOcGR7"
      },
      "outputs": [],
      "source": [
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Lambda(lambda x: x.view(-1))\n",
        "])\n",
        "\n",
        "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
        "train_size = int(0.8 * len(dataset))\n",
        "val_size = len(dataset) - train_size\n",
        "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zC8Z0Py8cDYy"
      },
      "outputs": [],
      "source": [
        "model = SimpleFCN(input_size=784)\n",
        "sparse_model = convert_dense_to_sparse_network(model)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "ef = EdgeFinder(GradientMeanEdgeMetric(criterion), val_loader, device)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qmg78Zloh7vk"
      },
      "outputs": [],
      "source": [
        "n_prev_epochs = 4\n",
        "delta_threshold = 0.3"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bgnfKSdVmz9p"
      },
      "outputs": [],
      "source": [
        "train_sparse_recursive(sparse_model,\n",
        "                       train_loader,\n",
        "                       val_loader,\n",
        "                       num_epochs=15,\n",
        "                       metric=GradientMeanEdgeMetric(criterion),\n",
        "                       edge_replacement_func=edge_replacement_func_new_layer,\n",
        "                       expansion_criterion=get_expansion_criterion)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "NZlTPEFqdjsb",
        "outputId": "1a0d9d1a-7f71-4082-aa5a-80d0eeb61548"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "    <style>\n",
              "        .wandb-row {\n",
              "            display: flex;\n",
              "            flex-direction: row;\n",
              "            flex-wrap: wrap;\n",
              "            justify-content: flex-start;\n",
              "            width: 100%;\n",
              "        }\n",
              "        .wandb-col {\n",
              "            display: flex;\n",
              "            flex-direction: column;\n",
              "            flex-basis: 100%;\n",
              "            flex: 1;\n",
              "            padding: 10px;\n",
              "        }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▃▂▂▂▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▆▇▇▇▇████</td></tr><tr><td>val_loss</td><td>█▄▃▃▂▂▂▂▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.19562</td></tr><tr><td>val_accuracy</td><td>0.94308</td></tr><tr><td>val_loss</td><td>0.2044</td></tr></table><br/></div></div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">true-bush-3</strong> at: <a href='https://wandb.ai/down-shift/self-expanding-nets/runs/017qmjlw' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets/runs/017qmjlw</a><br/> View project at: <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20241217_165911-017qmjlw/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "wandb.finish()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "h9XrsDtwdk56"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
