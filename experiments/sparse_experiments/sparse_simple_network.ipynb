{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "I1fFZaT5f8dR",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:04:28.751180Z",
     "start_time": "2024-11-04T22:04:24.778950Z"
    }
   },
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import torch.optim as optim\n",
    "import torch.nn.utils.prune as prune\n",
    "\n",
    "from copy import deepcopy"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "source": [
    "housing = fetch_california_housing()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(housing.data)\n",
    "y = housing.target\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "y_train_tensor = torch.tensor(y_train, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "y_test_tensor = torch.tensor(y_test, dtype=torch.float32).unsqueeze(1)\n",
    "\n",
    "train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=64, shuffle=False)\n"
   ],
   "metadata": {
    "id": "rvjazlWwiwzU",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:05:51.456260Z",
     "start_time": "2024-11-04T22:05:49.905550Z"
    }
   },
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "source": [
    "class SimpleFCN(nn.Module):\n",
    "    def __init__(self, input_size=8):\n",
    "        super(SimpleFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 16)\n",
    "        self.fc2 = nn.Linear(16, 8)\n",
    "        self.fc3 = nn.Linear(8, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "input_size = X_train.shape[1]\n",
    "model = SimpleFCN(input_size)"
   ],
   "metadata": {
    "id": "Y5Ndc5TRixFr",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:05:51.998198Z",
     "start_time": "2024-11-04T22:05:51.984569Z"
    }
   },
   "outputs": [],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, train_loader, criterion, optimizer, num_epochs=20):\n",
    "    model.train()\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, targets in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_loader):.4f}')\n",
    "\n",
    "def evaluate_model(model, test_loader, criterion):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for inputs, targets in test_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    print(f'Evaluation Loss: {avg_loss:.4f}')\n",
    "    return avg_loss\n",
    "\n",
    "num_epochs = 20\n",
    "train_model(model, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
    "evaluate_model(model, test_loader, criterion)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jwjrdKmkizg5",
    "outputId": "2b29daee-1d9e-423c-d9cc-7cd1c0546a88",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:06:03.281915Z",
     "start_time": "2024-11-04T22:05:52.720680Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 1.9756\n",
      "Epoch [2/20], Loss: 0.6325\n",
      "Epoch [3/20], Loss: 0.5182\n",
      "Epoch [4/20], Loss: 0.4572\n",
      "Epoch [5/20], Loss: 0.4252\n",
      "Epoch [6/20], Loss: 0.4100\n",
      "Epoch [7/20], Loss: 0.3977\n",
      "Epoch [8/20], Loss: 0.3881\n",
      "Epoch [9/20], Loss: 0.3814\n",
      "Epoch [10/20], Loss: 0.3754\n",
      "Epoch [11/20], Loss: 0.3697\n",
      "Epoch [12/20], Loss: 0.3665\n",
      "Epoch [13/20], Loss: 0.3641\n",
      "Epoch [14/20], Loss: 0.3599\n",
      "Epoch [15/20], Loss: 0.3570\n",
      "Epoch [16/20], Loss: 0.3549\n",
      "Epoch [17/20], Loss: 0.3505\n",
      "Epoch [18/20], Loss: 0.3464\n",
      "Epoch [19/20], Loss: 0.3439\n",
      "Epoch [20/20], Loss: 0.3395\n",
      "Evaluation Loss: 0.3525\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.35247760965273933"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "source": [
    "eps = torch.tensor([1e-10])"
   ],
   "metadata": {
    "id": "WDrvz-WKkcKX",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:06:04.104508Z",
     "start_time": "2024-11-04T22:06:04.098971Z"
    }
   },
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "source": [
    "@torch.enable_grad()\n",
    "def evaluate_sensitivity(model, dataloader, loss_function):\n",
    "\n",
    "    sensitivity = {}\n",
    "\n",
    "    for data, target in dataloader:\n",
    "\n",
    "        model.zero_grad()\n",
    "\n",
    "        output = model(data)\n",
    "        loss = loss_function(output, target)\n",
    "        loss.backward()\n",
    "\n",
    "        for param_name, p in model.named_parameters():\n",
    "            if \"weight\" in param_name:\n",
    "\n",
    "                if param_name in sensitivity.keys():\n",
    "                    sensitivity[param_name] = sensitivity[param_name] + torch.abs(p).detach().cpu()\n",
    "                else:\n",
    "                    sensitivity[param_name] = torch.abs(p).detach().cpu()\n",
    "\n",
    "    for k in sensitivity.keys():\n",
    "        sensitivity[k] /= len(dataloader)\n",
    "        sensitivity[k] /= torch.max(torch.max(sensitivity[k], eps))\n",
    "\n",
    "    return sensitivity\n"
   ],
   "metadata": {
    "id": "KUqaes5Ji2bp",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:06:04.706781Z",
     "start_time": "2024-11-04T22:06:04.695819Z"
    }
   },
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "source": [
    "def do_pruning(model, pruning_type=\"Random\", **kwargs):\n",
    "    prune_model = deepcopy(model)\n",
    "\n",
    "    amount = kwargs.pop('amount', 0.3)\n",
    "    logs = kwargs.pop('logs', False)\n",
    "    sensitivity = kwargs.pop('sensitivity', {})\n",
    "    counter = list(sensitivity.keys())\n",
    "\n",
    "    def apply_l1_pruning(module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.l1_unstructured(module, name='weight', amount=amount)\n",
    "            if logs:\n",
    "                print(f\"Применен L1 прунинг к слою: {module}\")\n",
    "                print(f\"Маска:\\n{module.weight_mask}\\n\")\n",
    "\n",
    "    def apply_random_pruning(module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            prune.random_unstructured(module, name='weight', amount=amount)\n",
    "            if logs:\n",
    "                print(f\"Применен Random прунинг к слою: {module}\")\n",
    "                print(f\"Маска:\\n{module.weight_mask}\\n\")\n",
    "\n",
    "    def remove_pruning(module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                prune.remove(module, 'weight')\n",
    "                if logs:\n",
    "                    print(f\"Удалена маска прунинга в слое: {module}\")\n",
    "\n",
    "    def zero_weights_by_mask(module):\n",
    "        if isinstance(module, nn.Linear):\n",
    "            if hasattr(module, 'weight_mask'):\n",
    "                with torch.no_grad():\n",
    "                    module.weight.data *= module.weight_mask\n",
    "                    if logs:\n",
    "                        print(f\"Обнулены веса по маске в слое: {module}\")\n",
    "                        print(f\"Текущие веса:\\n{module.weight.data}\\n\")\n",
    "\n",
    "\n",
    "    def apply_sensitivity_pruning(module):\n",
    "        nonlocal counter\n",
    "\n",
    "        if isinstance(module, nn.Linear):\n",
    "            param_name = counter.pop(0)\n",
    "            if param_name in sensitivity:\n",
    "\n",
    "                sens_tensor = sensitivity[param_name]\n",
    "\n",
    "                flat_weights = module.weight.view(-1)\n",
    "                flat_sensitivity = sens_tensor.view(-1)\n",
    "\n",
    "                num_params_to_prune = int(amount * flat_sensitivity.numel())\n",
    "                _, indices = torch.topk(flat_sensitivity, k=num_params_to_prune, largest=False)\n",
    "\n",
    "                mask = torch.ones_like(flat_weights)\n",
    "                mask[indices] = 0\n",
    "\n",
    "                prune.custom_from_mask(module, name='weight', mask=mask.view_as(module.weight))\n",
    "\n",
    "                if logs:\n",
    "                    print(f\"Применен Sensitivity-based прунинг к слою: {module}\")\n",
    "                    print(f\"Маска:\\n{mask.view_as(module.weight)}\\n\")\n",
    "\n",
    "    apply_func = None\n",
    "    if pruning_type == \"L1\":\n",
    "        apply_func = apply_l1_pruning\n",
    "    elif pruning_type == \"Random\":\n",
    "        apply_func = apply_random_pruning\n",
    "    elif pruning_type == \"Remove\":\n",
    "        apply_func = remove_pruning\n",
    "    elif pruning_type == \"SensitivityBased\":\n",
    "        apply_func = apply_sensitivity_pruning\n",
    "\n",
    "    if apply_func:\n",
    "        prune_model.apply(lambda module: apply_func(module))\n",
    "        prune_model.apply(lambda module: zero_weights_by_mask(module))\n",
    "        prune_model.apply(lambda module: remove_pruning(module))\n",
    "\n",
    "    return prune_model\n"
   ],
   "metadata": {
    "id": "XVDzDFpkkgt_",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:06:05.434342Z",
     "start_time": "2024-11-04T22:06:05.415490Z"
    }
   },
   "outputs": [],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "source": [
    "pruned_model = do_pruning(model, pruning_type=\"L1\", amount=0.75, logs=False)"
   ],
   "metadata": {
    "id": "WFU3ShYGnRDX",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:06:06.384723Z",
     "start_time": "2024-11-04T22:06:06.376081Z"
    }
   },
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "source": [
    "evaluate_model(pruned_model, test_loader, criterion)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PjaoCtvxncn_",
    "outputId": "c5c8d4e6-6375-493e-e40c-32d7e04914c5",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:06:07.275851Z",
     "start_time": "2024-11-04T22:06:07.214290Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluation Loss: 4.5228\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4.522848675801204"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "source": [
    "def dense_to_sparse(dense_tensor):\n",
    "    indices = dense_tensor.nonzero(as_tuple=True)\n",
    "    values = dense_tensor[indices]\n",
    "    indices = torch.stack(indices)\n",
    "\n",
    "    sparse_tensor = torch.sparse.FloatTensor(indices, values, dense_tensor.size())\n",
    "    return sparse_tensor"
   ],
   "metadata": {
    "id": "iMl8XMQqn3HU",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:15.429338Z",
     "start_time": "2024-11-04T22:07:15.423945Z"
    }
   },
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "source": [
    "class SparseLinear(nn.Module):\n",
    "    def __init__(self, weight, bias):\n",
    "        super(SparseLinear, self).__init__()\n",
    "\n",
    "        self.weight_indices = weight.coalesce().indices()\n",
    "        self.weight_values = nn.Parameter(weight.coalesce().values())\n",
    "        self.weight_size = list(weight.coalesce().size())\n",
    "\n",
    "        self.bias_indices = bias.coalesce().indices()\n",
    "        self.bias_values = nn.Parameter(bias.coalesce().values())\n",
    "        self.bias_size = list(bias.coalesce().size())\n",
    "\n",
    "    def forward(self, input):\n",
    "        sparse_weight = torch.sparse.FloatTensor(self.weight_indices, self.weight_values, self.weight_size)\n",
    "        sparse_bias = torch.sparse.FloatTensor(self.bias_indices, self.bias_values, self.bias_size).to_dense()\n",
    "\n",
    "        output = torch.sparse.mm(sparse_weight, input.t()).t()\n",
    "        output += sparse_bias.unsqueeze(0)\n",
    "\n",
    "        return output"
   ],
   "metadata": {
    "id": "7Rw6XsnopuCK",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:15.629347Z",
     "start_time": "2024-11-04T22:07:15.623911Z"
    }
   },
   "outputs": [],
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "\n",
    "# class SparseLinear(nn.Module):\n",
    "#     def __init__(self, weight, bias):\n",
    "#         super(SparseLinear, self).__init__()\n",
    "\n",
    "#         self.weight = nn.Parameter(weight.to_dense())\n",
    "#         # self.bias = nn.Parameter(bias)\n",
    "\n",
    "#     def forward(self, input):\n",
    "\n",
    "#         output = torch.sparse.mm(self.weight, input.t()).t()\n",
    "#         # output += self.bias\n",
    "\n",
    "#         return output"
   ],
   "metadata": {
    "id": "XvKLVJ1q8d3S",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:16.408966Z",
     "start_time": "2024-11-04T22:07:16.404136Z"
    }
   },
   "outputs": [],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "source": [
    "def convert_dense_to_sparse_network(model):\n",
    "    new_model = model.__class__()\n",
    "\n",
    "    for name, module in model.named_children():\n",
    "        if isinstance(module, nn.Linear):\n",
    "            sparse_weight = dense_to_sparse(module.weight.data)\n",
    "            sparse_bias = dense_to_sparse(module.bias.data)\n",
    "\n",
    "            setattr(new_model, name, SparseLinear(sparse_weight, sparse_bias))\n",
    "        else:\n",
    "            setattr(new_model, name, convert_dense_to_sparse_network(module))\n",
    "    return new_model"
   ],
   "metadata": {
    "id": "VLdl2c52pvmy",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:16.803919Z",
     "start_time": "2024-11-04T22:07:16.795388Z"
    }
   },
   "outputs": [],
   "execution_count": 14
  },
  {
   "cell_type": "code",
   "source": [
    "sparse_model = convert_dense_to_sparse_network(pruned_model)"
   ],
   "metadata": {
    "id": "cwBysM73pNx9",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:17.499494Z",
     "start_time": "2024-11-04T22:07:17.484997Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fedor\\AppData\\Local\\Temp\\ipykernel_16336\\2496503429.py:6: UserWarning: torch.sparse.SparseTensor(indices, values, shape, *, device=) is deprecated.  Please use torch.sparse_coo_tensor(indices, values, shape, dtype=, device=). (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:653.)\n",
      "  sparse_tensor = torch.sparse.FloatTensor(indices, values, dense_tensor.size())\n"
     ]
    }
   ],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "source": [
    "for param in sparse_model.named_parameters():\n",
    "    print(param[0], param[1].shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "I4NBXt3R6t4p",
    "outputId": "8ccc585d-7a2f-40c1-be86-2ceae5dc14af",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:19.185007Z",
     "start_time": "2024-11-04T22:07:19.178167Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight_values torch.Size([32])\n",
      "fc1.bias_values torch.Size([16])\n",
      "fc2.weight_values torch.Size([32])\n",
      "fc2.bias_values torch.Size([8])\n",
      "fc3.weight_values torch.Size([2])\n",
      "fc3.bias_values torch.Size([1])\n"
     ]
    }
   ],
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "source": [
    "for param in model.named_parameters():\n",
    "    print(param[0], param[1].shape)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OuqItk0hmdtV",
    "outputId": "cf0f2f44-4894-4892-c519-dad7e870216d",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:20.130091Z",
     "start_time": "2024-11-04T22:07:20.125439Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fc1.weight torch.Size([16, 8])\n",
      "fc1.bias torch.Size([16])\n",
      "fc2.weight torch.Size([8, 16])\n",
      "fc2.bias torch.Size([8])\n",
      "fc3.weight torch.Size([1, 8])\n",
      "fc3.bias torch.Size([1])\n"
     ]
    }
   ],
   "execution_count": 17
  },
  {
   "cell_type": "code",
   "source": [
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.AdamW(sparse_model.parameters(), lr=0.001)\n",
    "# optimizer = optim.SparseAdam(sparse_model.parameters(), lr=0.001)\n",
    "num_epochs = 20\n",
    "\n",
    "train_model(sparse_model, train_loader, criterion, optimizer, num_epochs=num_epochs)\n",
    "evaluate_model(sparse_model, test_loader, criterion)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 443
    },
    "id": "fmx8bHqfxuLl",
    "outputId": "3d5c5520-1314-4755-d4c6-206a7a5a8529",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:39.686195Z",
     "start_time": "2024-11-04T22:07:20.985078Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/20], Loss: 3.5808\n",
      "Epoch [2/20], Loss: 2.8319\n",
      "Epoch [3/20], Loss: 2.3597\n",
      "Epoch [4/20], Loss: 2.0076\n",
      "Epoch [5/20], Loss: 1.7449\n",
      "Epoch [6/20], Loss: 1.5384\n",
      "Epoch [7/20], Loss: 1.3585\n",
      "Epoch [8/20], Loss: 1.1938\n",
      "Epoch [9/20], Loss: 1.0535\n",
      "Epoch [10/20], Loss: 0.9420\n",
      "Epoch [11/20], Loss: 0.8533\n",
      "Epoch [12/20], Loss: 0.7818\n",
      "Epoch [13/20], Loss: 0.7227\n",
      "Epoch [14/20], Loss: 0.6739\n",
      "Epoch [15/20], Loss: 0.6336\n",
      "Epoch [16/20], Loss: 0.5999\n",
      "Epoch [17/20], Loss: 0.5714\n",
      "Epoch [18/20], Loss: 0.5472\n",
      "Epoch [19/20], Loss: 0.5266\n",
      "Epoch [20/20], Loss: 0.5090\n",
      "Evaluation Loss: 0.5010\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.5009587008219499"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "source": [
    "for name, module in sparse_model.named_children():\n",
    "    if isinstance(module, SparseLinear):\n",
    "        print(module.weight_indices)\n",
    "        print(module.weight_values)\n",
    "        print(module.weight_size)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n8WeZlp68Gl8",
    "outputId": "b7fb7f3b-8217-4a3f-e698-23ef1c39c397",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:40.557290Z",
     "start_time": "2024-11-04T22:07:40.545232Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0,  0,  1,  1,  1,  2,  2,  2,  2,  3,  4,  4,  5,  5,  6,  7,  7,  8,\n",
      "          9, 10, 10, 10, 11, 11, 12, 12, 13, 13, 14, 14, 14, 15],\n",
      "        [ 6,  7,  0,  2,  3,  0,  5,  6,  7,  5,  0,  5,  2,  3,  0,  5,  7,  5,\n",
      "          6,  5,  6,  7,  5,  7,  5,  7,  5,  7,  5,  6,  7,  2]])\n",
      "Parameter containing:\n",
      "tensor([-0.3744, -0.5310,  0.5842, -0.4551, -0.5888,  0.3508, -1.4082, -0.7931,\n",
      "        -0.7663, -2.7612,  0.4228, -1.6312, -0.9056,  0.5613,  0.4131, -1.1218,\n",
      "         0.4379, -1.5826, -0.4661, -0.6236, -0.5429, -0.4766, -1.1407, -0.4586,\n",
      "        -2.1161, -0.6248, -0.3464, -0.1559, -2.5288, -0.7230,  0.6464,  0.7459],\n",
      "       requires_grad=True)\n",
      "[16, 8]\n",
      "tensor([[ 0,  0,  0,  2,  2,  2,  2,  2,  3,  3,  3,  4,  4,  4,  4,  4,  5,  5,\n",
      "          5,  5,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7],\n",
      "        [ 2,  3, 13,  0,  9, 10, 12, 14,  9, 12, 13,  0,  5,  8, 11, 15,  1,  2,\n",
      "         10, 14,  1,  2,  5, 10, 11, 12,  3, 10, 11, 12, 14, 15]])\n",
      "Parameter containing:\n",
      "tensor([-1.0816, -0.7758,  0.6591,  0.4130,  0.3559,  0.4671,  0.5253,  0.4208,\n",
      "        -0.4530,  0.3794,  0.3730,  0.3989, -0.5483,  0.3443,  0.3680, -0.4750,\n",
      "        -0.4448,  0.3208,  0.3149,  0.4390, -0.3889,  0.3260,  0.4540,  0.5912,\n",
      "         0.3238,  0.3667, -0.3173, -0.4801, -0.3780, -0.5695,  0.5277, -0.7072],\n",
      "       requires_grad=True)\n",
      "[8, 16]\n",
      "tensor([[0, 0],\n",
      "        [0, 7]])\n",
      "Parameter containing:\n",
      "tensor([-1.7619, -1.0446], requires_grad=True)\n",
      "[1, 8]\n"
     ]
    }
   ],
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "source": [
    "# Define a simple sparse neural network\n",
    "class SparseNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SparseNet, self).__init__()\n",
    "        self.fc1 = nn.Linear(10, 5)  # Input layer\n",
    "        self.fc2 = nn.Linear(5, 1)    # Output layer\n",
    "\n",
    "        # Set weights to be sparse\n",
    "        self.fc1.weight.data = torch.nn.functional.dropout(self.fc1.weight.data, p=0.8, training=True)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "# Sparse Adam optimizer\n",
    "class SparseAdam(optim.Adam):\n",
    "    def __init__(self, params, lr=1e-3):\n",
    "        super(SparseAdam, self).__init__(params, lr=lr)\n",
    "\n",
    "    def step(self, closure=None):\n",
    "        # Custom step logic can be added here for sparse optimization\n",
    "        return super(SparseAdam, self).step(closure)\n",
    "\n",
    "# Training loop\n",
    "def train(model, optimizer, criterion, data_loader, epochs=5):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "        for inputs, targets in data_loader:\n",
    "            optimizer.zero_grad()  # Clear previous gradients\n",
    "            outputs = model(inputs)  # Forward pass\n",
    "            loss = criterion(outputs, targets)  # Compute loss\n",
    "            loss.backward()  # Backward pass\n",
    "            optimizer.step()  # Update weights\n",
    "\n",
    "        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Create synthetic data\n",
    "    inputs = torch.randn(100, 10)\n",
    "    targets = torch.randn(100, 1)\n",
    "\n",
    "    # Create a data loader\n",
    "    dataset = torch.utils.data.TensorDataset(inputs, targets)\n",
    "    data_loader = torch.utils.data.DataLoader(dataset, batch_size=16, shuffle=True)\n",
    "\n",
    "    # Instantiate model, optimizer, and loss function\n",
    "    model = SparseNet()\n",
    "    optimizer = SparseAdam(model.parameters(), lr=0.001)\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    # Train the model\n",
    "    train(model, optimizer, criterion, data_loader, epochs=5)\n"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u1a-vgx__Imm",
    "outputId": "b1055b75-ab16-47a0-c509-cf99137cdf59",
    "ExecuteTime": {
     "end_time": "2024-11-04T22:07:42.558958Z",
     "start_time": "2024-11-04T22:07:42.505188Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 1.9030\n",
      "Epoch [2/5], Loss: 0.6768\n",
      "Epoch [3/5], Loss: 1.1159\n",
      "Epoch [4/5], Loss: 0.6065\n",
      "Epoch [5/5], Loss: 1.3552\n"
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {
    "id": "NUODn6KW_JIQ"
   },
   "execution_count": null,
   "outputs": []
  }
 ]
}
