{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:46.046550Z",
     "start_time": "2024-12-17T13:08:46.029978Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 38
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:46.076596Z",
     "start_time": "2024-12-17T13:08:46.069376Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from senmodel.model.utils import convert_dense_to_sparse_network\n",
    "from senmodel.metrics.nonlinearity_metrics import GradientMeanEdgeMetric, PerturbationSensitivityEdgeMetric\n",
    "from senmodel.metrics.edge_finder import EdgeFinder\n"
   ],
   "id": "851a61bbbac63426",
   "outputs": [],
   "execution_count": 39
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:46.106256Z",
     "start_time": "2024-12-17T13:08:46.098958Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")",
   "id": "ed98f9250fb9b52",
   "outputs": [],
   "execution_count": 40
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:50.985738Z",
     "start_time": "2024-12-17T13:08:46.134968Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "data = pd.read_csv(url, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
    "data = data.dropna()\n",
    "\n",
    "X = data.drop('income', axis=1)\n",
    "y = data['income']\n",
    "\n",
    "\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ],
   "id": "8a1c4b0b6e33d5a4",
   "outputs": [],
   "execution_count": 41
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.019029Z",
     "start_time": "2024-12-17T13:08:51.008405Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ],
   "id": "d7d9e408b16a7a6a",
   "outputs": [],
   "execution_count": 42
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.053218Z",
     "start_time": "2024-12-17T13:08:51.042786Z"
    }
   },
   "cell_type": "code",
   "source": [
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "val_dataset = TabularDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ],
   "id": "183cc85a9b097f1",
   "outputs": [],
   "execution_count": 43
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.119952Z",
     "start_time": "2024-12-17T13:08:51.111442Z"
    }
   },
   "cell_type": "code",
   "source": [
    "class SimpleFCN(nn.Module):\n",
    "    def __init__(self, input_size=14, hidden_size=128, output_size=2):\n",
    "        super(SimpleFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ],
   "id": "cf7e5ab74bd84c4c",
   "outputs": [],
   "execution_count": 44
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.140638Z",
     "start_time": "2024-12-17T13:08:51.130324Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def edge_replacement_func_new_layer(model, optim, val_loader, metric):\n",
    "    layer = model.fc1\n",
    "    ef = EdgeFinder(metric, val_loader, device)\n",
    "    vals = ef.calculate_edge_metric_for_dataloader(model)\n",
    "    print(\"Edge metrics:\", vals, max(vals), sum(vals))\n",
    "    chosen_edges = ef.choose_edges_threshold(model, 0.2)\n",
    "    print(\"Chosen edges:\", chosen_edges, len(chosen_edges[0]))\n",
    "    layer.replace_many(*chosen_edges)\n",
    "\n",
    "    if layer.embed_linears:\n",
    "        optim.add_param_group({'params': layer.embed_linears[-1].weight_values})\n",
    "    else:\n",
    "        print(\"Empty metric\")\n",
    "        dummy_param = torch.zeros_like(layer.weight_values)\n",
    "        optim.add_param_group({'params': dummy_param})\n",
    "\n",
    "    return {'max': max(vals), 'sum': sum(vals), 'len': len(vals), 'len_choose': len(chosen_edges[0])}\n"
   ],
   "id": "6fe92b9bfdd4d7d1",
   "outputs": [],
   "execution_count": 45
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.204092Z",
     "start_time": "2024-12-17T13:08:51.189429Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func=None,\n",
    "                           window_size=3, threshold=0.10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(all_targets, all_preds)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        # new_l = {}\n",
    "        # val_losses.append(val_loss)\n",
    "        # if edge_replacement_func and len(val_losses) > window_size:\n",
    "        #     recent_changes = [abs(val_losses[i] - val_losses[i - 1]) for i in range(-window_size, 0)]\n",
    "        #     avg_change = sum(recent_changes) / window_size\n",
    "        #     if avg_change < threshold:\n",
    "        #         new_l = edge_replacement_func(model, optimizer, val_loader, metric)\n",
    "        #\n",
    "\n",
    "        new_l = {}\n",
    "        if edge_replacement_func and epoch % 8 == 0 and epoch != 0:\n",
    "            new_l = edge_replacement_func(model, optimizer, val_loader, metric)\n",
    "\n",
    "        wandb.log({'val_loss': val_loss, 'val_accuracy': val_accuracy, 'train_loss': train_loss} | new_l)\n",
    "\n"
   ],
   "id": "e0e4d086a0b3b29f",
   "outputs": [],
   "execution_count": 46
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.255915Z",
     "start_time": "2024-12-17T13:08:51.248933Z"
    }
   },
   "cell_type": "code",
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "metrics = [\n",
    "    GradientMeanEdgeMetric(criterion),\n",
    "    PerturbationSensitivityEdgeMetric(criterion),\n",
    "]\n"
   ],
   "id": "b44615f5a401dd16",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.277671Z",
     "start_time": "2024-12-17T13:08:51.264278Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ],
   "id": "c813771bca507d71",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: WARNING Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 48
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:51.317243Z",
     "start_time": "2024-12-17T13:08:51.313304Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "a10df7d34ecdcb18",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-17T13:08:59.973869Z",
     "start_time": "2024-12-17T13:08:51.369681Z"
    }
   },
   "cell_type": "code",
   "source": [
    "dense_model = SimpleFCN(input_size=X.shape[1], hidden_size=128, output_size=2)\n",
    "sparse_model = convert_dense_to_sparse_network(dense_model)\n",
    "wandb.init(\n",
    "    project=\"self-expanding-nets\",\n",
    "    name=f\"minst, threshold\",\n",
    ")\n",
    "\n",
    "train_sparse_recursive(sparse_model, train_loader, val_loader, num_epochs=20,\n",
    "                       metric=metrics[0],\n",
    "                       edge_replacement_func=edge_replacement_func_new_layer)"
   ],
   "id": "45fe9040816bb570",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 75.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20 | Train Loss: 0.5360 | Val Loss: 6.1244 | Val Accuracy: 0.7844\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 75.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/20 | Train Loss: 0.4289 | Val Loss: 5.3904 | Val Accuracy: 0.8167\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 54.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/20 | Train Loss: 0.3908 | Val Loss: 5.0982 | Val Accuracy: 0.8225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 70.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/20 | Train Loss: 0.3741 | Val Loss: 4.9360 | Val Accuracy: 0.8259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 68.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/20 | Train Loss: 0.3633 | Val Loss: 4.8072 | Val Accuracy: 0.8287\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 73.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/20 | Train Loss: 0.3542 | Val Loss: 4.6937 | Val Accuracy: 0.8316\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 63.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/20 | Train Loss: 0.3465 | Val Loss: 4.5977 | Val Accuracy: 0.8334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 74.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/20 | Train Loss: 0.3403 | Val Loss: 4.5219 | Val Accuracy: 0.8371\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:00<00:00, 68.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/20 | Train Loss: 0.3351 | Val Loss: 4.4719 | Val Accuracy: 0.8389\n",
      "Edge metrics: tensor([0.2121, 0.2701, 0.1974, 0.2064, 0.3173, 0.3030, 0.4002, 0.2843, 0.3264,\n",
      "        0.1350, 0.3179, 0.4202, 0.2969, 0.4108, 0.2482, 0.2320, 0.1596, 0.1846,\n",
      "        0.1533, 0.2579, 0.2373, 0.2034, 0.2726, 0.3189, 0.3002, 0.1575, 0.3317,\n",
      "        0.3257, 0.3012, 0.2516, 0.3030, 0.1498, 0.2744, 0.1219, 0.2771, 0.2659,\n",
      "        0.2635, 0.6179, 0.2181, 0.2286, 0.2003, 0.3168, 0.1589, 0.2215, 0.3460,\n",
      "        0.2198, 0.4586, 0.2031, 0.1755, 0.3911, 0.3571, 0.3863, 0.3498, 0.1882,\n",
      "        0.6400, 0.4179, 0.3154, 0.2050, 0.2304, 0.2364, 0.3337, 0.3199, 0.3471,\n",
      "        0.3309, 0.1289, 0.2427, 0.2275, 0.1835, 0.2867, 0.2692, 0.3252, 0.1742,\n",
      "        0.1765, 0.2567, 0.1999, 0.3535, 0.1795, 0.3713, 0.1228, 0.2634, 0.3261,\n",
      "        0.1328, 0.3208, 0.2221, 0.2049, 0.3320, 0.2747, 0.1342, 0.2919, 0.2697,\n",
      "        0.2715, 0.1852, 0.2126, 0.2027, 0.3385, 0.1479, 0.1144, 0.1872, 0.3119,\n",
      "        0.2760, 0.2988, 0.2338, 0.3963, 0.2118, 0.2454, 0.3791, 0.2212, 0.1951,\n",
      "        0.3152, 0.2198, 0.1880, 0.0953, 0.3648, 0.2116, 0.2868, 0.2078, 0.2786,\n",
      "        0.2248, 0.2117, 0.1375, 0.2101, 0.2400, 0.1373, 0.1762, 0.2954, 0.4247,\n",
      "        0.3710, 0.2812, 0.2121, 0.2701, 0.1974, 0.2064, 0.3173, 0.3030, 0.4002,\n",
      "        0.2843, 0.3264, 0.1350, 0.3179, 0.4202, 0.2969, 0.4108, 0.2482, 0.2320,\n",
      "        0.1596, 0.1846, 0.1533, 0.2579, 0.2373, 0.2034, 0.2726, 0.3189, 0.3002,\n",
      "        0.1575, 0.3317, 0.3257, 0.3012, 0.2516, 0.3030, 0.1498, 0.2744, 0.1219,\n",
      "        0.2771, 0.2659, 0.2635, 0.6179, 0.2181, 0.2286, 0.2003, 0.3168, 0.1589,\n",
      "        0.2215, 0.3460, 0.2198, 0.4586, 0.2031, 0.1755, 0.3911, 0.3571, 0.3863,\n",
      "        0.3498, 0.1882, 0.6400, 0.4179, 0.3154, 0.2050, 0.2304, 0.2364, 0.3337,\n",
      "        0.3199, 0.3471, 0.3309, 0.1289, 0.2427, 0.2275, 0.1835, 0.2867, 0.2692,\n",
      "        0.3252, 0.1742, 0.1765, 0.2567, 0.1999, 0.3535, 0.1795, 0.3713, 0.1228,\n",
      "        0.2634, 0.3261, 0.1328, 0.3208, 0.2221, 0.2049, 0.3320, 0.2747, 0.1342,\n",
      "        0.2919, 0.2697, 0.2715, 0.1852, 0.2126, 0.2027, 0.3385, 0.1479, 0.1144,\n",
      "        0.1872, 0.3119, 0.2760, 0.2988, 0.2338, 0.3963, 0.2118, 0.2454, 0.3791,\n",
      "        0.2212, 0.1951, 0.3152, 0.2198, 0.1880, 0.0953, 0.3648, 0.2116, 0.2868,\n",
      "        0.2078, 0.2786, 0.2248, 0.2117, 0.1375, 0.2101, 0.2400, 0.1373, 0.1762,\n",
      "        0.2954, 0.4247, 0.3710, 0.2812]) tensor(0.6400) tensor(67.3639)\n",
      "Chosen edges: tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  0,   1,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,  14,  15,\n",
      "          19,  20,  21,  22,  23,  24,  26,  27,  28,  29,  30,  32,  34,  35,\n",
      "          36,  37,  38,  39,  40,  41,  43,  44,  45,  46,  47,  49,  50,  51,\n",
      "          52,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  65,  66,  68,\n",
      "          69,  70,  73,  75,  77,  79,  80,  82,  83,  84,  85,  86,  88,  89,\n",
      "          90,  92,  93,  94,  98,  99, 100, 101, 102, 103, 104, 105, 106, 108,\n",
      "         109, 112, 113, 114, 115, 116, 117, 118, 120, 121, 124, 125, 126, 127,\n",
      "           0,   1,   3,   4,   5,   6,   7,   8,  10,  11,  12,  13,  14,  15,\n",
      "          19,  20,  21,  22,  23,  24,  26,  27,  28,  29,  30,  32,  34,  35,\n",
      "          36,  37,  38,  39,  40,  41,  43,  44,  45,  46,  47,  49,  50,  51,\n",
      "          52,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  65,  66,  68,\n",
      "          69,  70,  73,  75,  77,  79,  80,  82,  83,  84,  85,  86,  88,  89,\n",
      "          90,  92,  93,  94,  98,  99, 100, 101, 102, 103, 104, 105, 106, 108,\n",
      "         109, 112, 113, 114, 115, 116, 117, 118, 120, 121, 124, 125, 126, 127]]) 196\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/51 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "addmm: index out of column bound: 14 not between 1 and 14",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[49], line 8\u001B[0m\n\u001B[0;32m      2\u001B[0m sparse_model \u001B[38;5;241m=\u001B[39m convert_dense_to_sparse_network(dense_model)\n\u001B[0;32m      3\u001B[0m wandb\u001B[38;5;241m.\u001B[39minit(\n\u001B[0;32m      4\u001B[0m     project\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mself-expanding-nets\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      5\u001B[0m     name\u001B[38;5;241m=\u001B[39m\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mminst, threshold\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m      6\u001B[0m )\n\u001B[1;32m----> 8\u001B[0m \u001B[43mtrain_sparse_recursive\u001B[49m\u001B[43m(\u001B[49m\u001B[43msparse_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mnum_epochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m20\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m      9\u001B[0m \u001B[43m                       \u001B[49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mmetrics\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m     10\u001B[0m \u001B[43m                       \u001B[49m\u001B[43medge_replacement_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_replacement_func_new_layer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[46], line 12\u001B[0m, in \u001B[0;36mtrain_sparse_recursive\u001B[1;34m(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func, window_size, threshold)\u001B[0m\n\u001B[0;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m inputs, targets \u001B[38;5;129;01min\u001B[39;00m tqdm(train_loader):\n\u001B[0;32m     11\u001B[0m     inputs, targets \u001B[38;5;241m=\u001B[39m inputs\u001B[38;5;241m.\u001B[39mto(device), targets\u001B[38;5;241m.\u001B[39mto(device)\n\u001B[1;32m---> 12\u001B[0m     outputs \u001B[38;5;241m=\u001B[39m \u001B[43mmodel\u001B[49m\u001B[43m(\u001B[49m\u001B[43minputs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     13\u001B[0m     loss \u001B[38;5;241m=\u001B[39m criterion(outputs, targets)\n\u001B[0;32m     15\u001B[0m     optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "Cell \u001B[1;32mIn[44], line 9\u001B[0m, in \u001B[0;36mSimpleFCN.forward\u001B[1;34m(self, x)\u001B[0m\n\u001B[0;32m      8\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, x):\n\u001B[1;32m----> 9\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfc1\u001B[49m\u001B[43m(\u001B[49m\u001B[43mx\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     10\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mrelu(x)\n\u001B[0;32m     11\u001B[0m     x \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfc2(x)\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\senmodel\\model\\model.py:95\u001B[0m, in \u001B[0;36mExpandingLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m embed_linear \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39membed_linears:\n\u001B[1;32m---> 95\u001B[0m         \u001B[38;5;28minput\u001B[39m \u001B[38;5;241m=\u001B[39m \u001B[43membed_linear\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[0;32m     97\u001B[0m     sparse_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_sparse_tensor()\n\u001B[0;32m     98\u001B[0m     sparse_bias \u001B[38;5;241m=\u001B[39m torch\u001B[38;5;241m.\u001B[39msparse_coo_tensor(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias_indices, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias_values, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mbias_size,\n\u001B[0;32m     99\u001B[0m                                           device\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdevice)\u001B[38;5;241m.\u001B[39mto_dense()\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1736\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1734\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1735\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1736\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1747\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1742\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1743\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1744\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1745\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1746\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1747\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1749\u001B[0m result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m   1750\u001B[0m called_always_called_hooks \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mset\u001B[39m()\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\senmodel\\model\\model.py:49\u001B[0m, in \u001B[0;36mEmbedLinear.forward\u001B[1;34m(self, input)\u001B[0m\n\u001B[0;32m     47\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, \u001B[38;5;28minput\u001B[39m):\n\u001B[0;32m     48\u001B[0m     sparse_embed_weight \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcreate_sparse_tensor()\n\u001B[1;32m---> 49\u001B[0m     output \u001B[38;5;241m=\u001B[39m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43msparse\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmm\u001B[49m\u001B[43m(\u001B[49m\u001B[43msparse_embed_weight\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43minput\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mt()\n\u001B[0;32m     50\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m torch\u001B[38;5;241m.\u001B[39mcat([\u001B[38;5;28minput\u001B[39m, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mactivation(output)], dim\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n",
      "\u001B[1;31mRuntimeError\u001B[0m: addmm: index out of column bound: 14 not between 1 and 14"
     ]
    }
   ],
   "execution_count": 49
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "533bf1b57447aa62"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
