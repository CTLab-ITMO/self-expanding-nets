{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Setup"
      ],
      "metadata": {
        "id": "6Qjs4JTOsGTG"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "LKB5vVirrtEQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "939e67f7-c207-4bd2-d0b2-9480bdc92329"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'self-expanding-nets'...\n",
            "remote: Enumerating objects: 551, done.\u001b[K\n",
            "remote: Counting objects: 100% (551/551), done.\u001b[K\n",
            "remote: Compressing objects: 100% (255/255), done.\u001b[K\n",
            "remote: Total 551 (delta 307), reused 523 (delta 280), pack-reused 0 (from 0)\u001b[K\n",
            "Receiving objects: 100% (551/551), 2.62 MiB | 5.95 MiB/s, done.\n",
            "Resolving deltas: 100% (307/307), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/CTLab-ITMO/self-expanding-nets -b freeze-layers"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U -e ./self-expanding-nets/ --force-reinstall"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "GsfRiMqosF-8",
        "outputId": "adc2c822-3329-4dd6-ae0f-68eb6ae34557"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Obtaining file:///content/self-expanding-nets\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Checking if build backend supports build_editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build editable ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing editable metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting torch (from senmodel==1.0.0)\n",
            "  Downloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl.metadata (28 kB)\n",
            "Collecting torchvision (from senmodel==1.0.0)\n",
            "  Downloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl.metadata (6.1 kB)\n",
            "Collecting pandas (from senmodel==1.0.0)\n",
            "  Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (89 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.9/89.9 kB\u001b[0m \u001b[31m1.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting scikit-learn (from senmodel==1.0.0)\n",
            "  Downloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (18 kB)\n",
            "Collecting tqdm (from senmodel==1.0.0)\n",
            "  Downloading tqdm-4.67.1-py3-none-any.whl.metadata (57 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.7/57.7 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting wandb (from senmodel==1.0.0)\n",
            "  Downloading wandb-0.19.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting numpy>=1.23.2 (from pandas->senmodel==1.0.0)\n",
            "  Downloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting python-dateutil>=2.8.2 (from pandas->senmodel==1.0.0)\n",
            "  Downloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl.metadata (8.4 kB)\n",
            "Collecting pytz>=2020.1 (from pandas->senmodel==1.0.0)\n",
            "  Downloading pytz-2025.1-py2.py3-none-any.whl.metadata (22 kB)\n",
            "Collecting tzdata>=2022.7 (from pandas->senmodel==1.0.0)\n",
            "  Downloading tzdata-2025.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
            "Collecting scipy>=1.6.0 (from scikit-learn->senmodel==1.0.0)\n",
            "  Downloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (61 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn->senmodel==1.0.0)\n",
            "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
            "Collecting threadpoolctl>=3.1.0 (from scikit-learn->senmodel==1.0.0)\n",
            "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting filelock (from torch->senmodel==1.0.0)\n",
            "  Downloading filelock-3.17.0-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting typing-extensions>=4.10.0 (from torch->senmodel==1.0.0)\n",
            "  Downloading typing_extensions-4.12.2-py3-none-any.whl.metadata (3.0 kB)\n",
            "Collecting networkx (from torch->senmodel==1.0.0)\n",
            "  Downloading networkx-3.4.2-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting jinja2 (from torch->senmodel==1.0.0)\n",
            "  Downloading jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
            "Collecting fsspec (from torch->senmodel==1.0.0)\n",
            "  Downloading fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparselt-cu12==0.6.2 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl.metadata (6.8 kB)\n",
            "Collecting nvidia-nccl-cu12==2.21.5 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
            "Collecting nvidia-nvtx-cu12==12.4.127 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch->senmodel==1.0.0)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting triton==3.2.0 (from torch->senmodel==1.0.0)\n",
            "  Downloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.4 kB)\n",
            "Collecting sympy==1.13.1 (from torch->senmodel==1.0.0)\n",
            "  Downloading sympy-1.13.1-py3-none-any.whl.metadata (12 kB)\n",
            "Collecting mpmath<1.4,>=1.1.0 (from sympy==1.13.1->torch->senmodel==1.0.0)\n",
            "  Downloading mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
            "Collecting pillow!=8.3.*,>=5.3.0 (from torchvision->senmodel==1.0.0)\n",
            "  Downloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl.metadata (9.1 kB)\n",
            "Collecting click!=8.0.0,>=7.1 (from wandb->senmodel==1.0.0)\n",
            "  Downloading click-8.1.8-py3-none-any.whl.metadata (2.3 kB)\n",
            "Collecting docker-pycreds>=0.4.0 (from wandb->senmodel==1.0.0)\n",
            "  Downloading docker_pycreds-0.4.0-py2.py3-none-any.whl.metadata (1.8 kB)\n",
            "Collecting gitpython!=3.1.29,>=1.0.0 (from wandb->senmodel==1.0.0)\n",
            "  Downloading GitPython-3.1.44-py3-none-any.whl.metadata (13 kB)\n",
            "Collecting platformdirs (from wandb->senmodel==1.0.0)\n",
            "  Downloading platformdirs-4.3.6-py3-none-any.whl.metadata (11 kB)\n",
            "Collecting protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 (from wandb->senmodel==1.0.0)\n",
            "  Downloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl.metadata (592 bytes)\n",
            "Collecting psutil>=5.0.0 (from wandb->senmodel==1.0.0)\n",
            "  Downloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (22 kB)\n",
            "Collecting pydantic<3,>=2.6 (from wandb->senmodel==1.0.0)\n",
            "  Downloading pydantic-2.10.6-py3-none-any.whl.metadata (30 kB)\n",
            "Collecting pyyaml (from wandb->senmodel==1.0.0)\n",
            "  Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.1 kB)\n",
            "Collecting requests<3,>=2.0.0 (from wandb->senmodel==1.0.0)\n",
            "  Downloading requests-2.32.3-py3-none-any.whl.metadata (4.6 kB)\n",
            "Collecting sentry-sdk>=2.0.0 (from wandb->senmodel==1.0.0)\n",
            "  Downloading sentry_sdk-2.22.0-py2.py3-none-any.whl.metadata (10 kB)\n",
            "Collecting setproctitle (from wandb->senmodel==1.0.0)\n",
            "  Downloading setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (10 kB)\n",
            "Collecting setuptools (from wandb->senmodel==1.0.0)\n",
            "  Using cached setuptools-76.0.0-py3-none-any.whl.metadata (6.7 kB)\n",
            "Collecting six>=1.4.0 (from docker-pycreds>=0.4.0->wandb->senmodel==1.0.0)\n",
            "  Downloading six-1.17.0-py2.py3-none-any.whl.metadata (1.7 kB)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.29,>=1.0.0->wandb->senmodel==1.0.0)\n",
            "  Downloading gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
            "Collecting annotated-types>=0.6.0 (from pydantic<3,>=2.6->wandb->senmodel==1.0.0)\n",
            "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
            "Collecting pydantic-core==2.27.2 (from pydantic<3,>=2.6->wandb->senmodel==1.0.0)\n",
            "  Downloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
            "Collecting charset-normalizer<4,>=2 (from requests<3,>=2.0.0->wandb->senmodel==1.0.0)\n",
            "  Downloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (35 kB)\n",
            "Collecting idna<4,>=2.5 (from requests<3,>=2.0.0->wandb->senmodel==1.0.0)\n",
            "  Downloading idna-3.10-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting urllib3<3,>=1.21.1 (from requests<3,>=2.0.0->wandb->senmodel==1.0.0)\n",
            "  Downloading urllib3-2.3.0-py3-none-any.whl.metadata (6.5 kB)\n",
            "Collecting certifi>=2017.4.17 (from requests<3,>=2.0.0->wandb->senmodel==1.0.0)\n",
            "  Downloading certifi-2025.1.31-py3-none-any.whl.metadata (2.5 kB)\n",
            "Collecting MarkupSafe>=2.0 (from jinja2->torch->senmodel==1.0.0)\n",
            "  Downloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.0 kB)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb->senmodel==1.0.0)\n",
            "  Downloading smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
            "Downloading pandas-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.1/13.1 MB\u001b[0m \u001b[31m64.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scikit_learn-1.6.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.5/13.5 MB\u001b[0m \u001b[31m67.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torch-2.6.0-cp311-cp311-manylinux1_x86_64.whl (766.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m766.7/766.7 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m77.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m54.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m11.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparselt_cu12-0.6.2-py3-none-manylinux2014_x86_64.whl (150.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m150.1/150.1 MB\u001b[0m \u001b[31m6.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nccl_cu12-2.21.5-py3-none-manylinux2014_x86_64.whl (188.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m188.7/188.7 MB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m75.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvtx_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (99 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m99.1/99.1 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sympy-1.13.1-py3-none-any.whl (6.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.2/6.2 MB\u001b[0m \u001b[31m83.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading triton-3.2.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (253.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m253.2/253.2 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchvision-0.21.0-cp311-cp311-manylinux1_x86_64.whl (7.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m98.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tqdm-4.67.1-py3-none-any.whl (78 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m78.5/78.5 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading wandb-0.19.8-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (20.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.8/20.8 MB\u001b[0m \u001b[31m82.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading click-8.1.8-py3-none-any.whl (98 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.2/98.2 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading docker_pycreds-0.4.0-py2.py3-none-any.whl (9.0 kB)\n",
            "Downloading GitPython-3.1.44-py3-none-any.whl (207 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.6/207.6 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m90.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pillow-11.1.0-cp311-cp311-manylinux_2_28_x86_64.whl (4.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m92.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading protobuf-5.29.3-cp38-abi3-manylinux2014_x86_64.whl (319 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m319.7/319.7 kB\u001b[0m \u001b[31m27.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading psutil-7.0.0-cp36-abi3-manylinux_2_12_x86_64.manylinux2010_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (277 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m278.0/278.0 kB\u001b[0m \u001b[31m24.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic-2.10.6-py3-none-any.whl (431 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m431.7/431.7 kB\u001b[0m \u001b[31m32.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pydantic_core-2.27.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m73.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading python_dateutil-2.9.0.post0-py2.py3-none-any.whl (229 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m229.9/229.9 kB\u001b[0m \u001b[31m21.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pytz-2025.1-py2.py3-none-any.whl (507 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m507.9/507.9 kB\u001b[0m \u001b[31m35.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading requests-2.32.3-py3-none-any.whl (64 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m64.9/64.9 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading scipy-1.15.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (37.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.6/37.6 MB\u001b[0m \u001b[31m16.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading sentry_sdk-2.22.0-py2.py3-none-any.whl (325 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m325.8/325.8 kB\u001b[0m \u001b[31m26.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
            "Downloading typing_extensions-4.12.2-py3-none-any.whl (37 kB)\n",
            "Downloading tzdata-2025.1-py2.py3-none-any.whl (346 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m346.8/346.8 kB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading filelock-3.17.0-py3-none-any.whl (16 kB)\n",
            "Downloading fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m193.6/193.6 kB\u001b[0m \u001b[31m17.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.9/134.9 kB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading networkx-3.4.2-py3-none-any.whl (1.7 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m71.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading platformdirs-4.3.6-py3-none-any.whl (18 kB)\n",
            "Downloading PyYAML-6.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (762 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m763.0/763.0 kB\u001b[0m \u001b[31m51.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading setproctitle-1.3.5-cp311-cp311-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (31 kB)\n",
            "Using cached setuptools-76.0.0-py3-none-any.whl (1.2 MB)\n",
            "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
            "Downloading certifi-2025.1.31-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.4/166.4 kB\u001b[0m \u001b[31m15.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading charset_normalizer-3.4.1-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.9/143.9 kB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.8/62.8 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading idna-3.10-py3-none-any.whl (70 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m70.4/70.4 kB\u001b[0m \u001b[31m6.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading MarkupSafe-3.0.2-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (23 kB)\n",
            "Downloading mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m536.2/536.2 kB\u001b[0m \u001b[31m40.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading six-1.17.0-py2.py3-none-any.whl (11 kB)\n",
            "Downloading urllib3-2.3.0-py3-none-any.whl (128 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m128.4/128.4 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading smmap-5.0.2-py3-none-any.whl (24 kB)\n",
            "Building wheels for collected packages: senmodel\n",
            "  Building editable for senmodel (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for senmodel: filename=senmodel-1.0.0-0.editable-py3-none-any.whl size=2898 sha256=39993ebd080bec246d214c300b04dd8eaa5ca90b6f57f84e4bff1743027acc87\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-uj4v6a3s/wheels/05/37/83/60ae64e47ec8e068894939349d8f7a54d05e0200ded6473a79\n",
            "Successfully built senmodel\n",
            "Installing collected packages: triton, pytz, nvidia-cusparselt-cu12, mpmath, urllib3, tzdata, typing-extensions, tqdm, threadpoolctl, sympy, smmap, six, setuptools, setproctitle, pyyaml, psutil, protobuf, platformdirs, pillow, nvidia-nvtx-cu12, nvidia-nvjitlink-cu12, nvidia-nccl-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, numpy, networkx, MarkupSafe, joblib, idna, fsspec, filelock, click, charset-normalizer, certifi, annotated-types, sentry-sdk, scipy, requests, python-dateutil, pydantic-core, nvidia-cusparse-cu12, nvidia-cudnn-cu12, jinja2, gitdb, docker-pycreds, scikit-learn, pydantic, pandas, nvidia-cusolver-cu12, gitpython, wandb, torch, torchvision, senmodel\n",
            "  Attempting uninstall: triton\n",
            "    Found existing installation: triton 3.1.0\n",
            "    Uninstalling triton-3.1.0:\n",
            "      Successfully uninstalled triton-3.1.0\n",
            "  Attempting uninstall: pytz\n",
            "    Found existing installation: pytz 2025.1\n",
            "    Uninstalling pytz-2025.1:\n",
            "      Successfully uninstalled pytz-2025.1\n",
            "  Attempting uninstall: mpmath\n",
            "    Found existing installation: mpmath 1.3.0\n",
            "    Uninstalling mpmath-1.3.0:\n",
            "      Successfully uninstalled mpmath-1.3.0\n",
            "  Attempting uninstall: urllib3\n",
            "    Found existing installation: urllib3 2.3.0\n",
            "    Uninstalling urllib3-2.3.0:\n",
            "      Successfully uninstalled urllib3-2.3.0\n",
            "  Attempting uninstall: tzdata\n",
            "    Found existing installation: tzdata 2025.1\n",
            "    Uninstalling tzdata-2025.1:\n",
            "      Successfully uninstalled tzdata-2025.1\n",
            "  Attempting uninstall: typing-extensions\n",
            "    Found existing installation: typing_extensions 4.12.2\n",
            "    Uninstalling typing_extensions-4.12.2:\n",
            "      Successfully uninstalled typing_extensions-4.12.2\n",
            "  Attempting uninstall: tqdm\n",
            "    Found existing installation: tqdm 4.67.1\n",
            "    Uninstalling tqdm-4.67.1:\n",
            "      Successfully uninstalled tqdm-4.67.1\n",
            "  Attempting uninstall: threadpoolctl\n",
            "    Found existing installation: threadpoolctl 3.5.0\n",
            "    Uninstalling threadpoolctl-3.5.0:\n",
            "      Successfully uninstalled threadpoolctl-3.5.0\n",
            "  Attempting uninstall: sympy\n",
            "    Found existing installation: sympy 1.13.1\n",
            "    Uninstalling sympy-1.13.1:\n",
            "      Successfully uninstalled sympy-1.13.1\n",
            "  Attempting uninstall: smmap\n",
            "    Found existing installation: smmap 5.0.2\n",
            "    Uninstalling smmap-5.0.2:\n",
            "      Successfully uninstalled smmap-5.0.2\n",
            "  Attempting uninstall: six\n",
            "    Found existing installation: six 1.17.0\n",
            "    Uninstalling six-1.17.0:\n",
            "      Successfully uninstalled six-1.17.0\n",
            "  Attempting uninstall: setuptools\n",
            "    Found existing installation: setuptools 75.1.0\n",
            "    Uninstalling setuptools-75.1.0:\n",
            "      Successfully uninstalled setuptools-75.1.0\n",
            "  Attempting uninstall: setproctitle\n",
            "    Found existing installation: setproctitle 1.3.5\n",
            "    Uninstalling setproctitle-1.3.5:\n",
            "      Successfully uninstalled setproctitle-1.3.5\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 6.0.2\n",
            "    Uninstalling PyYAML-6.0.2:\n",
            "      Successfully uninstalled PyYAML-6.0.2\n",
            "  Attempting uninstall: psutil\n",
            "    Found existing installation: psutil 5.9.5\n",
            "    Uninstalling psutil-5.9.5:\n",
            "      Successfully uninstalled psutil-5.9.5\n",
            "  Attempting uninstall: protobuf\n",
            "    Found existing installation: protobuf 4.25.6\n",
            "    Uninstalling protobuf-4.25.6:\n",
            "      Successfully uninstalled protobuf-4.25.6\n",
            "  Attempting uninstall: platformdirs\n",
            "    Found existing installation: platformdirs 4.3.6\n",
            "    Uninstalling platformdirs-4.3.6:\n",
            "      Successfully uninstalled platformdirs-4.3.6\n",
            "  Attempting uninstall: pillow\n",
            "    Found existing installation: pillow 11.1.0\n",
            "    Uninstalling pillow-11.1.0:\n",
            "      Successfully uninstalled pillow-11.1.0\n",
            "  Attempting uninstall: nvidia-nvtx-cu12\n",
            "    Found existing installation: nvidia-nvtx-cu12 12.4.127\n",
            "    Uninstalling nvidia-nvtx-cu12-12.4.127:\n",
            "      Successfully uninstalled nvidia-nvtx-cu12-12.4.127\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-nccl-cu12\n",
            "    Found existing installation: nvidia-nccl-cu12 2.21.5\n",
            "    Uninstalling nvidia-nccl-cu12-2.21.5:\n",
            "      Successfully uninstalled nvidia-nccl-cu12-2.21.5\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "  Attempting uninstall: networkx\n",
            "    Found existing installation: networkx 3.4.2\n",
            "    Uninstalling networkx-3.4.2:\n",
            "      Successfully uninstalled networkx-3.4.2\n",
            "  Attempting uninstall: MarkupSafe\n",
            "    Found existing installation: MarkupSafe 3.0.2\n",
            "    Uninstalling MarkupSafe-3.0.2:\n",
            "      Successfully uninstalled MarkupSafe-3.0.2\n",
            "  Attempting uninstall: joblib\n",
            "    Found existing installation: joblib 1.4.2\n",
            "    Uninstalling joblib-1.4.2:\n",
            "      Successfully uninstalled joblib-1.4.2\n",
            "  Attempting uninstall: idna\n",
            "    Found existing installation: idna 3.10\n",
            "    Uninstalling idna-3.10:\n",
            "      Successfully uninstalled idna-3.10\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2024.10.0\n",
            "    Uninstalling fsspec-2024.10.0:\n",
            "      Successfully uninstalled fsspec-2024.10.0\n",
            "  Attempting uninstall: filelock\n",
            "    Found existing installation: filelock 3.17.0\n",
            "    Uninstalling filelock-3.17.0:\n",
            "      Successfully uninstalled filelock-3.17.0\n",
            "  Attempting uninstall: click\n",
            "    Found existing installation: click 8.1.8\n",
            "    Uninstalling click-8.1.8:\n",
            "      Successfully uninstalled click-8.1.8\n",
            "  Attempting uninstall: charset-normalizer\n",
            "    Found existing installation: charset-normalizer 3.4.1\n",
            "    Uninstalling charset-normalizer-3.4.1:\n",
            "      Successfully uninstalled charset-normalizer-3.4.1\n",
            "  Attempting uninstall: certifi\n",
            "    Found existing installation: certifi 2025.1.31\n",
            "    Uninstalling certifi-2025.1.31:\n",
            "      Successfully uninstalled certifi-2025.1.31\n",
            "  Attempting uninstall: annotated-types\n",
            "    Found existing installation: annotated-types 0.7.0\n",
            "    Uninstalling annotated-types-0.7.0:\n",
            "      Successfully uninstalled annotated-types-0.7.0\n",
            "  Attempting uninstall: sentry-sdk\n",
            "    Found existing installation: sentry-sdk 2.22.0\n",
            "    Uninstalling sentry-sdk-2.22.0:\n",
            "      Successfully uninstalled sentry-sdk-2.22.0\n",
            "  Attempting uninstall: scipy\n",
            "    Found existing installation: scipy 1.13.1\n",
            "    Uninstalling scipy-1.13.1:\n",
            "      Successfully uninstalled scipy-1.13.1\n",
            "  Attempting uninstall: requests\n",
            "    Found existing installation: requests 2.32.3\n",
            "    Uninstalling requests-2.32.3:\n",
            "      Successfully uninstalled requests-2.32.3\n",
            "  Attempting uninstall: python-dateutil\n",
            "    Found existing installation: python-dateutil 2.8.2\n",
            "    Uninstalling python-dateutil-2.8.2:\n",
            "      Successfully uninstalled python-dateutil-2.8.2\n",
            "  Attempting uninstall: pydantic-core\n",
            "    Found existing installation: pydantic_core 2.27.2\n",
            "    Uninstalling pydantic_core-2.27.2:\n",
            "      Successfully uninstalled pydantic_core-2.27.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: jinja2\n",
            "    Found existing installation: Jinja2 3.1.6\n",
            "    Uninstalling Jinja2-3.1.6:\n",
            "      Successfully uninstalled Jinja2-3.1.6\n",
            "  Attempting uninstall: gitdb\n",
            "    Found existing installation: gitdb 4.0.12\n",
            "    Uninstalling gitdb-4.0.12:\n",
            "      Successfully uninstalled gitdb-4.0.12\n",
            "  Attempting uninstall: docker-pycreds\n",
            "    Found existing installation: docker-pycreds 0.4.0\n",
            "    Uninstalling docker-pycreds-0.4.0:\n",
            "      Successfully uninstalled docker-pycreds-0.4.0\n",
            "  Attempting uninstall: scikit-learn\n",
            "    Found existing installation: scikit-learn 1.6.1\n",
            "    Uninstalling scikit-learn-1.6.1:\n",
            "      Successfully uninstalled scikit-learn-1.6.1\n",
            "  Attempting uninstall: pydantic\n",
            "    Found existing installation: pydantic 2.10.6\n",
            "    Uninstalling pydantic-2.10.6:\n",
            "      Successfully uninstalled pydantic-2.10.6\n",
            "  Attempting uninstall: pandas\n",
            "    Found existing installation: pandas 2.2.2\n",
            "    Uninstalling pandas-2.2.2:\n",
            "      Successfully uninstalled pandas-2.2.2\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "  Attempting uninstall: gitpython\n",
            "    Found existing installation: GitPython 3.1.44\n",
            "    Uninstalling GitPython-3.1.44:\n",
            "      Successfully uninstalled GitPython-3.1.44\n",
            "  Attempting uninstall: wandb\n",
            "    Found existing installation: wandb 0.19.8\n",
            "    Uninstalling wandb-0.19.8:\n",
            "      Successfully uninstalled wandb-0.19.8\n",
            "  Attempting uninstall: torch\n",
            "    Found existing installation: torch 2.5.1+cu124\n",
            "    Uninstalling torch-2.5.1+cu124:\n",
            "      Successfully uninstalled torch-2.5.1+cu124\n",
            "  Attempting uninstall: torchvision\n",
            "    Found existing installation: torchvision 0.20.1+cu124\n",
            "    Uninstalling torchvision-0.20.1+cu124:\n",
            "      Successfully uninstalled torchvision-0.20.1+cu124\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "ipython 7.34.0 requires jedi>=0.16, which is not installed.\n",
            "google-colab 1.0.0 requires pandas==2.2.2, but you have pandas 2.2.3 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.3 which is incompatible.\n",
            "gcsfs 2024.10.0 requires fsspec==2024.10.0, but you have fsspec 2025.3.0 which is incompatible.\n",
            "pytensor 2.27.1 requires numpy<2,>=1.17.0, but you have numpy 2.2.3 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.3 which is incompatible.\n",
            "torchaudio 2.5.1+cu124 requires torch==2.5.1, but you have torch 2.6.0 which is incompatible.\n",
            "gensim 4.3.3 requires numpy<2.0,>=1.18.5, but you have numpy 2.2.3 which is incompatible.\n",
            "gensim 4.3.3 requires scipy<1.14.0,>=1.7.0, but you have scipy 1.15.2 which is incompatible.\n",
            "thinc 8.2.5 requires numpy<2.0.0,>=1.19.0; python_version >= \"3.9\", but you have numpy 2.2.3 which is incompatible.\n",
            "fastai 2.7.18 requires torch<2.6,>=1.10, but you have torch 2.6.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed MarkupSafe-3.0.2 annotated-types-0.7.0 certifi-2025.1.31 charset-normalizer-3.4.1 click-8.1.8 docker-pycreds-0.4.0 filelock-3.17.0 fsspec-2025.3.0 gitdb-4.0.12 gitpython-3.1.44 idna-3.10 jinja2-3.1.6 joblib-1.4.2 mpmath-1.3.0 networkx-3.4.2 numpy-2.2.3 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-cusparselt-cu12-0.6.2 nvidia-nccl-cu12-2.21.5 nvidia-nvjitlink-cu12-12.4.127 nvidia-nvtx-cu12-12.4.127 pandas-2.2.3 pillow-11.1.0 platformdirs-4.3.6 protobuf-5.29.3 psutil-7.0.0 pydantic-2.10.6 pydantic-core-2.27.2 python-dateutil-2.9.0.post0 pytz-2025.1 pyyaml-6.0.2 requests-2.32.3 scikit-learn-1.6.1 scipy-1.15.2 senmodel-1.0.0 sentry-sdk-2.22.0 setproctitle-1.3.5 setuptools-76.0.0 six-1.17.0 smmap-5.0.2 sympy-1.13.1 threadpoolctl-3.5.0 torch-2.6.0 torchvision-0.21.0 tqdm-4.67.1 triton-3.2.0 typing-extensions-4.12.2 tzdata-2025.1 urllib3-2.3.0 wandb-0.19.8\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "PIL",
                  "_distutils_hack",
                  "certifi",
                  "dateutil",
                  "psutil",
                  "six"
                ]
              },
              "id": "4c68d1b6209d4ee79c2ddc9957762d1a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "cyQKwB0wtoOg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import datasets, transforms\n",
        "import torch.optim as optim\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from senmodel.model.utils import convert_dense_to_sparse_network, get_model_last_layer\n",
        "from senmodel.metrics.edge_finder import EdgeFinder\n",
        "from senmodel.model.utils import freeze_all_but_last, freeze_only_last\n",
        "from senmodel.metrics.nonlinearity_metrics import *\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n",
        "SEED = 8642\n",
        "\n",
        "np.random.seed(SEED)\n",
        "torch.manual_seed(SEED)\n",
        "torch.cuda.manual_seed(SEED)\n",
        "\n",
        "device = 'cpu' #torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "sfNCXfaAsKM6",
        "outputId": "1acdb98e-828b-49fc-b662-46ca03dd1c89"
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cpu'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "UxwP-4uVt07U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Lambda(lambda x: x.view(-1)),\n",
        "     ]\n",
        ")\n",
        "\n",
        "train_dataset = datasets.FashionMNIST(root='./data', train=True,\n",
        "                                      download=True, transform=transform)\n",
        "val_dataset = datasets.FashionMNIST(root='./data', train=False,\n",
        "                                    download=True, transform=transform)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)"
      ],
      "metadata": {
        "id": "es065tPYtyT2"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "8cOTVsM0uIcv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def freeze_model(model, num_trainable_layers: int = 1):\n",
        "    for i in range(len(list(model.children())) - num_trainable_layers):\n",
        "        for param in list(model.children())[i].parameters():\n",
        "            param.requires_grad = False\n",
        "\n",
        "\n",
        "def print_layer_status(model):\n",
        "    for name, param in model.named_parameters():\n",
        "        print(f\"Layer: {name}, frozen: {not param.requires_grad}\")"
      ],
      "metadata": {
        "id": "SklE5_IxxrO5"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# class ExpandingHead(nn.Module):\n",
        "#     def __init__(self, input_size: int = 64, hidden_size: int = 50, output_size: int = 10):\n",
        "#         super().__init__()\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "#         self.dropout = nn.Dropout(p=0.5)\n",
        "#         self.fc2 = nn.Linear(hidden_size, output_size)\n",
        "#         # self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.relu(self.fc1(x))\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.fc2(x)\n",
        "#         # x = self.relu(self.fc2(x))\n",
        "#         # x = self.dropout(x)\n",
        "#         # x = self.fc3(x)\n",
        "#         return x\n",
        "\n",
        "# class ResnetExp(nn.Module):\n",
        "#     def __init__(self, freeze_base: bool = False, device=torch.device('cpu')):\n",
        "#         super().__init__()\n",
        "#         self.base_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\",\n",
        "#                                          \"cifar10_resnet20\", pretrained=True)\n",
        "#         self.base_model = torch.nn.Sequential(\n",
        "#             *(list(self.base_model.children())[:-1])\n",
        "#         ).to(device)\n",
        "#         self.expanding_head = convert_dense_to_sparse_network(\n",
        "#             ExpandingHead(input_size=64,\n",
        "#                           # hidden_size=50,\n",
        "#                           output_size=10).to(device),\n",
        "#             device=device\n",
        "#         )\n",
        "#         if freeze_base:\n",
        "#             freeze_model(self.base_model)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.base_model(x)\n",
        "#         x = x.view(x.size(0), -1)\n",
        "#         x = self.expanding_head(x)\n",
        "#         return x"
      ],
      "metadata": {
        "id": "8IJ-2uwWvXud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleFCN(nn.Module):\n",
        "    def __init__(self, input_size=100, hidden_size: int = 100, leak_coef: float = 0.2):\n",
        "        super(SimpleFCN, self).__init__()\n",
        "        self.relu = nn.LeakyReLU(leak_coef) # nn.ReLU()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, 10)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "cVfiYexCuJgt"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "device"
      ],
      "metadata": {
        "id": "dQzHwmrZ_TAh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5c4eff36-445f-4a66-8fdb-9288fa67481b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset[0][0].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iQZPGA3xGB-E",
        "outputId": "c66218a8-60cb-4b8f-e307-52a1b8b50cda"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([1, 28, 28])"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = SimpleFCN(input_size=784).to(device)\n",
        "input_tensor = torch.randn(1, 784).to(device)\n",
        "output = model(input_tensor)\n",
        "output"
      ],
      "metadata": {
        "id": "07rOjU-F9PTY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc6f5235-97f8-4b13-a289-f5b778b72724"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.1510, -0.0659,  0.4219,  0.1664,  0.0037,  0.0008, -0.1808,  0.1891,\n",
              "         -0.2884,  0.1506]], device='cuda:0', grad_fn=<AddmmBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train loop"
      ],
      "metadata": {
        "id": "tq2yPOzdwdFm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def edge_replacement_func_new_layer(model, optim, val_loader, metric, choose_threshold, aggregation_mode='mean', len_choose=None):\n",
        "    layer = get_model_last_layer(model)\n",
        "    ef = EdgeFinder(metric, val_loader, device, aggregation_mode)\n",
        "\n",
        "    vals = ef.calculate_edge_metric_for_dataloader(model, len_choose, False)\n",
        "    print(\"Edge metrics:\", vals, max(vals, default=0), sum(vals))\n",
        "\n",
        "    chosen_edges = ef.choose_edges_threshold(model, choose_threshold, len_choose)\n",
        "    print(\"Chosen edges:\", chosen_edges, len(chosen_edges[0]))\n",
        "\n",
        "    layer.replace_many(*chosen_edges)\n",
        "\n",
        "    if len(chosen_edges[0]) > 0:\n",
        "        optim.add_param_group({'params': layer.embed_linears[-1].weight_values})\n",
        "    else:\n",
        "        print(\"Empty metric\")\n",
        "\n",
        "    return {'max': max(vals, default=0), 'sum': sum(vals), 'len': len(vals), 'len_choose': layer.count_replaces[-1]}"
      ],
      "metadata": {
        "id": "L80TSI2Uvy_j"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func=None,\n",
        "                           window_size=3, threshold=0.1, lr=5e-4, choose_threshold=0.3, aggregation_mode='mean', replace_all_epochs=3):\n",
        "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    val_losses = []\n",
        "    print(f'Device: {device}')\n",
        "    model = model.to(device)\n",
        "\n",
        "    len_choose = get_model_last_layer(model).count_replaces\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "\n",
        "        for i, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "\n",
        "            if len(len_choose) > replace_all_epochs and i > window_size:\n",
        "                freeze_all_but_last(model)\n",
        "\n",
        "            optimizer.step()\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_preds = []\n",
        "        all_targets = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = accuracy_score(all_targets, all_preds)\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} | \"\n",
        "              f\"Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
        "\n",
        "        new_l = dict()\n",
        "\n",
        "        val_losses.append(val_loss)\n",
        "        # print(edge_replacement_func)\n",
        "        # print(len(val_losses), val_losses, window_size)\n",
        "        if edge_replacement_func and len(val_losses) > window_size:\n",
        "            print(\"checking if edge replacement is needed\")\n",
        "            recent_changes = [abs(val_losses[i] - val_losses[i - 1]) for i in range(-window_size, 0)]\n",
        "            print(f\"{recent_changes}\")\n",
        "            avg_change = sum(recent_changes) / window_size\n",
        "            print(f\"avg_change = {avg_change}, threshold = {threshold}, win_size = {window_size}\")\n",
        "            if avg_change < threshold:\n",
        "                print(f\"{len_choose=}\")\n",
        "                len_ch = len_choose[-1] if len(len_choose) > replace_all_epochs else None\n",
        "                new_l = edge_replacement_func(model, optimizer, val_loader, metric, choose_threshold, aggregation_mode, len_ch)\n",
        "                # Замораживаем все слои кроме последнего\n",
        "                val_losses = []\n",
        "                len_choose = get_model_last_layer(model).count_replaces\n",
        "\n",
        "        wandb.log({'val_loss': val_loss, 'val_accuracy': val_accuracy, 'train_loss': train_loss} | new_l)"
      ],
      "metadata": {
        "id": "pMrBd8Umv22S"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "RpHs7JvEtwBd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "metrics = [\n",
        "    MagnitudeL2Metric(criterion),\n",
        "    SNIPMetric(criterion),\n",
        "    # GradientMeanEdgeMetric(criterion),\n",
        "    PerturbationSensitivityEdgeMetric(criterion),\n",
        "]\n",
        "\n",
        "hyperparams = {\"num_epochs\": 50,\n",
        "               \"metric\": metrics[0],\n",
        "               \"aggregation_mode\": \"mean\",\n",
        "               \"choose_threshold\": 0.05,\n",
        "               \"window_size\": 3,\n",
        "               \"threshold\": 0.05,\n",
        "               \"lr\": 5e-4,\n",
        "               \"replace_all_epochs\": 3\n",
        "               }"
      ],
      "metadata": {
        "id": "9NGAd8SfI6Zq"
      },
      "execution_count": 59,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sparse_model = convert_dense_to_sparse_network(SimpleFCN(784).to(device)).to(device)\n",
        "print_layer_status(sparse_model)"
      ],
      "metadata": {
        "id": "ZOOv4rrXxS3R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0fd4d6ca-e3cc-4546-afcf-025b0232b609"
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Layer: fc1.weight, frozen: False\n",
            "Layer: fc1.bias, frozen: False\n",
            "Layer: fc2.weight, frozen: False\n",
            "Layer: fc2.bias, frozen: False\n",
            "Layer: fc3.weight_values, frozen: False\n",
            "Layer: fc3.bias_values, frozen: False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project=\"self-expanding-nets\",\n",
        "    name=\"fashionmnist test\"\n",
        ")"
      ],
      "metadata": {
        "id": "Vt-XM-p0tTUV",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "40442457-55f6-4c02-9b09-f164a01af0a2"
      },
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.8"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250310_174403-92fjb3ls</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/down-shift/self-expanding-nets/runs/92fjb3ls' target=\"_blank\">fashionmnist test</a></strong> to <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/down-shift/self-expanding-nets/runs/92fjb3ls' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets/runs/92fjb3ls</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/down-shift/self-expanding-nets/runs/92fjb3ls?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7b848ba54a10>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for name, param in sparse_model.named_parameters():\n",
        "    print(f\"{name}: {'cuda' if param.is_cuda else 'cpu'}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "blebKFl-HJKS",
        "outputId": "d903553e-eeb0-485a-b3d2-2d3e1624f087"
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fc1.weight: cpu\n",
            "fc1.bias: cpu\n",
            "fc2.weight: cpu\n",
            "fc2.bias: cpu\n",
            "fc3.weight_values: cpu\n",
            "fc3.bias_values: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_sparse_recursive(sparse_model, train_loader, val_loader,\n",
        "                       edge_replacement_func=edge_replacement_func_new_layer,\n",
        "                       **hyperparams)"
      ],
      "metadata": {
        "id": "1ibCIcSpuDqw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "811978c4-36ad-47a4-ffaf-9b0e0117038f"
      },
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Device: cpu\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:09<00:00, 99.62it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50 | Train Loss: 0.8413 | Val Loss: 0.5213 | Val Accuracy: 0.8139\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:09<00:00, 102.98it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 2/50 | Train Loss: 0.5448 | Val Loss: 0.4570 | Val Accuracy: 0.8356\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:09<00:00, 95.62it/s] \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 3/50 | Train Loss: 0.4922 | Val Loss: 0.4322 | Val Accuracy: 0.8427\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:09<00:00, 94.39it/s] \n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 4/50 | Train Loss: 0.4650 | Val Loss: 0.4276 | Val Accuracy: 0.8450\n",
            "checking if edge replacement is needed\n",
            "[0.06431364937193074, 0.024827098960329752, 0.004640457356811345]\n",
            "avg_change = 0.03126040189635728, threshold = 0.05, win_size = 3\n",
            "len_choose=[1000]\n",
            "Edge metrics: tensor([5.7624e-03, 6.6672e-06, 2.6994e-03, 6.6084e-03, 1.3106e-03, 6.1276e-03,\n",
            "        1.2724e-02, 2.5343e-02, 9.4980e-05, 1.7219e-03, 1.3006e-03, 1.9543e-02,\n",
            "        7.0829e-03, 1.4500e-02, 1.6109e-03, 3.7938e-03, 5.7729e-03, 6.1964e-03,\n",
            "        5.1851e-03, 1.3483e-03, 1.5991e-02, 7.3523e-03, 1.1802e-02, 1.4779e-02,\n",
            "        1.2008e-03, 9.8362e-03, 5.8998e-03, 2.7256e-02, 1.2154e-02, 2.3083e-03,\n",
            "        1.6753e-02, 6.9886e-03, 2.6349e-03, 1.1511e-02, 1.9264e-03, 5.8306e-03,\n",
            "        2.7329e-05, 9.4636e-03, 7.0157e-03, 9.0599e-03, 6.0463e-03, 8.0875e-05,\n",
            "        1.1281e-02, 1.4852e-02, 9.2678e-03, 2.1258e-02, 5.7437e-03, 5.0638e-05,\n",
            "        8.8067e-04, 9.0946e-03, 5.4878e-04, 3.6796e-05, 1.6138e-03, 8.0713e-03,\n",
            "        1.0524e-02, 5.2234e-03, 1.7708e-02, 8.8050e-04, 8.1950e-04, 4.5776e-06,\n",
            "        1.4519e-02, 1.3621e-02, 7.7662e-03, 1.3307e-02, 8.6873e-03, 8.5837e-03,\n",
            "        8.8608e-03, 7.9422e-03, 9.8968e-03, 7.5318e-03, 5.5613e-06, 2.0264e-02,\n",
            "        2.3902e-02, 1.1064e-02, 8.0019e-04, 7.4904e-03, 6.3614e-03, 7.2942e-03,\n",
            "        8.7662e-04, 8.2721e-03, 2.3158e-02, 2.9269e-04, 2.6962e-02, 8.1644e-03,\n",
            "        9.4628e-03, 2.7709e-03, 4.9064e-04, 8.9257e-04, 1.8533e-04, 8.8607e-04,\n",
            "        5.9533e-03, 9.2923e-03, 1.3272e-02, 9.8398e-03, 1.3522e-02, 2.5291e-02,\n",
            "        5.3285e-03, 1.9494e-04, 2.0165e-03, 7.7981e-03, 5.0867e-02, 1.3889e-02,\n",
            "        1.5717e-02, 1.3203e-02, 2.0020e-02, 5.4764e-03, 6.0245e-03, 1.1107e-01,\n",
            "        1.1258e-01, 1.0864e-02, 6.1321e-02, 8.9522e-03, 6.7555e-03, 1.9863e-02,\n",
            "        9.4575e-03, 5.4864e-04, 3.2586e-02, 6.5646e-04, 3.8652e-02, 5.5105e-03,\n",
            "        1.1377e-02, 4.6667e-02, 8.2390e-04, 4.4043e-03, 1.5998e-02, 1.8091e-02,\n",
            "        2.3910e-02, 1.0933e-03, 1.0314e-02, 1.6553e-02, 7.0657e-04, 6.4828e-02,\n",
            "        2.6813e-02, 6.4581e-03, 4.7083e-02, 1.5164e-03, 4.3329e-02, 1.3706e-02,\n",
            "        2.1069e-03, 4.0955e-02, 1.1243e-02, 1.7510e-02, 1.3909e-02, 2.8938e-02,\n",
            "        3.1650e-02, 6.2342e-02, 5.9600e-03, 3.0997e-02, 7.0927e-04, 3.6925e-03,\n",
            "        3.3607e-03, 2.8513e-02, 1.7045e-02, 3.7497e-02, 2.3891e-03, 9.1075e-03,\n",
            "        9.7392e-05, 2.9142e-02, 6.1201e-03, 1.0626e-02, 7.3124e-03, 5.1552e-03,\n",
            "        1.2318e-02, 2.7171e-02, 1.5780e-02, 2.3070e-02, 2.0440e-03, 6.7886e-03,\n",
            "        2.2604e-02, 3.8365e-02, 2.2160e-03, 3.6102e-02, 3.6814e-02, 1.3128e-03,\n",
            "        3.6592e-02, 3.9051e-02, 4.7614e-03, 2.2622e-04, 3.8727e-03, 1.6998e-02,\n",
            "        9.1989e-03, 2.0444e-03, 3.8857e-02, 5.8764e-02, 1.2974e-02, 1.2534e-01,\n",
            "        1.2454e-02, 3.1641e-02, 3.0857e-02, 1.4236e-02, 7.5397e-02, 1.2560e-03,\n",
            "        2.4457e-03, 1.5850e-02, 8.9653e-03, 9.8700e-04, 4.9296e-03, 6.7195e-04,\n",
            "        2.0040e-03, 4.0389e-02, 1.0366e-02, 1.7963e-02, 2.7662e-02, 3.1080e-05,\n",
            "        3.3845e-03, 3.2554e-03, 3.4023e-02, 6.6769e-03, 3.2451e-03, 2.6791e-03,\n",
            "        1.4550e-02, 4.5325e-02, 8.3862e-03, 3.5026e-03, 6.3511e-03, 1.4590e-03,\n",
            "        2.1828e-02, 5.9514e-03, 5.7531e-03, 1.1631e-02, 5.6737e-03, 4.5039e-04,\n",
            "        1.5538e-02, 1.8507e-02, 4.7909e-02, 2.4650e-03, 4.8023e-03, 7.2863e-03,\n",
            "        1.0002e-02, 7.6534e-03, 2.7250e-04, 4.6319e-03, 3.2531e-06, 4.6219e-03,\n",
            "        5.6994e-03, 2.3236e-03, 8.4190e-03, 6.6291e-03, 7.4312e-03, 9.9783e-03,\n",
            "        7.9107e-03, 3.9582e-02, 1.2888e-02, 9.2192e-03, 1.3216e-02, 1.0643e-03,\n",
            "        7.7186e-03, 2.0547e-03, 6.4072e-05, 1.3877e-02, 8.2615e-03, 1.2425e-03,\n",
            "        3.7658e-03, 1.3237e-03, 3.2954e-02, 2.7974e-03, 7.3670e-03, 1.1769e-02,\n",
            "        3.0324e-05, 7.3939e-03, 9.6031e-04, 2.0439e-02, 1.9075e-02, 2.3833e-03,\n",
            "        3.7141e-02, 7.4316e-04, 1.7364e-02, 2.5884e-03, 7.7449e-03, 1.2909e-06,\n",
            "        2.4167e-03, 2.9956e-03, 1.9005e-03, 8.8038e-03, 2.1394e-03, 5.0051e-03,\n",
            "        2.2618e-03, 4.8857e-03, 3.0408e-02, 3.4325e-03, 3.7158e-03, 2.0935e-02,\n",
            "        1.2765e-02, 5.2642e-03, 2.5817e-02, 5.1281e-02, 1.7835e-03, 3.0028e-03,\n",
            "        4.8872e-04, 1.6415e-02, 2.4346e-02, 3.7690e-02, 2.6517e-03, 3.5039e-04,\n",
            "        6.0235e-03, 6.9885e-03, 1.7699e-02, 4.8576e-04, 3.4076e-05, 7.2625e-03,\n",
            "        2.3038e-03, 2.4384e-04, 8.2474e-03, 1.8540e-03, 2.9461e-02, 3.6839e-03,\n",
            "        7.4193e-04, 7.2536e-03, 7.1122e-03, 4.6386e-03, 1.6532e-04, 2.7535e-03,\n",
            "        1.1176e-02, 1.0940e-02, 4.7759e-03, 2.9989e-03, 7.1702e-03, 2.8533e-04,\n",
            "        1.5904e-02, 5.3006e-04, 1.0319e-02, 2.8156e-02, 1.0302e-02, 9.7628e-03,\n",
            "        1.5574e-02, 4.7083e-02, 6.1439e-03, 2.6284e-04, 2.5344e-04, 3.3234e-02,\n",
            "        4.2672e-02, 5.8880e-02, 7.2058e-04, 4.6349e-02, 2.5394e-03, 4.0369e-03,\n",
            "        1.0659e-02, 2.0014e-02, 2.7927e-04, 1.1514e-02, 8.4716e-03, 5.1562e-05,\n",
            "        7.7102e-04, 1.7083e-02, 3.4882e-03, 2.0401e-02, 3.8412e-03, 9.4174e-03,\n",
            "        1.5416e-02, 1.1818e-02, 3.1363e-02, 1.3267e-02, 3.1315e-02, 5.1052e-03,\n",
            "        7.3862e-03, 8.4813e-03, 4.0925e-02, 1.1266e-02, 1.6323e-03, 1.3744e-02,\n",
            "        1.0423e-02, 4.3161e-03, 9.0532e-03, 1.4431e-06, 4.3907e-03, 6.9776e-04,\n",
            "        4.4354e-03, 6.9203e-03, 6.3084e-03, 2.0677e-02, 1.0501e-02, 2.2299e-02,\n",
            "        2.9907e-04, 1.0426e-03, 3.9829e-02, 3.4364e-02, 1.2408e-03, 8.8998e-03,\n",
            "        2.9520e-03, 2.4591e-03, 1.6008e-03, 1.5495e-02, 4.0495e-03, 1.4148e-02,\n",
            "        1.5295e-02, 4.3542e-04, 1.0898e-02, 3.5077e-03, 2.0100e-04, 4.5759e-03,\n",
            "        2.3605e-02, 1.2436e-02, 1.6907e-04, 3.8164e-03, 2.3984e-06, 3.5933e-03,\n",
            "        1.1902e-02, 2.0222e-02, 4.9690e-03, 3.9290e-03, 5.6958e-03, 3.2632e-02,\n",
            "        2.3271e-02, 6.6466e-03, 2.4215e-03, 4.3317e-03, 2.4459e-02, 2.0730e-03,\n",
            "        2.9252e-02, 2.7378e-03, 2.6830e-02, 2.1805e-02, 1.1219e-02, 3.2229e-06,\n",
            "        1.6791e-02, 2.2668e-03, 1.9167e-02, 7.7324e-03, 2.9289e-03, 3.5940e-03,\n",
            "        5.3146e-02, 1.4560e-02, 1.6540e-02, 1.7145e-05, 2.4056e-06, 7.4432e-04,\n",
            "        1.9008e-02, 5.2300e-03, 1.6796e-02, 1.4272e-04, 7.3535e-05, 1.2962e-03,\n",
            "        9.0949e-03, 3.2764e-03, 7.7562e-03, 1.0337e-05, 7.8249e-03, 2.7449e-03,\n",
            "        5.8486e-03, 2.7962e-02, 1.0480e-02, 1.3209e-02, 1.3948e-03, 9.7094e-03,\n",
            "        1.9859e-05, 3.8412e-02, 1.8860e-02, 7.3617e-03, 2.5838e-02, 6.1563e-03,\n",
            "        7.0447e-03, 8.0633e-05, 2.7680e-03, 2.7257e-02, 1.0412e-02, 6.6069e-03,\n",
            "        9.3867e-04, 2.5094e-02, 1.9213e-03, 8.7500e-03, 8.8671e-03, 3.4896e-04,\n",
            "        3.8340e-04, 4.0140e-03, 3.1650e-04, 4.1577e-03, 9.1482e-03, 6.9471e-03,\n",
            "        3.9313e-03, 1.8366e-03, 1.1722e-03, 5.4817e-03, 1.2708e-04, 9.7350e-03,\n",
            "        5.2881e-02, 7.0796e-04, 1.6069e-03, 2.3931e-03, 2.7677e-04, 8.7391e-04,\n",
            "        4.2575e-02, 6.5472e-03, 1.9677e-02, 1.8073e-02, 2.8337e-02, 6.5254e-02,\n",
            "        1.5492e-03, 1.1703e-03, 5.7424e-04, 1.1594e-03, 6.3760e-02, 2.8798e-04,\n",
            "        5.0769e-03, 5.7419e-04, 6.2264e-03, 1.2140e-02, 9.3650e-03, 1.7563e-02,\n",
            "        4.3471e-03, 1.0134e-02, 3.3024e-03, 1.9503e-02, 1.1928e-02, 6.6867e-02,\n",
            "        2.1439e-02, 6.6467e-02, 4.7932e-03, 1.8002e-03, 2.6775e-02, 2.6101e-02,\n",
            "        8.2661e-03, 1.3761e-02, 9.1602e-03, 6.8046e-03, 1.4804e-02, 6.8233e-02,\n",
            "        1.3233e-02, 4.0921e-02, 1.7836e-02, 3.6160e-02, 3.2064e-03, 2.9826e-03,\n",
            "        1.1519e-02, 2.9627e-02, 5.8398e-03, 1.5691e-03, 3.0112e-03, 9.2743e-03,\n",
            "        1.0065e-02, 3.1975e-02, 1.1146e-03, 2.5280e-02, 1.8709e-02, 2.7972e-03,\n",
            "        8.8348e-02, 5.3383e-02, 1.1948e-03, 2.2445e-02, 6.5029e-02, 1.4233e-02,\n",
            "        2.4233e-02, 9.9828e-03, 2.3937e-02, 4.4272e-02, 9.3195e-03, 1.1763e-02,\n",
            "        4.6600e-03, 7.0783e-03, 2.2642e-02, 1.4608e-02, 4.9917e-03, 1.7315e-02,\n",
            "        8.1159e-02, 9.7497e-03, 2.3706e-02, 1.3478e-02, 1.2839e-05, 3.7943e-02,\n",
            "        3.1702e-02, 1.5111e-02, 3.2571e-02, 1.1424e-05, 2.5471e-02, 5.1717e-02,\n",
            "        1.6233e-03, 2.0060e-02, 4.1183e-02, 2.9958e-02, 5.8972e-02, 1.1062e-02,\n",
            "        1.0809e-02, 1.3298e-02, 5.1421e-02, 7.8924e-03, 8.0782e-03, 6.8111e-03,\n",
            "        5.0478e-02, 5.0729e-02, 5.6360e-02, 2.5889e-02, 1.6528e-02, 2.2388e-03,\n",
            "        1.3749e-02, 1.9289e-03, 1.5429e-02, 1.3743e-02, 7.6458e-02, 4.7798e-02,\n",
            "        7.5834e-02, 7.9643e-03, 7.0231e-03, 1.9855e-04, 4.3080e-02, 1.3363e-02,\n",
            "        6.3758e-03, 1.0716e-02, 3.1701e-02, 2.4525e-02, 7.1475e-02, 8.6044e-04,\n",
            "        1.5015e-02, 2.8146e-02, 1.3647e-02, 6.8302e-03, 7.1303e-03, 3.5993e-03,\n",
            "        3.2717e-02, 2.7987e-02, 6.3178e-04, 3.0624e-03, 2.4418e-03, 2.5063e-02,\n",
            "        2.8531e-02, 1.3313e-02, 3.2473e-04, 1.1697e-03, 1.7046e-03, 4.8502e-03,\n",
            "        2.5367e-03, 3.9007e-05, 1.6525e-02, 3.2328e-02, 1.2768e-02, 1.7061e-03,\n",
            "        8.4897e-06, 1.6477e-03, 3.3415e-03, 6.2972e-03, 1.1116e-02, 4.5567e-03,\n",
            "        1.7382e-02, 2.6726e-03, 2.4989e-03, 1.4821e-03, 4.8170e-03, 1.9723e-03,\n",
            "        8.4885e-03, 6.0932e-06, 4.7489e-03, 5.7151e-03, 1.4057e-03, 1.4545e-02,\n",
            "        1.2626e-02, 1.3265e-02, 1.6538e-04, 2.1715e-03, 2.3015e-05, 8.0479e-03,\n",
            "        1.7306e-03, 3.3607e-03, 7.3597e-03, 1.8432e-03, 1.2659e-03, 1.1566e-02,\n",
            "        1.2110e-02, 4.7868e-03, 2.4683e-03, 4.7614e-04, 5.9605e-03, 8.6522e-04,\n",
            "        1.1590e-02, 1.6030e-04, 1.0385e-02, 3.4130e-03, 1.5414e-02, 3.9650e-03,\n",
            "        1.1365e-02, 1.0021e-02, 1.8912e-02, 2.9337e-03, 6.2516e-08, 1.0362e-02,\n",
            "        5.0277e-02, 1.1673e-02, 4.2255e-02, 3.5097e-02, 3.2855e-04, 1.3760e-02,\n",
            "        7.8676e-04, 8.4868e-03, 3.6314e-02, 2.9721e-02, 1.4322e-02, 6.3853e-03,\n",
            "        2.0404e-02, 2.0529e-03, 2.1250e-03, 9.8777e-03, 4.2317e-04, 2.9547e-03,\n",
            "        5.8044e-03, 9.7797e-03, 4.4362e-03, 3.4588e-02, 8.5020e-03, 1.1940e-02,\n",
            "        1.4258e-03, 1.4493e-02, 1.9621e-03, 1.0483e-02, 4.1990e-03, 6.6439e-03,\n",
            "        2.8254e-05, 8.5182e-02, 7.6164e-04, 2.7038e-02, 1.1209e-02, 1.1985e-03,\n",
            "        2.2551e-02, 6.2934e-02, 1.0507e-02, 1.1267e-02, 2.3681e-03, 3.1486e-02,\n",
            "        1.9659e-02, 4.4392e-02, 3.9653e-03, 4.9507e-02, 7.0340e-03, 3.5423e-02,\n",
            "        5.2022e-03, 5.6630e-03, 3.7957e-02, 1.2686e-02, 1.0775e-02, 1.5250e-03,\n",
            "        2.8002e-04, 8.4726e-03, 5.3710e-02, 5.7334e-05, 1.4080e-02, 1.4082e-02,\n",
            "        2.0438e-02, 5.3681e-03, 3.9375e-02, 8.0809e-02, 2.5649e-02, 1.5282e-02,\n",
            "        2.7100e-02, 4.5794e-02, 1.4546e-02, 9.2721e-03, 5.7649e-02, 6.8159e-03,\n",
            "        1.6666e-03, 1.4697e-02, 2.7346e-02, 9.2190e-02, 2.2342e-03, 5.0123e-02,\n",
            "        9.2347e-03, 6.2577e-02, 3.1517e-03, 3.3148e-02, 2.2619e-02, 5.4566e-02,\n",
            "        6.5062e-05, 7.2986e-03, 5.9981e-02, 5.6325e-02, 1.3578e-02, 1.9619e-02,\n",
            "        2.8466e-02, 7.7336e-03, 1.3721e-02, 5.4162e-02, 8.2293e-04, 1.7363e-03,\n",
            "        2.6451e-03, 4.1521e-02, 1.3632e-02, 1.8273e-02, 5.0359e-04, 1.1770e-01,\n",
            "        7.4975e-03, 7.4631e-03, 3.4860e-02, 3.2020e-02, 2.6820e-03, 1.0514e-02,\n",
            "        1.8454e-02, 4.6641e-02, 6.5110e-03, 2.9415e-03, 1.5360e-02, 2.0008e-02,\n",
            "        4.6675e-02, 7.4899e-03, 6.2062e-02, 6.8526e-02, 2.0704e-05, 1.4838e-02,\n",
            "        1.2942e-02, 1.1198e-02, 4.4162e-02, 1.9010e-02, 5.4374e-02, 1.6016e-02,\n",
            "        6.6580e-02, 9.9130e-02, 1.4407e-05, 2.8862e-03, 7.5857e-04, 5.4009e-03,\n",
            "        9.4330e-03, 4.5206e-02, 5.5872e-02, 3.4956e-03, 1.0958e-03, 5.1937e-02,\n",
            "        2.1105e-02, 6.1690e-03, 1.7085e-02, 2.0061e-02, 1.0083e-02, 7.2097e-03,\n",
            "        2.4113e-02, 4.0525e-03, 1.9200e-02, 3.1312e-02, 1.6793e-02, 2.4909e-03,\n",
            "        1.9356e-02, 1.0291e-02, 4.7292e-03, 3.2359e-03, 2.2780e-02, 8.5162e-02,\n",
            "        2.7655e-03, 1.1685e-02, 8.0772e-03, 2.5005e-07, 2.2999e-03, 4.1165e-02,\n",
            "        3.9397e-03, 3.8121e-06, 4.0044e-03, 1.3740e-03, 1.6985e-03, 3.6713e-02,\n",
            "        4.7829e-03, 4.0126e-02, 2.8776e-03, 3.4154e-02, 1.5182e-02, 6.4603e-03,\n",
            "        1.6689e-02, 6.1112e-03, 1.1534e-02, 8.9653e-03, 7.5120e-03, 5.1849e-02,\n",
            "        4.3283e-03, 3.4727e-03, 3.6665e-02, 8.3165e-03, 1.2908e-04, 1.8724e-02,\n",
            "        4.9887e-02, 1.2606e-02, 2.2623e-02, 1.3264e-02, 8.9827e-03, 1.7827e-02,\n",
            "        1.7899e-02, 5.8865e-03, 2.1626e-02, 3.0001e-03, 1.6295e-02, 1.0938e-02,\n",
            "        2.4655e-02, 9.9882e-05, 2.5087e-02, 5.8029e-02, 2.9550e-04, 9.8151e-03,\n",
            "        1.6652e-02, 5.4258e-03, 9.6265e-03, 9.8464e-03, 5.6629e-03, 3.6347e-02,\n",
            "        3.8835e-03, 1.1155e-02, 1.9946e-02, 1.4247e-03, 8.1517e-04, 8.6298e-03,\n",
            "        2.8342e-02, 7.9314e-03, 1.0185e-04, 2.8485e-02, 4.1860e-02, 1.9893e-02,\n",
            "        2.2424e-02, 5.1807e-02, 1.2599e-02, 8.0255e-08, 1.8545e-03, 8.1297e-03,\n",
            "        6.1048e-03, 1.2344e-02, 1.4371e-02, 5.8241e-02, 1.0930e-03, 5.9063e-02,\n",
            "        1.0192e-02, 2.4168e-05, 3.1704e-03, 4.4942e-02, 1.3327e-02, 1.0032e-02,\n",
            "        2.6514e-02, 3.7803e-03, 3.2459e-02, 4.8050e-02, 2.7747e-03, 6.6860e-02,\n",
            "        1.4932e-02, 4.6682e-02, 2.0482e-04, 4.3994e-03, 3.0936e-02, 1.0630e-02,\n",
            "        1.0214e-02, 8.2250e-03, 1.1551e-02, 4.8794e-02, 5.7388e-02, 4.5147e-02,\n",
            "        2.8352e-03, 1.2743e-02, 4.0242e-04, 2.4831e-02, 3.4367e-02, 4.7920e-02,\n",
            "        8.6123e-02, 2.9347e-03, 1.0255e-01, 7.0047e-03, 2.6420e-02, 1.4290e-02,\n",
            "        3.0042e-02, 6.4333e-02, 7.3305e-02, 1.0743e-02, 3.7292e-03, 1.2266e-01,\n",
            "        1.9440e-02, 2.8852e-02, 7.8823e-02, 5.7711e-02, 1.8910e-03, 2.8966e-04,\n",
            "        8.8818e-03, 1.0019e-01, 2.0782e-02, 6.8460e-03, 2.0180e-02, 9.8066e-02,\n",
            "        5.1312e-04, 2.6869e-03, 4.0838e-02, 6.0585e-02, 1.4528e-02, 5.5112e-02,\n",
            "        7.7087e-02, 2.1157e-02, 2.2366e-02, 2.1554e-02, 2.3320e-02, 7.2844e-04,\n",
            "        6.0468e-03, 2.2516e-03, 1.0486e-02, 1.9930e-02, 5.4912e-02, 2.9618e-03,\n",
            "        7.0014e-02, 2.2763e-02, 1.8807e-02, 5.2317e-02, 7.4988e-03, 9.7434e-03,\n",
            "        2.0347e-02, 3.3363e-04, 9.5081e-02, 8.4838e-02, 7.6184e-02, 5.5927e-02,\n",
            "        7.1284e-03, 4.3804e-02, 1.9208e-02, 1.1118e-02, 1.7974e-02, 1.9321e-02,\n",
            "        4.0130e-02, 3.0860e-02, 8.5754e-02, 1.5649e-04],\n",
            "       grad_fn=<DivBackward0>) tensor(0.1253, grad_fn=<UnbindBackward0>) tensor(16.4720, grad_fn=<AddBackward0>)\n",
            "Chosen edges: tensor([[ 0,  0,  0,  ...,  9,  9,  9],\n",
            "        [ 3,  6,  7,  ..., 96, 97, 98]]) 621\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:35<00:00, 26.18it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 5/50 | Train Loss: 0.4581 | Val Loss: 0.4035 | Val Accuracy: 0.8542\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:35<00:00, 26.38it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 6/50 | Train Loss: 0.4386 | Val Loss: 0.4125 | Val Accuracy: 0.8490\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:35<00:00, 26.37it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 7/50 | Train Loss: 0.4255 | Val Loss: 0.3903 | Val Accuracy: 0.8579\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [00:36<00:00, 25.47it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 8/50 | Train Loss: 0.4178 | Val Loss: 0.3851 | Val Accuracy: 0.8583\n",
            "checking if edge replacement is needed\n",
            "[0.008934309528132123, 0.02219039923066546, 0.005172875561531953]\n",
            "avg_change = 0.012099194773443178, threshold = 0.05, win_size = 3\n",
            "len_choose=[1000, 621]\n",
            "Edge metrics: tensor([5.7624e-03, 6.6672e-06, 2.6994e-03,  ..., 6.3133e-17, 1.2088e-17,\n",
            "        8.5754e-02], grad_fn=<DivBackward0>) tensor(0.1253, grad_fn=<UnbindBackward0>) tensor(16.4720, grad_fn=<AddBackward0>)\n",
            "Chosen edges: tensor([[  0,   0,   0,  ...,   9,   9,   9],\n",
            "        [100, 101, 102,  ..., 718, 719, 720]]) 621\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [02:58<00:00,  5.25it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 9/50 | Train Loss: 0.4313 | Val Loss: 0.3980 | Val Accuracy: 0.8587\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [02:59<00:00,  5.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 10/50 | Train Loss: 0.4157 | Val Loss: 0.3885 | Val Accuracy: 0.8597\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [03:00<00:00,  5.21it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 11/50 | Train Loss: 0.4067 | Val Loss: 0.3792 | Val Accuracy: 0.8637\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 938/938 [03:02<00:00,  5.15it/s]\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 12/50 | Train Loss: 0.4018 | Val Loss: 0.3872 | Val Accuracy: 0.8614\n",
            "checking if edge replacement is needed\n",
            "[0.009485460960181658, 0.009292631202442614, 0.008041154996604682]\n",
            "avg_change = 0.008939749053076318, threshold = 0.05, win_size = 3\n",
            "len_choose=[1000, 621, 621]\n",
            "Edge metrics: tensor([5.7624e-03, 6.6672e-06, 2.6994e-03,  ..., 1.8094e-17, 4.0965e-17,\n",
            "        8.5754e-02], grad_fn=<DivBackward0>) tensor(0.1253, grad_fn=<UnbindBackward0>) tensor(16.4720, grad_fn=<AddBackward0>)\n",
            "Chosen edges: tensor([[   0,    0,    0,  ...,    9,    9,    9],\n",
            "        [ 721,  722,  723,  ..., 1339, 1340, 1341]]) 621\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [07:44<00:00,  2.02it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/50 | Train Loss: 0.3955 | Val Loss: 0.3802 | Val Accuracy: 0.8641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 938/938 [07:42<00:00,  2.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/50 | Train Loss: 0.3850 | Val Loss: 0.3795 | Val Accuracy: 0.8641\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            " 72%|███████▏  | 678/938 [05:33<02:28,  1.75it/s]"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "T-wssmtsuCxy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 575
        },
        "outputId": "92ca11e5-2892-4f2a-dc60-9658b965e891"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>len</td><td>▁█</td></tr><tr><td>len_choose</td><td>▁▁</td></tr><tr><td>max</td><td>▁▁</td></tr><tr><td>sum</td><td>█▁</td></tr><tr><td>train_loss</td><td>██▃▂▂▂▁▁▁▁▁█▃▂▂▂▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▂▁▄▅▆▆▇▆▇▇█▁▄▅▆▇▇▇█▇</td></tr><tr><td>val_loss</td><td>▇█▅▄▃▂▂▂▁▁▁█▅▃▃▂▂▂▁▂</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>len</td><td>5014</td></tr><tr><td>len_choose</td><td>446</td></tr><tr><td>max</td><td>0.1479</td></tr><tr><td>sum</td><td>15.81557</td></tr><tr><td>train_loss</td><td>0.43083</td></tr><tr><td>val_accuracy</td><td>0.8556</td></tr><tr><td>val_loss</td><td>0.39761</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">fashionmnist test</strong> at: <a href='https://wandb.ai/down-shift/self-expanding-nets/runs/vevpwj70' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets/runs/vevpwj70</a><br> View project at: <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250310_172827-vevpwj70/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqfTinBU_3ju"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}