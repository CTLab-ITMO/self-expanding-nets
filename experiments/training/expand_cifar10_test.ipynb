{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XPdzrZyCcsX1"
      },
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install wandb"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IBZya_BRPBUo",
        "outputId": "75b13611-787a-4546-8dbb-cde55766ef7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: wandb in /usr/local/lib/python3.11/dist-packages (0.19.6)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.11/dist-packages (from wandb) (8.1.8)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (3.1.44)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.11/dist-packages (from wandb) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.25.6)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (5.9.5)\n",
            "Requirement already satisfied: pydantic<3,>=2.6 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.10.6)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from wandb) (6.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.32.3)\n",
            "Requirement already satisfied: sentry-sdk>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from wandb) (2.20.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.11/dist-packages (from wandb) (1.3.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from wandb) (75.1.0)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.4 in /usr/local/lib/python3.11/dist-packages (from wandb) (4.12.2)\n",
            "Requirement already satisfied: six>=1.4.0 in /usr/local/lib/python3.11/dist-packages (from docker-pycreds>=0.4.0->wandb) (1.17.0)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.11/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb) (4.0.12)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=2.6->wandb) (2.27.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests<3,>=2.0.0->wandb) (2025.1.31)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.11/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb) (5.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import wandb\n",
        "\n",
        "wandb.init(\n",
        "    project=\"self-expanding-nets\",\n",
        "    name=\"cifar10 resnet, exp, no freeze\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "cBDk7-o1PE1V",
        "outputId": "7e5c32b2-0bd3-4fdd-d931-bcc4f63b6410"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "        window._wandbApiKey = new Promise((resolve, reject) => {\n",
              "            function loadScript(url) {\n",
              "            return new Promise(function(resolve, reject) {\n",
              "                let newScript = document.createElement(\"script\");\n",
              "                newScript.onerror = reject;\n",
              "                newScript.onload = resolve;\n",
              "                document.body.appendChild(newScript);\n",
              "                newScript.src = url;\n",
              "            });\n",
              "            }\n",
              "            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n",
              "            const iframe = document.createElement('iframe')\n",
              "            iframe.style.cssText = \"width:0;height:0;border:none\"\n",
              "            document.body.appendChild(iframe)\n",
              "            const handshake = new Postmate({\n",
              "                container: iframe,\n",
              "                url: 'https://wandb.ai/authorize'\n",
              "            });\n",
              "            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n",
              "            handshake.then(function(child) {\n",
              "                child.on('authorize', data => {\n",
              "                    clearTimeout(timeout)\n",
              "                    resolve(data)\n",
              "                });\n",
              "            });\n",
              "            })\n",
              "        });\n",
              "    "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n",
            "wandb: Paste an API key from your profile and hit enter:"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            " ··········\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mdown-shift\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.19.6"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/wandb/run-20250209_155055-84zm3szs</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/down-shift/self-expanding-nets/runs/84zm3szs' target=\"_blank\">cifar10 resnet, exp, no freeze</a></strong> to <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/down-shift/self-expanding-nets/runs/84zm3szs' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets/runs/84zm3szs</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/down-shift/self-expanding-nets/runs/84zm3szs?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
            ],
            "text/plain": [
              "<wandb.sdk.wandb_run.Run at 0x7824a03b1e50>"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "id": "uwkRa6_EZ7xN",
        "outputId": "097306a9-6777-4769-a75a-c505f884eb74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">cifar10 resnet, exp, no freeze</strong> at: <a href='https://wandb.ai/down-shift/self-expanding-nets/runs/84zm3szs' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets/runs/84zm3szs</a><br> View project at: <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250209_155055-84zm3szs/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "j0vPMyO9csX2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c2c54b00-1b4f-4b0f-e0d4-6751e065b2eb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ],
      "source": [
        "from abc import abstractmethod, ABC\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader, random_split\n",
        "from torchvision import datasets, transforms\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from tqdm import tqdm\n",
        "\n",
        "SEED = 8642\n",
        "torch.manual_seed(8642)\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abCa34mWcsX3"
      },
      "source": [
        "## Utils"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5du0GTQ_csX3"
      },
      "outputs": [],
      "source": [
        "def dense_to_sparse(dense_tensor: torch.Tensor) -> torch.Tensor:\n",
        "    indices = dense_tensor.nonzero(as_tuple=True)\n",
        "    values = dense_tensor[indices]\n",
        "    indices = torch.stack(indices)\n",
        "\n",
        "    sparse_tensor = torch.sparse_coo_tensor(indices, values, dense_tensor.size(), device=device)\n",
        "    return sparse_tensor\n",
        "\n",
        "\n",
        "def convert_dense_to_sparse_network(model: nn.Module) -> nn.Module:\n",
        "    \"\"\"\n",
        "    Converts a given dense neural network model to a sparse neural network model.\n",
        "\n",
        "    This function recursively iterate through the given model and replaces all instances of\n",
        "    `nn.Linear` layers with `SparseLinear` layers\n",
        "\n",
        "    Args:\n",
        "        model (nn.Module): The dense neural network model to be converted.\n",
        "\n",
        "    Returns:\n",
        "        nn.Module: A new neural network model with sparse layers.\n",
        "    \"\"\"\n",
        "    new_model = model.__class__()\n",
        "\n",
        "    for name, module in model.named_children():\n",
        "        if isinstance(module, nn.Linear):\n",
        "            sparse_weight = dense_to_sparse(module.weight.data)\n",
        "            sparse_bias = dense_to_sparse(module.bias.data)\n",
        "\n",
        "            setattr(new_model, name, ExpandingLinear(sparse_weight, sparse_bias, device=device))\n",
        "        else:\n",
        "            setattr(new_model, name, convert_dense_to_sparse_network(module))\n",
        "    return new_model\n",
        "\n",
        "\n",
        "def get_model_last_layer(model):\n",
        "    if isinstance(model, ResnetExp):   # TODO: generalize\n",
        "        return get_model_last_layer(model.expanding_head)\n",
        "    if isinstance(model, SparseModule):\n",
        "        return model\n",
        "    else:\n",
        "        return list(model.children())[-1]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UM_B9qUcsX3"
      },
      "outputs": [],
      "source": [
        "class NonlinearityMetric(ABC):\n",
        "    def __init__(self, loss_fn):\n",
        "        self.loss_fn = loss_fn\n",
        "\n",
        "    @abstractmethod\n",
        "    def calculate(self, model, X_arr, y_arr):\n",
        "        pass\n",
        "\n",
        "\n",
        "# Метрика 1: Средний градиент для каждого ребра\n",
        "class GradientMeanEdgeMetric(NonlinearityMetric):\n",
        "    def calculate(self, model, X_arr, y_arr):\n",
        "        model.eval()\n",
        "        model.zero_grad()\n",
        "\n",
        "        y_pred = model(X_arr).squeeze()\n",
        "        loss = self.loss_fn(y_pred, y_arr)\n",
        "        loss.backward()\n",
        "\n",
        "        last_layer = get_model_last_layer(model)\n",
        "\n",
        "        # Градиенты для разреженных весов\n",
        "        edge_gradients = last_layer.weight_values.grad.abs()\n",
        "        model.zero_grad()\n",
        "        return edge_gradients\n",
        "\n",
        "\n",
        "# Метрика 3: Чувствительность к возмущению для каждого ребра\n",
        "class PerturbationSensitivityEdgeMetric(NonlinearityMetric):\n",
        "    def __init__(self, loss_fn, epsilon=1e-2):\n",
        "        super().__init__(loss_fn)\n",
        "        self.epsilon = epsilon\n",
        "\n",
        "    def calculate(self, model, X_arr, y_arr):\n",
        "        model.eval()\n",
        "\n",
        "        # Оригинальный вывод модели\n",
        "        original_output = model(X_arr).detach()\n",
        "\n",
        "        last_layer = get_model_last_layer(model)\n",
        "        sensitivities = torch.zeros_like(last_layer.weight_values)\n",
        "\n",
        "        # Возмущение каждого веса\n",
        "        for idx in range(last_layer.weight_values.size(0)):\n",
        "            with torch.no_grad():\n",
        "                original_value = last_layer.weight_values[idx].item()\n",
        "                last_layer.weight_values[idx] += self.epsilon\n",
        "\n",
        "                # Пересчет модели с возмущением\n",
        "                perturbed_output = model(X_arr)\n",
        "                sensitivity = (perturbed_output - original_output).abs().mean().item()\n",
        "                sensitivities[idx] = sensitivity\n",
        "\n",
        "                # Восстановление оригинального значения\n",
        "                last_layer.weight_values[idx] = original_value\n",
        "\n",
        "        return sensitivities\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NENK8UZ1csX4"
      },
      "outputs": [],
      "source": [
        "class EdgeFinder:\n",
        "    def __init__(self, metric: NonlinearityMetric, dataloader, device=torch.device('cpu')):\n",
        "        self.metric = metric\n",
        "        self.dataloader = dataloader\n",
        "        self.device = device\n",
        "\n",
        "    def calculate_edge_metric_for_dataloader(self, model, categorical_label: bool = True):\n",
        "        accumulated_grads = None\n",
        "        for data, target in self.dataloader:\n",
        "            data, target = data.to(self.device), target.to(self.device)#.to(torch.float32)\n",
        "\n",
        "            if not categorical_label:\n",
        "                target = target.to(torch.float32)\n",
        "\n",
        "            metric = self.metric.calculate(model, data, target)\n",
        "\n",
        "            if accumulated_grads is None:\n",
        "                accumulated_grads = torch.zeros_like(metric).to(self.device)\n",
        "\n",
        "            accumulated_grads += metric\n",
        "\n",
        "        return accumulated_grads / len(self.dataloader)\n",
        "\n",
        "    def choose_edges_top_k(self, model, top_k: int):\n",
        "        avg_metric = self.calculate_edge_metric_for_dataloader(model)\n",
        "        sorted_indices = torch.argsort(avg_metric, descending=True)\n",
        "        last_layer = get_model_last_layer(model)\n",
        "        return last_layer.weight_indices[:, sorted_indices[:top_k]]\n",
        "\n",
        "    def choose_edges_top_percent(self, model, percent: float):\n",
        "        percent = min(max(percent, 0.0), 1.0)  # percent in [0, 1]\n",
        "        avg_metric = self.calculate_edge_metric_for_dataloader(model)\n",
        "        k = int(percent * avg_metric.numel())\n",
        "        sorted_indices = torch.argsort(avg_metric, descending=True)\n",
        "        last_layer = get_model_last_layer(model)\n",
        "        return last_layer.weight_indices[:, sorted_indices[:k]]\n",
        "\n",
        "    def choose_edges_threshold(self, model, threshold):\n",
        "        avg_metric = self.calculate_edge_metric_for_dataloader(model)\n",
        "        mask = avg_metric > threshold\n",
        "        last_layer = get_model_last_layer(model)\n",
        "        return last_layer.weight_indices[:, mask.nonzero(as_tuple=True)[0]]\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric,\n",
        "#                            edge_replacement_func=None, logging=True,\n",
        "#                            expansion_criterion=None, metric_threshold: float = 0.05,\n",
        "#                            delta_threshold: float = 0.25, n_prev_epochs: int = 3,\n",
        "#                            get_n_neurons_func=None):\n",
        "#     optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "#     criterion = nn.CrossEntropyLoss()\n",
        "#     loss_history = []\n",
        "#     prev_replacement_epoch = -1\n",
        "\n",
        "#     for epoch in range(num_epochs):\n",
        "#         model.train()\n",
        "#         train_loss = 0\n",
        "#         for inputs, targets in tqdm(train_loader):\n",
        "#             outputs = model(inputs)\n",
        "#             loss = criterion(outputs, targets)\n",
        "\n",
        "#             optimizer.zero_grad()\n",
        "#             loss.backward()\n",
        "#             optimizer.step()\n",
        "#             train_loss += loss.item()\n",
        "\n",
        "#         train_loss /= len(train_loader)\n",
        "\n",
        "#         model.eval()\n",
        "#         val_loss = 0\n",
        "#         all_targets = []\n",
        "#         all_preds = []\n",
        "#         with torch.no_grad():\n",
        "#             for inputs, targets in val_loader:\n",
        "#                 outputs = model(inputs)\n",
        "#                 loss = criterion(outputs, targets)\n",
        "#                 val_loss += loss.item()\n",
        "\n",
        "#                 preds = torch.argmax(outputs, dim=1)\n",
        "#                 all_targets.extend(targets.cpu().numpy())\n",
        "#                 all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "#         val_loss /= len(val_loader)\n",
        "#         val_accuracy = accuracy_score(all_targets, all_preds)\n",
        "#         loss_history.append(val_loss)\n",
        "\n",
        "#         print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
        "#               f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\\n\")\n",
        "\n",
        "#         if logging:\n",
        "#             wandb.log({\"val_accuracy\": val_accuracy, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
        "\n",
        "#         if edge_replacement_func and (epoch - prev_replacement_epoch) >= n_prev_epochs and expansion_criterion:\n",
        "#             if expansion_criterion(loss_history, n_prev_epochs, delta_threshold):\n",
        "#                 if get_n_neurons_func:\n",
        "#                     n_neurons = get_n_neurons_func(loss_history, n_prev_epochs, delta_threshold)\n",
        "#                 else:\n",
        "#                     n_neurons = 2\n",
        "#                 edge_replacement_func(model, optimizer, val_loader, metric,\n",
        "#                                       metric_threshold, n_neurons)\n",
        "#                 prev_replacement_epoch = epoch\n",
        "#                 print(\"Replacement done\\n\")\n",
        "#             else:\n",
        "#                 print(\"Replacement denied\\n\")\n",
        "\n",
        "\n",
        "def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric,\n",
        "                           edge_replacement_func=None, logging=True,\n",
        "                           expansion_criterion=None, metric_threshold: float = 0.05,\n",
        "                           delta_threshold: float = 0.25, n_prev_epochs: int = 3,\n",
        "                           get_n_neurons_func=None, device=None):\n",
        "\n",
        "    if device is None:\n",
        "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    loss_history = []\n",
        "    prev_replacement_epoch = -1\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        train_loss = 0\n",
        "        for inputs, targets in tqdm(train_loader):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            train_loss += loss.item()\n",
        "\n",
        "        train_loss /= len(train_loader)\n",
        "\n",
        "        model.eval()\n",
        "        val_loss = 0\n",
        "        all_targets = []\n",
        "        all_preds = []\n",
        "        with torch.no_grad():\n",
        "            for inputs, targets in val_loader:\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, targets)\n",
        "                val_loss += loss.item()\n",
        "\n",
        "                preds = torch.argmax(outputs, dim=1)\n",
        "                all_targets.extend(targets.cpu().numpy())\n",
        "                all_preds.extend(preds.cpu().numpy())\n",
        "\n",
        "        val_loss /= len(val_loader)\n",
        "        val_accuracy = accuracy_score(all_targets, all_preds)\n",
        "        loss_history.append(val_loss)\n",
        "\n",
        "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
        "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\\n\")\n",
        "\n",
        "        if logging:\n",
        "            wandb.log({\"val_accuracy\": val_accuracy, \"train_loss\": train_loss, \"val_loss\": val_loss})\n",
        "\n",
        "        if edge_replacement_func and (epoch - prev_replacement_epoch) >= n_prev_epochs and expansion_criterion:\n",
        "            if expansion_criterion(loss_history, n_prev_epochs, delta_threshold):\n",
        "                if get_n_neurons_func:\n",
        "                    n_neurons = get_n_neurons_func(loss_history, n_prev_epochs, delta_threshold)\n",
        "                else:\n",
        "                    n_neurons = 2\n",
        "                edge_replacement_func(model, optimizer, val_loader, metric,\n",
        "                                      metric_threshold, n_neurons)\n",
        "                prev_replacement_epoch = epoch\n",
        "                print(\"Replacement done\\n\")\n",
        "            else:\n",
        "                print(\"Replacement denied\\n\")\n"
      ],
      "metadata": {
        "id": "g_BtC_0XQ1nB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## New model"
      ],
      "metadata": {
        "id": "H-CFfvB_cOJq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "new_weight = torch.empty(1, device=device)\n",
        "\n",
        "weight_value = 1 / n_neurons\n",
        "eps = 1e-4\n",
        "\n",
        "new_weight.uniform_(weight_value - eps, weight_value + eps)  # ReLU\n",
        "new_weight"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ToypMYziagAF",
        "outputId": "ec48e079-791c-4683-bb27-9bc1647e5e24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.4999], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class SparseModule(ABC, nn.Module):\n",
        "    def __init__(self, weight_size, device='cpu', eps: float = 1e-4):\n",
        "        super(SparseModule, self).__init__()\n",
        "        self.weight_indices = torch.empty(2, 0, dtype=torch.long, device=device)\n",
        "        self.weight_values = nn.Parameter(torch.empty(0, device=device))\n",
        "        self.weight_size = list(weight_size)\n",
        "        self.device = device\n",
        "        self.eps = eps\n",
        "\n",
        "    def add_edge(self, child, parent, n_neurons: int):\n",
        "        assert n_neurons >= 1\n",
        "\n",
        "        new_edge = torch.tensor([[child, parent]], dtype=torch.long, device=self.device).t()\n",
        "        self.weight_indices = torch.cat([self.weight_indices, new_edge], dim=1)\n",
        "\n",
        "        new_weight = torch.empty(1, device=self.device)\n",
        "        weight_value = 1 / n_neurons\n",
        "        new_weight.uniform_(weight_value - self.eps, weight_value + self.eps)  # TODO: not only ReLU\n",
        "\n",
        "        self.weight_values.data = torch.cat([self.weight_values.data, new_weight])\n",
        "\n",
        "    def create_sparse_tensor(self):\n",
        "        return torch.sparse_coo_tensor(self.weight_indices, self.weight_values, self.weight_size, device=self.device)\n",
        "\n",
        "    @abstractmethod\n",
        "    def replace(self, child, parent, n_neurons: int = 2):\n",
        "        pass\n",
        "\n",
        "    def replace_many(self, children, parents, n_neurons: int = 2):\n",
        "        for c, p in zip(children, parents):\n",
        "            self.replace(c, p, n_neurons)\n",
        "\n",
        "\n",
        "class EmbedLinear(SparseModule):\n",
        "    def __init__(self, weight_size, activation=nn.ReLU(), device='cpu'):\n",
        "        super(EmbedLinear, self).__init__([0, weight_size], device=device)\n",
        "        self.child_counter = 0\n",
        "        self.activation = activation\n",
        "        self.device = device\n",
        "\n",
        "    def replace(self, child, parent, n_neurons: int = 2):\n",
        "        for i in range(n_neurons):\n",
        "            self.add_edge(self.child_counter + i, parent, n_neurons)\n",
        "        self.weight_size[0] += n_neurons\n",
        "        self.child_counter += n_neurons\n",
        "\n",
        "    def forward(self, input):\n",
        "        sparse_embed_weight = self.create_sparse_tensor()\n",
        "        # print(\"\\nEmbedLinear shapes: \", sparse_embed_weight.shape, input.shape)\n",
        "        output = torch.sparse.mm(sparse_embed_weight, input.t()).t()\n",
        "        return torch.cat([input, self.activation(output)], dim=1)\n",
        "\n",
        "\n",
        "class ExpandingLinear(SparseModule):\n",
        "    def __init__(self, weight: torch.sparse_coo_tensor, bias: torch.sparse_coo_tensor, device='cpu'):\n",
        "        super(ExpandingLinear, self).__init__(weight.size(), device=device)\n",
        "\n",
        "        weight = weight.coalesce()\n",
        "        self.weight_indices = weight.indices().to(device)\n",
        "        self.weight_values = nn.Parameter(weight.values().to(device))\n",
        "\n",
        "        self.embed_linears = []\n",
        "\n",
        "        bias = bias.coalesce()\n",
        "        self.bias_indices = bias.indices().to(device)\n",
        "        self.bias_values = nn.Parameter(bias.values().to(device))\n",
        "        self.bias_size = list(bias.size())\n",
        "\n",
        "        self.current_iteration = -1\n",
        "        self.device = device\n",
        "\n",
        "    def replace(self, child, parent, n_neurons: int = 2):\n",
        "        if self.current_iteration == -1:\n",
        "            self.current_iteration = 0\n",
        "\n",
        "        if len(self.embed_linears) <= self.current_iteration:\n",
        "            self.embed_linears.append(EmbedLinear(self.weight_size[1], device=self.device))\n",
        "\n",
        "        matches = (self.weight_indices[0] == child) & (self.weight_indices[1] == parent)\n",
        "\n",
        "        assert torch.any(matches), \"Edge must extist\"\n",
        "\n",
        "        max_parent = self.weight_indices[1].max().item() + 1  # n_neurons # before deleting edge\n",
        "\n",
        "        self.weight_indices = self.weight_indices[:, ~matches]\n",
        "        self.weight_values = nn.Parameter(self.weight_values[~matches])\n",
        "\n",
        "        for i in range(n_neurons):\n",
        "            self.add_edge(child, max_parent + i)\n",
        "\n",
        "        self.weight_size[1] += n_neurons\n",
        "        self.embed_linears[self.current_iteration].replace(child, parent, n_neurons=n_neurons)\n",
        "\n",
        "    def replace_many(self, children, parents, n_neurons: int = 2):\n",
        "        self.current_iteration += (len(children) != 0 and len(parents) != 0)\n",
        "        super().replace_many(children, parents, n_neurons)\n",
        "\n",
        "    def forward(self, input):\n",
        "        for embed_linear in self.embed_linears:\n",
        "            input = embed_linear(input)\n",
        "\n",
        "        sparse_weight = self.create_sparse_tensor()\n",
        "        sparse_bias = torch.sparse_coo_tensor(self.bias_indices, self.bias_values, self.bias_size,\n",
        "                                              device=self.device).to_dense()\n",
        "\n",
        "        try:\n",
        "            output = torch.sparse.mm(sparse_weight, input.t()).t()\n",
        "            output += sparse_bias.unsqueeze(0)\n",
        "        except:\n",
        "            print(sparse_weight.shape, sparse_bias.shape, input.t().shape)\n",
        "            assert 0 == 1\n",
        "\n",
        "        return output"
      ],
      "metadata": {
        "id": "VxOVP4CLcP__"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x00Sjsa5csX4"
      },
      "outputs": [],
      "source": [
        "def edge_replacement_func_new_layer(model, optim, val_loader, metric,\n",
        "                                    threshold: float = 0.05, n_neurons: int = 2):\n",
        "    layer = model.expanding_head.fc3    # TODO: select last layer\n",
        "    ef = EdgeFinder(metric, val_loader, device)\n",
        "    vals = ef.calculate_edge_metric_for_dataloader(model)\n",
        "    # print(\"Edge metrics:\", vals, max(vals), sum(vals))\n",
        "    chosen_edges = ef.choose_edges_threshold(model, threshold)\n",
        "    print(\"Chosen edges:\", chosen_edges, len(chosen_edges[0]))\n",
        "    layer.replace_many(*chosen_edges, n_neurons=n_neurons)\n",
        "\n",
        "    if layer.embed_linears:\n",
        "        if not any(layer.embed_linears[-1].weight_values is p for pg in optim.param_groups for p in pg['params']): # Changed line\n",
        "            optim.add_param_group({'params': layer.embed_linears[-1].weight_values})\n",
        "    else:\n",
        "        print(\"Empty metric\")\n",
        "        dummy_param = torch.zeros_like(layer.weight_values)\n",
        "        if not any(dummy_param is p for pg in optim.param_groups for p in pg['params']): # Changed line\n",
        "            optim.add_param_group({'params': dummy_param})\n",
        "\n",
        "    return {'max': max(vals), 'sum': sum(vals), 'len': len(vals), 'len_choose': len(chosen_edges[0])}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7hQLNdkBcsX4"
      },
      "outputs": [],
      "source": [
        "# class SimpleFCN(nn.Module):\n",
        "#     def __init__(self, input_size=100):\n",
        "#         super(SimpleFCN, self).__init__()\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc1 = nn.Linear(input_size, 50)\n",
        "#         self.dropout = nn.Dropout(p=0.5)\n",
        "#         self.fc2 = nn.Linear(50, 50)\n",
        "#         self.fc3 = nn.Linear(50, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.relu(self.fc1(x))\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.relu(self.fc2(x))\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.fc3(x)\n",
        "#         return x"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# class DummyFCN(nn.Module):\n",
        "#     def __init__(self, input_size=100):\n",
        "#         super().__init__()\n",
        "#         self.relu = nn.ReLU()\n",
        "#         self.fc1 = nn.Linear(input_size, 50)\n",
        "#         self.dropout = nn.Dropout(p=0.5)\n",
        "#         # self.fc2 = nn.Linear(50, 50)\n",
        "#         self.fc3 = nn.Linear(50, 10)\n",
        "\n",
        "#     def forward(self, x):\n",
        "#         x = self.relu(self.fc1(x))\n",
        "#         # x = self.relu(self.fc2(x))\n",
        "#         x = self.dropout(x)\n",
        "#         x = self.fc3(x)\n",
        "#         return x"
      ],
      "metadata": {
        "id": "FbZ-qp9G_0nP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Dynamic sublayer size adjustment"
      ],
      "metadata": {
        "id": "EEgNzOkYd1Hm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_expansion_criterion(loss_history, n_prev_epochs: int = 3,\n",
        "                            delta_threshold: float = 0.25) -> bool:\n",
        "    \"\"\"\n",
        "    Idea: extend layer if mean of [|∆loss_i|] over n previous epochs\n",
        "    is smaller than delta_threshold\n",
        "    \"\"\"\n",
        "    # TODO: derivation from mean\n",
        "    arr = np.array(loss_history[-n_prev_epochs:])\n",
        "    deltas = np.array([arr[i + 1] - arr[i] for i in range(len(arr) - 1)])\n",
        "    mean_delta = np.mean(np.abs(deltas))\n",
        "    print(\"Mean delta: \", mean_delta)\n",
        "    return mean_delta < delta_threshold"
      ],
      "metadata": {
        "id": "VIJhPLang7Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_n_neurons_by_delta(loss_history, n_prev_epochs: int = 3,\n",
        "                           delta_threshold: float = 0.25, upper_bound: int = 10):\n",
        "    arr = np.array(loss_history[-n_prev_epochs:])\n",
        "    deltas = np.array([arr[i + 1] - arr[i] for i in range(len(arr) - 1)])\n",
        "    mean_delta = np.mean(np.abs(deltas))\n",
        "    n_neurons = min(int(1 / mean_delta), upper_bound)\n",
        "    print(\"Number of new neurons per edge: \", n_neurons)\n",
        "    return n_neurons"
      ],
      "metadata": {
        "id": "Vvc2-7hyQFQk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def get_sqrt_n_neurons_by_delta(loss_history, n_prev_epochs: int = 3,\n",
        "                           delta_threshold: float = 0.25, upper_bound: int = 10):\n",
        "    arr = np.array(loss_history[-n_prev_epochs:])\n",
        "    deltas = np.array([arr[i + 1] - arr[i] for i in range(len(arr) - 1)])\n",
        "    mean_delta = np.mean(np.abs(deltas))\n",
        "    n_neurons = min(int(np.sqrt(1 / mean_delta)), upper_bound)\n",
        "    print(\"Number of new neurons per edge: \", n_neurons)\n",
        "    return n_neurons"
      ],
      "metadata": {
        "id": "R-cSMJZmWlUT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data"
      ],
      "metadata": {
        "id": "krPGhnTzZ0TQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n",
        ")\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse',\n",
        "           'ship', 'truck')\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root='./data', train=True,\n",
        "                                  download=True, transform=transform)\n",
        "val_dataset = datasets.CIFAR10(root='./data', train=False,\n",
        "                                  download=True, transform=transform)\n",
        "\n",
        "# train_size = int(0.8 * len(train_dataset))\n",
        "# val_size = len(train_dataset) - train_size\n",
        "# # train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
        "# train_dataset, val_dataset, test_dataset = random_split(train_dataset, [train_size // 2, val_size // 2, len(train_dataset) - (train_size // 2 + val_size // 2)])\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
        "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False)\n",
        "\n",
        "print(len(train_loader))"
      ],
      "metadata": {
        "id": "0o6BD4zOcGR7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f0c65e99-04bb-4ff9-e531-d25270c05ed9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Files already downloaded and verified\n",
            "Files already downloaded and verified\n",
            "782\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model\n"
      ],
      "metadata": {
        "id": "tvu7bPScuIZE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# model = SimpleFCN(input_size=64)\n",
        "# model = DummyFCN(input_size=784)\n",
        "# sparse_model = convert_dense_to_sparse_network(model)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# ef = EdgeFinder(GradientMeanEdgeMetric(criterion), val_loader, device)"
      ],
      "metadata": {
        "id": "zC8Z0Py8cDYy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# base_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\", \"cifar10_resnet20\", pretrained=True)\n",
        "# base_model = torch.nn.Sequential(*(list(base_model.children())[:-1]))\n",
        "# base_model"
      ],
      "metadata": {
        "id": "qvVb8hF-vQp_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ExpandingHead(nn.Module):\n",
        "    def __init__(self, input_size: int = 64, hidden_size: int = 50, output_size: int = 10):\n",
        "        super().__init__()\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
        "        self.dropout = nn.Dropout(p=0.5)\n",
        "        self.fc2 = nn.Linear(hidden_size, hidden_size)\n",
        "        self.fc3 = nn.Linear(hidden_size, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.relu(self.fc2(x))\n",
        "        x = self.dropout(x)\n",
        "        x = self.fc3(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "P5CJsZ8JWW37"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResnetExp(nn.Module):\n",
        "    def __init__(self, freeze_base: bool = False):\n",
        "        super().__init__()\n",
        "        self.base_model = torch.hub.load(\"chenyaofo/pytorch-cifar-models\",\n",
        "                                         \"cifar10_resnet20\", pretrained=True)\n",
        "        self.base_model = torch.nn.Sequential(\n",
        "            *(list(self.base_model.children())[:-1])\n",
        "        )\n",
        "        self.expanding_head = convert_dense_to_sparse_network(\n",
        "            ExpandingHead(input_size=64, hidden_size=50, output_size=10)\n",
        "        ).to(device)\n",
        "        # if freeze_base:\n",
        "        #     self.freeze(self.base_model)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.base_model(x)\n",
        "        x = x.view(x.size(0), -1)\n",
        "        x = self.expanding_head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "E46j8bB7T3dk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rexp = ResnetExp(device)\n",
        "rexp = rexp.to(device)\n",
        "img = val_dataset[0][0].unsqueeze(0).to(device)\n",
        "rexp(img)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vINAOS5NVW9W",
        "outputId": "c344c0c3-a697-420c-a45c-064aa74dc6a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Using cache found in /root/.cache/torch/hub/chenyaofo_pytorch-cifar-models_master\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-0.0817,  0.0430,  0.0596, -0.1064,  0.1145, -0.0934, -0.0041,  0.1266,\n",
              "         -0.1026, -0.0511]], device='cuda:0', grad_fn=<AsStridedBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 168
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train"
      ],
      "metadata": {
        "id": "P_dxPc_KvO0_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "❗️TODO:\n",
        "- adjust train loop code to only extend the head\n",
        "- freeze the backbone\n",
        "- add GPU support"
      ],
      "metadata": {
        "id": "BrchJqD6XrgF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "ef = EdgeFinder(GradientMeanEdgeMetric(criterion), val_loader, device)\n",
        "# device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "y2wZHgeYSjrg",
        "outputId": "2f641724-f855-457e-d2f6-0573c6971be5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'cuda'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 145
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_prev_epochs = 100\n",
        "delta_threshold = 0.1\n",
        "metric_threshold = 0.015\n",
        "num_epochs = 15"
      ],
      "metadata": {
        "id": "Qmg78Zloh7vk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_sparse_recursive(rexp,\n",
        "                       train_loader,\n",
        "                       val_loader,\n",
        "                       num_epochs=num_epochs,\n",
        "                       metric=GradientMeanEdgeMetric(criterion),\n",
        "                       edge_replacement_func=edge_replacement_func_new_layer,\n",
        "                       expansion_criterion=get_expansion_criterion,\n",
        "                       logging=True,\n",
        "                       delta_threshold=delta_threshold,\n",
        "                       metric_threshold=metric_threshold,\n",
        "                       n_prev_epochs=n_prev_epochs,\n",
        "                       get_n_neurons_func=get_sqrt_n_neurons_by_delta,\n",
        "                       device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pHzSaVyk6j7e",
        "outputId": "87948950-5a3c-44e7-9908-28111008d77f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 22.26it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15, Train Loss: 0.0694, Val Loss: 0.8137, Val Accuracy: 0.9035\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 22.23it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/15, Train Loss: 0.0756, Val Loss: 0.7664, Val Accuracy: 0.9096\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:34<00:00, 22.34it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/15, Train Loss: 0.0710, Val Loss: 0.7671, Val Accuracy: 0.9082\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 22.29it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/15, Train Loss: 0.0608, Val Loss: 0.8417, Val Accuracy: 0.9117\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 22.03it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/15, Train Loss: 0.0700, Val Loss: 0.8038, Val Accuracy: 0.9038\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:34<00:00, 22.54it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/15, Train Loss: 0.0613, Val Loss: 0.8233, Val Accuracy: 0.9099\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:34<00:00, 22.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/15, Train Loss: 0.0614, Val Loss: 0.7964, Val Accuracy: 0.9100\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:34<00:00, 22.77it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/15, Train Loss: 0.0581, Val Loss: 0.8279, Val Accuracy: 0.9058\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:34<00:00, 22.82it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/15, Train Loss: 0.0685, Val Loss: 0.7769, Val Accuracy: 0.9069\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:34<00:00, 22.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/15, Train Loss: 0.0566, Val Loss: 0.7902, Val Accuracy: 0.9085\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 21.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/15, Train Loss: 0.0593, Val Loss: 0.8137, Val Accuracy: 0.9041\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 21.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/15, Train Loss: 0.0595, Val Loss: 0.8616, Val Accuracy: 0.9046\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 22.21it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/15, Train Loss: 0.0622, Val Loss: 0.7867, Val Accuracy: 0.9074\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 21.97it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/15, Train Loss: 0.0581, Val Loss: 0.8030, Val Accuracy: 0.9084\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 782/782 [00:35<00:00, 21.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/15, Train Loss: 0.0565, Val Loss: 0.7692, Val Accuracy: 0.9072\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "wandb.finish()"
      ],
      "metadata": {
        "id": "h9XrsDtwdk56",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 401
        },
        "outputId": "e55ef0d9-054e-49a2-92a5-04626123ed8b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": []
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▃▃▂▂▂▁▁▁▁▁▁▁▁▁▇▂▂▁▇▂▂▂▁▃▂▂▁▁▁▁▁▇▄▂▃▂▂▂</td></tr><tr><td>val_accuracy</td><td>▇████▅▆▅▆▅▅▅▅▅▅▆▆▆▆▅▆▆▆▅▆▆▆▆▆▆▁▆▅▆▆▅▅▅▅▅</td></tr><tr><td>val_loss</td><td>▄▁▁▁▅▃▄▄▄▅▅▅▆▆▆▆▃▄▄▄▃▃▃▄▄▆▃▃▄▄▅▅█▆▅▅▅▅▆▆</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.20335</td></tr><tr><td>val_accuracy</td><td>0.9096</td></tr><tr><td>val_loss</td><td>0.58987</td></tr></table><br/></div></div>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">BEBRA v2.0.3</strong> at: <a href='https://wandb.ai/down-shift/self-expanding-nets/runs/8nurxhfa' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets/runs/8nurxhfa</a><br> View project at: <a href='https://wandb.ai/down-shift/self-expanding-nets' target=\"_blank\">https://wandb.ai/down-shift/self-expanding-nets</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Find logs at: <code>./wandb/run-20250203_151400-8nurxhfa/logs</code>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AT_duuxp0wlF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.1"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}