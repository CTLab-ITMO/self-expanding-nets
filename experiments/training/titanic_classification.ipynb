{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:20.318020Z",
     "start_time": "2025-02-11T21:01:25.170016Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from torch.utils.data import DataLoader, Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "851a61bbbac63426",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:20.409711Z",
     "start_time": "2025-02-11T21:02:20.359673Z"
    }
   },
   "outputs": [],
   "source": [
    "from senmodel.model.utils import convert_dense_to_sparse_network, get_model_last_layer\n",
    "from senmodel.metrics.edge_finder import EdgeFinder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ed98f9250fb9b52",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:20.443325Z",
     "start_time": "2025-02-11T21:02:20.428808Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8a1c4b0b6e33d5a4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:23.590919Z",
     "start_time": "2025-02-11T21:02:20.480333Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data\"\n",
    "columns = [\n",
    "    'age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital-status',\n",
    "    'occupation', 'relationship', 'race', 'sex', 'capital-gain', 'capital-loss',\n",
    "    'hours-per-week', 'native-country', 'income'\n",
    "]\n",
    "data = pd.read_csv(url, names=columns, na_values=\" ?\", skipinitialspace=True)\n",
    "data = data.dropna()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "y = data['occupation']\n",
    "y = LabelEncoder().fit_transform(y)\n",
    "\n",
    "X = data.drop(['occupation'], axis=1)\n",
    "\n",
    "for col in X.select_dtypes(include=['object']).columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col])\n",
    "\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "\n",
    "len(set(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7d9e408b16a7a6a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:24.903666Z",
     "start_time": "2025-02-11T21:02:24.884257Z"
    }
   },
   "outputs": [],
   "source": [
    "class TabularDataset(Dataset):\n",
    "    def __init__(self, features, targets):\n",
    "        self.features = torch.tensor(features, dtype=torch.float32)\n",
    "        self.targets = torch.tensor(targets, dtype=torch.long)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.targets)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.targets[idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "183cc85a9b097f1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:25.139816Z",
     "start_time": "2025-02-11T21:02:25.010546Z"
    }
   },
   "outputs": [],
   "source": [
    "train_dataset = TabularDataset(X_train, y_train)\n",
    "val_dataset = TabularDataset(X_val, y_val)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=512, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=512, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7e5ab74bd84c4c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:25.182863Z",
     "start_time": "2025-02-11T21:02:25.161851Z"
    }
   },
   "outputs": [],
   "source": [
    "class MulticlassFCN(nn.Module):\n",
    "    def __init__(self, input_size=14, hidden_sizes=None, output_size=15, dropout_rate=0.3):\n",
    "        super(MulticlassFCN, self).__init__()\n",
    "        if hidden_sizes is None:\n",
    "            hidden_sizes = [128, 64]\n",
    "        self.fc1 = nn.Linear(input_size, hidden_sizes[0])\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.fc2 = nn.Linear(hidden_sizes[0], hidden_sizes[1])\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout2 = nn.Dropout(0.1)\n",
    "\n",
    "        self.output = nn.Linear(hidden_sizes[1], output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.dropout1(x)\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        x = self.relu2(x)\n",
    "        x = self.dropout2(x)\n",
    "\n",
    "        x = self.output(x)\n",
    "        # x = self.dropout2(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6fe92b9bfdd4d7d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:25.288977Z",
     "start_time": "2025-02-11T21:02:25.260801Z"
    }
   },
   "outputs": [],
   "source": [
    "def edge_replacement_func_new_layer(model, optim, val_loader, metric, choose_threshold, aggregation_mode='mean', len_choose=None):\n",
    "    layer = get_model_last_layer(model)\n",
    "    ef = EdgeFinder(metric, val_loader, device, aggregation_mode)\n",
    "    vals = ef.calculate_edge_metric_for_dataloader(model, len_choose, False)\n",
    "    print(\"Edge metrics:\", vals, max(vals), sum(vals))\n",
    "    chosen_edges = ef.choose_edges_threshold(model, choose_threshold, len_choose)\n",
    "    print(\"Chosen edges:\", chosen_edges, len(chosen_edges[0]))\n",
    "    layer.replace_many(*chosen_edges)\n",
    "\n",
    "    if len(chosen_edges[0]) > 0:\n",
    "        optim.add_param_group({'params': layer.embed_linears[-1].weight_values})\n",
    "    else:\n",
    "        print(\"Empty metric\")\n",
    "\n",
    "    return {'max': max(vals), 'sum': sum(vals), 'len': len(vals), 'len_choose': layer.count_replaces[-1]}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e4d086a0b3b29f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:25.591134Z",
     "start_time": "2025-02-11T21:02:25.433629Z"
    }
   },
   "outputs": [],
   "source": [
    "from senmodel.model.utils import freeze_all_but_last, freeze_only_last\n",
    "from tqdm import tqdm\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func=None,\n",
    "                           window_size=3, threshold=0.1, lr=5e-4, choose_threshold=0.3, aggregation_mode='mean'):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    val_losses = []\n",
    "\n",
    "    len_choose = get_model_last_layer(model).count_replaces\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "\n",
    "        for i, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "            inputs, targets = inputs.to(device), targets.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "\n",
    "            if len(len_choose) > 3:\n",
    "                freeze_all_but_last(model)\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(all_targets, all_preds)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "\n",
    "        new_l = dict()\n",
    "\n",
    "        val_losses.append(val_loss)\n",
    "        if edge_replacement_func and len(val_losses) > window_size:\n",
    "            recent_changes = [abs(val_losses[i] - val_losses[i - 1]) for i in range(-window_size, 0)]\n",
    "            avg_change = sum(recent_changes) / window_size\n",
    "            if avg_change < threshold:\n",
    "                print(f\"{len_choose=}\")\n",
    "                len_ch = len_choose[-1] if len(len_choose) > 3 else None\n",
    "                new_l = edge_replacement_func(model, optimizer, val_loader, metric, choose_threshold, aggregation_mode, len_ch)\n",
    "                # Замораживаем все слои кроме последнего\n",
    "                val_losses = []\n",
    "                len_choose = get_model_last_layer(model).count_replaces\n",
    "\n",
    "        wandb.log({'val_loss': val_loss, 'val_accuracy': val_accuracy, 'train_loss': train_loss} | new_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b44615f5a401dd16",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:25.628149Z",
     "start_time": "2025-02-11T21:02:25.613167Z"
    }
   },
   "outputs": [],
   "source": [
    "from senmodel.metrics.nonlinearity_metrics import *\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "metrics = [\n",
    "    AbsGradientEdgeMetric(criterion),\n",
    "    ReversedAbsGradientEdgeMetric(criterion),\n",
    "    SNIPMetric(criterion),\n",
    "    MagnitudeL2Metric(criterion),\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c813771bca507d71",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:39.557848Z",
     "start_time": "2025-02-11T21:02:25.697276Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "wandb: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "wandb: Currently logged in as: fedornigretuk. Use `wandb login --relogin` to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a10df7d34ecdcb18",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:02:39.805781Z",
     "start_time": "2025-02-11T21:02:39.779777Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_epochs: 50, metric: AbsGradientEdgeMetric, aggregation_mode: mean, choose_threshold: 0.5, window_size: 3, threshold: 0.05, lr: 0.0005'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = {\"num_epochs\": 50,\n",
    "               \"metric\": metrics[0],\n",
    "               \"aggregation_mode\": \"mean\",\n",
    "               \"choose_threshold\": 0.5,\n",
    "               \"window_size\": 3,\n",
    "               \"threshold\": 0.05,\n",
    "               \"lr\": 5e-4\n",
    "               }\n",
    "\n",
    "name = \", \".join(\n",
    "    f\"{key}: {value.__class__.__name__ if key == 'metric' else value}\"\n",
    "    for key, value in hyperparams.items()\n",
    ")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "45fe9040816bb570",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:06:17.151538Z",
     "start_time": "2025-02-11T21:02:40.108023Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.0"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Coding\\PY\\self-expanding-nets\\experiments\\training\\wandb\\run-20250212_191502-me4h3nmp</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fedornigretuk/self-expanding-nets/runs/me4h3nmp' target=\"_blank\">titanic-mul, num_epochs: 50, metric: AbsGradientEdgeMetric, aggregation_mode: mean, choose_threshold: 0.5, window_size: 3, threshold: 0.05, lr: 0.0005</a></strong> to <a href='https://wandb.ai/fedornigretuk/self-expanding-nets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fedornigretuk/self-expanding-nets' target=\"_blank\">https://wandb.ai/fedornigretuk/self-expanding-nets</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fedornigretuk/self-expanding-nets/runs/me4h3nmp' target=\"_blank\">https://wandb.ai/fedornigretuk/self-expanding-nets/runs/me4h3nmp</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 35.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 2.5659 | Val Loss: 31.0064 | Val Accuracy: 0.2702\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 38.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 2.3129 | Val Loss: 27.8593 | Val Accuracy: 0.3261\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 35.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 2.1632 | Val Loss: 26.2555 | Val Accuracy: 0.3341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 33.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 2.0903 | Val Loss: 25.6272 | Val Accuracy: 0.3386\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 35.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 2.0520 | Val Loss: 25.3449 | Val Accuracy: 0.3407\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 35.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 2.0303 | Val Loss: 25.1602 | Val Accuracy: 0.3424\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 30.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 2.0164 | Val Loss: 25.0259 | Val Accuracy: 0.3450\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 34.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 2.0018 | Val Loss: 24.9240 | Val Accuracy: 0.3465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 30.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 1.9853 | Val Loss: 24.8207 | Val Accuracy: 0.3485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 31.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 1.9800 | Val Loss: 24.7259 | Val Accuracy: 0.3508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 31.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/50 | Train Loss: 1.9717 | Val Loss: 24.6558 | Val Accuracy: 0.3528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 33.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/50 | Train Loss: 1.9691 | Val Loss: 24.6055 | Val Accuracy: 0.3528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 33.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/50 | Train Loss: 1.9628 | Val Loss: 24.5469 | Val Accuracy: 0.3516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 37.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/50 | Train Loss: 1.9579 | Val Loss: 24.4965 | Val Accuracy: 0.3531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 38.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/50 | Train Loss: 1.9517 | Val Loss: 24.4821 | Val Accuracy: 0.3511\n",
      "len_choose=[960]\n",
      "Edge metrics: tensor([3.4563e-03, 2.2910e-03, 2.1521e-03, 2.6363e-03, 2.7747e-03, 4.9007e-03,\n",
      "        1.9890e-03, 2.9380e-05, 3.4119e-03, 4.6652e-03, 4.0696e-03, 5.6801e-04,\n",
      "        1.3916e-03, 3.5282e-03, 9.0317e-04, 1.7548e-03, 3.4815e-03, 2.0844e-03,\n",
      "        1.5064e-03, 1.3889e-03, 3.2403e-03, 2.3049e-03, 3.3943e-03, 2.3837e-03,\n",
      "        1.9463e-03, 2.5094e-03, 1.7530e-03, 2.9674e-03, 3.8340e-03, 3.9615e-03,\n",
      "        1.2118e-03, 6.8596e-03, 3.8086e-03, 3.3433e-03, 2.3462e-03, 2.1069e-03,\n",
      "        2.0243e-03, 2.9119e-03, 2.8925e-03, 3.0832e-03, 1.9273e-03, 3.1661e-03,\n",
      "        3.7570e-03, 9.7297e-04, 9.8611e-04, 1.7259e-03, 1.0094e-03, 1.2123e-03,\n",
      "        1.2694e-03, 5.6358e-03, 1.3621e-03, 1.3714e-03, 4.6028e-03, 9.7005e-04,\n",
      "        0.0000e+00, 2.8222e-03, 3.5545e-03, 2.4483e-03, 4.4076e-03, 1.5011e-03,\n",
      "        3.2925e-03, 1.4533e-03, 1.2355e-04, 5.2282e-03, 8.7160e-03, 2.1786e-03,\n",
      "        7.1738e-03, 7.7113e-03, 5.7006e-03, 7.3808e-03, 7.9623e-03, 1.0624e-04,\n",
      "        4.6390e-03, 1.1334e-02, 3.2696e-03, 4.6455e-03, 4.1679e-03, 3.8699e-03,\n",
      "        4.1071e-03, 7.5175e-03, 1.4809e-02, 1.0723e-02, 4.9957e-03, 6.5205e-03,\n",
      "        4.2355e-03, 5.8698e-03, 7.7230e-03, 1.2412e-03, 8.1768e-03, 1.3018e-03,\n",
      "        9.5724e-03, 7.8185e-03, 1.0965e-02, 6.9478e-03, 1.0748e-02, 8.2085e-03,\n",
      "        3.3948e-03, 6.0624e-03, 4.1141e-03, 7.0252e-03, 5.1447e-03, 1.2154e-02,\n",
      "        6.3999e-03, 2.8045e-03, 3.4478e-03, 7.4562e-03, 5.7885e-03, 1.0086e-02,\n",
      "        6.8839e-03, 4.2362e-03, 6.7877e-03, 7.8245e-03, 1.3548e-02, 5.9860e-03,\n",
      "        7.2709e-03, 1.6616e-02, 1.0147e-02, 6.8605e-03, 0.0000e+00, 7.7772e-03,\n",
      "        4.0104e-03, 6.8703e-03, 3.7655e-03, 9.6166e-03, 2.0156e-03, 6.4809e-03,\n",
      "        2.4736e-04, 2.1053e-02, 3.8860e-04, 2.0755e-04, 4.8496e-04, 2.2454e-04,\n",
      "        1.3448e-04, 6.8438e-04, 2.8745e-04, 1.3251e-06, 4.2783e-04, 8.0635e-04,\n",
      "        3.7697e-04, 2.2997e-04, 2.8079e-04, 2.1305e-04, 2.4612e-04, 3.0592e-04,\n",
      "        6.2491e-04, 2.2100e-04, 2.6443e-04, 1.1301e-04, 2.1313e-04, 3.5676e-04,\n",
      "        6.0285e-04, 2.2192e-04, 2.0257e-04, 1.8961e-04, 2.4133e-04, 3.4679e-04,\n",
      "        3.7847e-04, 4.9581e-04, 1.9424e-04, 8.0048e-04, 3.7461e-04, 3.2899e-04,\n",
      "        3.3645e-04, 4.3096e-04, 4.4938e-04, 3.3242e-04, 3.2710e-04, 3.0306e-04,\n",
      "        2.2528e-04, 2.5104e-04, 3.7935e-04, 2.1654e-04, 1.6539e-04, 1.9630e-04,\n",
      "        9.7773e-05, 9.6785e-05, 2.6705e-04, 6.6632e-04, 1.3775e-04, 5.1760e-04,\n",
      "        4.7118e-04, 2.2596e-04, 0.0000e+00, 5.1314e-04, 3.0359e-04, 4.6362e-04,\n",
      "        3.8008e-04, 3.1847e-04, 3.0658e-04, 1.2633e-04, 3.7878e-06, 9.6937e-04,\n",
      "        4.8953e-03, 1.4515e-03, 1.3663e-02, 7.5919e-03, 3.3636e-03, 8.2802e-03,\n",
      "        4.1775e-03, 2.7089e-04, 7.5850e-03, 1.7365e-02, 2.4601e-03, 1.1342e-02,\n",
      "        1.0665e-02, 1.8307e-03, 1.0108e-02, 9.6619e-03, 1.0881e-02, 5.3717e-03,\n",
      "        7.1500e-03, 2.7629e-03, 1.6891e-03, 6.3399e-03, 1.3183e-02, 1.1762e-03,\n",
      "        4.3371e-03, 1.4483e-03, 5.6307e-03, 4.7098e-03, 7.3339e-03, 4.8009e-03,\n",
      "        5.5338e-03, 8.0622e-03, 2.2834e-03, 6.0055e-03, 5.2709e-03, 8.2235e-03,\n",
      "        1.3300e-02, 6.2386e-03, 3.9545e-03, 1.8215e-03, 6.5595e-03, 7.6788e-03,\n",
      "        4.1905e-03, 5.6707e-03, 7.6650e-03, 3.2882e-03, 4.8223e-03, 2.7203e-03,\n",
      "        6.9908e-03, 5.4332e-03, 4.1029e-03, 1.3741e-02, 6.2002e-03, 4.8508e-03,\n",
      "        0.0000e+00, 1.3733e-02, 3.0147e-03, 1.0018e-02, 2.4655e-03, 6.0089e-03,\n",
      "        1.5960e-03, 3.1737e-03, 5.0417e-04, 2.0760e-02, 4.9396e-03, 1.5490e-03,\n",
      "        2.3663e-02, 1.8497e-02, 1.2158e-02, 7.4625e-03, 4.8048e-03, 8.2338e-05,\n",
      "        5.0134e-03, 1.9078e-02, 3.9757e-03, 1.0862e-02, 8.9555e-03, 3.4065e-03,\n",
      "        7.6139e-03, 2.0655e-02, 1.8999e-02, 7.5090e-03, 5.5383e-03, 2.6907e-03,\n",
      "        5.5242e-03, 2.8735e-03, 8.7628e-03, 1.7101e-03, 6.3107e-03, 1.6641e-03,\n",
      "        9.9919e-03, 3.9648e-03, 1.8149e-02, 4.2071e-03, 1.2098e-02, 9.7614e-03,\n",
      "        3.9493e-03, 1.1862e-02, 3.3589e-03, 7.1576e-03, 8.4084e-03, 2.0450e-02,\n",
      "        6.1529e-03, 3.0989e-03, 4.7655e-03, 1.6289e-02, 3.0720e-03, 1.7196e-02,\n",
      "        1.5764e-02, 8.2099e-03, 1.1420e-02, 1.3637e-02, 1.9329e-02, 4.9551e-03,\n",
      "        1.3686e-02, 2.8677e-02, 1.7468e-02, 1.1584e-02, 0.0000e+00, 1.9837e-02,\n",
      "        7.1915e-03, 6.5012e-03, 4.7841e-03, 5.5535e-03, 2.2535e-03, 1.1053e-02,\n",
      "        1.5882e-04, 3.8168e-02, 1.3910e-03, 1.1552e-03, 7.4707e-03, 5.3070e-03,\n",
      "        1.6128e-03, 6.7296e-03, 1.8072e-03, 1.1936e-04, 6.2480e-03, 1.1303e-02,\n",
      "        7.5558e-04, 8.4064e-03, 7.4063e-03, 6.4996e-04, 6.8512e-03, 5.7900e-03,\n",
      "        5.5843e-03, 2.7363e-03, 5.3990e-03, 1.6472e-03, 5.1847e-04, 3.2533e-03,\n",
      "        9.3480e-03, 3.5892e-04, 2.5288e-03, 3.9000e-04, 2.4397e-03, 1.3042e-03,\n",
      "        2.9290e-03, 2.5660e-03, 2.3510e-03, 6.1730e-03, 1.0674e-03, 2.5193e-03,\n",
      "        4.2123e-03, 6.4140e-03, 8.4746e-03, 3.0757e-03, 1.2889e-03, 7.4153e-04,\n",
      "        4.9101e-03, 3.6678e-03, 1.3021e-03, 3.1958e-03, 5.0641e-03, 2.1754e-03,\n",
      "        5.5311e-03, 2.3559e-03, 3.3497e-03, 4.7189e-03, 2.4934e-03, 1.0961e-02,\n",
      "        2.3256e-03, 5.3136e-03, 0.0000e+00, 8.4430e-03, 7.3374e-04, 6.3668e-03,\n",
      "        7.2739e-04, 2.6357e-03, 7.2253e-04, 1.3577e-03, 2.9093e-04, 1.4342e-02,\n",
      "        3.2490e-03, 1.0236e-03, 5.0672e-03, 2.6161e-03, 1.1234e-03, 9.0036e-03,\n",
      "        4.0364e-03, 1.7640e-04, 6.3574e-03, 1.0339e-02, 2.2898e-03, 5.9234e-03,\n",
      "        6.9308e-03, 1.8202e-03, 6.5277e-03, 3.6053e-03, 8.3263e-03, 3.0571e-03,\n",
      "        7.3486e-03, 1.7864e-03, 1.1853e-03, 6.5302e-03, 1.0724e-02, 1.0790e-03,\n",
      "        2.4080e-03, 1.0521e-03, 2.4600e-03, 3.3439e-03, 2.8261e-03, 5.7445e-03,\n",
      "        2.4527e-03, 8.8511e-03, 2.8317e-03, 2.5872e-03, 5.4347e-03, 7.1031e-03,\n",
      "        8.5912e-03, 2.5553e-03, 2.1390e-03, 2.0061e-03, 4.5523e-03, 2.5882e-03,\n",
      "        3.1059e-03, 2.0865e-03, 2.6971e-03, 2.0234e-03, 1.5012e-03, 1.0613e-03,\n",
      "        2.9536e-03, 8.3687e-03, 1.4307e-03, 5.2495e-03, 2.8280e-03, 4.3165e-03,\n",
      "        0.0000e+00, 7.2237e-03, 1.3821e-03, 8.6178e-03, 2.4659e-03, 6.3022e-03,\n",
      "        1.6000e-03, 1.3478e-03, 5.9906e-04, 9.8020e-03, 3.8833e-03, 1.7130e-03,\n",
      "        9.0869e-03, 4.4167e-03, 1.5287e-03, 6.4555e-03, 4.5734e-03, 3.1253e-04,\n",
      "        5.5299e-03, 1.2444e-02, 1.7489e-03, 6.0603e-03, 6.8327e-03, 1.5995e-03,\n",
      "        6.4283e-03, 6.5541e-03, 6.7113e-03, 6.5318e-03, 6.1482e-03, 4.5027e-03,\n",
      "        9.4774e-04, 5.1902e-03, 1.0580e-02, 5.0807e-04, 6.4065e-03, 7.5999e-04,\n",
      "        4.6771e-03, 3.2155e-03, 5.7027e-03, 5.4588e-03, 3.2035e-03, 4.2567e-03,\n",
      "        1.7094e-03, 3.0598e-03, 4.2615e-03, 8.1779e-03, 9.3722e-03, 3.1037e-03,\n",
      "        3.0967e-03, 1.5447e-03, 4.2494e-03, 3.5334e-03, 4.6201e-03, 2.6453e-03,\n",
      "        4.2668e-03, 3.0027e-03, 2.7090e-03, 1.4618e-03, 4.2926e-03, 5.6111e-03,\n",
      "        2.1011e-03, 7.6042e-03, 4.0125e-03, 3.7770e-03, 0.0000e+00, 9.0161e-03,\n",
      "        1.7155e-03, 8.9967e-03, 1.9161e-03, 5.5743e-03, 1.2181e-03, 1.9348e-03,\n",
      "        4.2113e-04, 1.3158e-02, 7.4795e-03, 3.4947e-03, 8.2699e-03, 4.2937e-03,\n",
      "        2.4228e-03, 9.9821e-03, 7.3906e-03, 2.6747e-04, 5.0079e-03, 1.4919e-02,\n",
      "        1.9481e-03, 5.3711e-03, 5.5587e-03, 2.2011e-03, 6.0511e-03, 5.1624e-03,\n",
      "        1.1283e-02, 7.8196e-03, 6.1968e-03, 5.8360e-03, 1.9879e-03, 9.8979e-03,\n",
      "        1.3920e-02, 7.6279e-04, 6.4033e-03, 1.2263e-03, 6.3617e-03, 7.1057e-03,\n",
      "        8.7455e-03, 9.9809e-03, 6.1811e-03, 8.0176e-03, 2.5216e-03, 2.8440e-03,\n",
      "        6.9395e-03, 1.1013e-02, 8.8769e-03, 6.9207e-03, 4.6077e-03, 1.6881e-03,\n",
      "        3.6015e-03, 3.8529e-03, 8.3277e-03, 4.9454e-03, 3.6213e-03, 3.8208e-03,\n",
      "        2.4060e-03, 2.5447e-03, 7.9615e-03, 9.8564e-03, 2.9555e-03, 9.9387e-03,\n",
      "        7.5141e-03, 7.1981e-03, 0.0000e+00, 7.5034e-03, 2.1816e-03, 1.1474e-02,\n",
      "        1.8219e-03, 1.0494e-02, 1.5319e-03, 3.8053e-03, 5.0168e-04, 1.7304e-02,\n",
      "        3.2001e-03, 1.8464e-03, 1.0856e-03, 7.1902e-04, 5.8646e-04, 1.9434e-03,\n",
      "        2.1991e-03, 1.9027e-04, 6.8930e-04, 2.8962e-03, 2.9714e-04, 8.1158e-04,\n",
      "        9.0830e-04, 6.7513e-04, 7.3500e-04, 9.5757e-04, 2.4350e-03, 3.5642e-03,\n",
      "        2.4329e-03, 4.0887e-03, 2.7856e-04, 4.2438e-03, 3.2881e-03, 7.6403e-05,\n",
      "        3.2429e-03, 1.4773e-04, 1.6551e-03, 1.8434e-03, 2.2209e-03, 3.7598e-03,\n",
      "        1.4140e-03, 1.0997e-03, 2.9732e-04, 5.6295e-04, 2.9880e-03, 2.5930e-03,\n",
      "        9.8604e-04, 1.4157e-03, 1.3834e-03, 2.2639e-04, 6.3334e-04, 4.9234e-04,\n",
      "        3.6713e-03, 8.7216e-04, 5.8218e-04, 1.7935e-03, 4.8939e-04, 5.4190e-04,\n",
      "        2.0064e-03, 2.6145e-03, 6.1090e-04, 1.7740e-03, 1.5923e-03, 1.2803e-03,\n",
      "        0.0000e+00, 1.2270e-03, 4.1836e-04, 2.7976e-03, 3.2764e-04, 3.7501e-03,\n",
      "        1.9974e-04, 7.7956e-04, 7.3184e-05, 3.3405e-03, 4.2308e-03, 1.1210e-03,\n",
      "        2.8408e-02, 2.3854e-02, 1.8799e-02, 6.0796e-03, 5.1290e-03, 4.2336e-05,\n",
      "        4.0337e-03, 1.9086e-02, 4.7748e-03, 7.8203e-03, 5.0746e-03, 3.1270e-03,\n",
      "        4.8891e-03, 2.6742e-02, 2.3505e-02, 6.0379e-03, 2.9101e-03, 2.5653e-03,\n",
      "        9.4389e-03, 2.7180e-03, 5.1750e-03, 1.8694e-03, 4.4800e-03, 1.9392e-03,\n",
      "        1.0368e-02, 5.7365e-03, 2.1417e-02, 3.1559e-03, 1.6617e-02, 1.2374e-02,\n",
      "        3.4808e-03, 1.5919e-02, 2.4365e-03, 4.6691e-03, 4.3203e-03, 2.8670e-02,\n",
      "        8.8171e-03, 3.6629e-03, 3.2293e-03, 1.8489e-02, 2.9677e-03, 2.7120e-02,\n",
      "        2.1504e-02, 8.3550e-03, 1.6771e-02, 2.4314e-02, 2.3288e-02, 4.4042e-03,\n",
      "        2.0871e-02, 3.7989e-02, 2.2899e-02, 1.2852e-02, 0.0000e+00, 2.1142e-02,\n",
      "        1.0942e-02, 5.1416e-03, 5.2887e-03, 5.1591e-03, 2.1205e-03, 1.7069e-02,\n",
      "        1.3038e-04, 4.5715e-02, 1.1257e-03, 1.0175e-03, 7.3317e-03, 4.9860e-03,\n",
      "        3.4152e-03, 4.6082e-03, 1.7900e-03, 5.0266e-05, 4.8950e-03, 8.1925e-03,\n",
      "        3.8944e-03, 4.0306e-03, 4.2706e-03, 2.1234e-03, 3.9083e-03, 5.3389e-03,\n",
      "        5.1715e-03, 1.8899e-03, 3.3881e-03, 1.0597e-03, 1.8406e-03, 1.6476e-03,\n",
      "        6.6173e-03, 9.6665e-04, 1.7973e-03, 1.3520e-03, 2.3290e-03, 1.1755e-03,\n",
      "        4.0328e-03, 2.0617e-03, 2.3470e-03, 6.2538e-03, 5.5669e-03, 4.4895e-03,\n",
      "        2.1054e-03, 4.3631e-03, 5.9718e-03, 3.5053e-03, 1.7558e-03, 4.0246e-03,\n",
      "        2.8695e-03, 4.9502e-03, 1.4575e-03, 3.6637e-03, 3.6637e-03, 2.6507e-03,\n",
      "        2.5140e-03, 2.6791e-03, 3.8081e-03, 4.1367e-03, 2.8764e-03, 7.3731e-03,\n",
      "        3.5809e-03, 1.9675e-03, 0.0000e+00, 6.8570e-03, 3.2642e-03, 4.6538e-03,\n",
      "        4.9736e-03, 2.3801e-03, 1.3353e-03, 2.1012e-03, 8.8983e-05, 1.1128e-02,\n",
      "        6.4474e-03, 2.4587e-03, 1.3988e-02, 8.8415e-03, 6.7564e-03, 5.8489e-03,\n",
      "        4.4299e-03, 2.3101e-04, 3.6869e-03, 1.5088e-02, 2.8946e-03, 5.8944e-03,\n",
      "        5.1868e-03, 2.8109e-03, 5.1249e-03, 1.0071e-02, 1.1409e-02, 6.9765e-03,\n",
      "        5.3654e-03, 4.1934e-03, 3.6922e-03, 4.7574e-03, 8.7735e-03, 9.3355e-04,\n",
      "        6.3980e-03, 9.1433e-04, 7.4639e-03, 4.6801e-03, 1.3602e-02, 5.0699e-03,\n",
      "        8.0680e-03, 5.7360e-03, 2.6201e-03, 5.7325e-03, 4.4557e-03, 6.3658e-03,\n",
      "        7.7035e-03, 1.0094e-02, 5.4819e-03, 2.2417e-03, 3.1109e-03, 7.1971e-03,\n",
      "        4.3077e-03, 9.6724e-03, 7.0344e-03, 6.9195e-03, 6.2418e-03, 6.8900e-03,\n",
      "        1.1748e-02, 5.6363e-03, 6.7443e-03, 1.4108e-02, 1.0158e-02, 4.6754e-03,\n",
      "        0.0000e+00, 1.0518e-02, 4.4015e-03, 7.1595e-03, 3.4193e-03, 5.0651e-03,\n",
      "        1.5393e-03, 7.0774e-03, 3.2024e-04, 2.3065e-02, 3.5504e-03, 9.8599e-04,\n",
      "        6.1511e-03, 5.1379e-03, 4.9541e-03, 4.3790e-03, 3.4220e-03, 3.5049e-05,\n",
      "        3.6462e-03, 7.2867e-03, 2.2868e-03, 2.9505e-03, 2.7145e-03, 2.0420e-03,\n",
      "        2.8121e-03, 4.4774e-03, 6.7573e-03, 5.0000e-03, 2.2897e-03, 2.1768e-03,\n",
      "        2.2768e-03, 2.0017e-03, 6.5148e-03, 1.0455e-03, 3.9902e-03, 7.7790e-04,\n",
      "        4.9740e-03, 3.4094e-03, 8.9021e-03, 2.6655e-03, 5.9204e-03, 5.4696e-03,\n",
      "        2.6299e-03, 3.4920e-03, 1.8652e-03, 4.5066e-03, 4.3609e-03, 8.1635e-03,\n",
      "        3.8187e-03, 2.0518e-03, 2.3596e-03, 4.5906e-03, 2.4080e-03, 6.2852e-03,\n",
      "        3.2829e-03, 4.0656e-03, 3.1834e-03, 4.8119e-03, 8.1897e-03, 4.3491e-03,\n",
      "        3.9755e-03, 8.1030e-03, 7.9135e-03, 2.7846e-03, 0.0000e+00, 5.3412e-03,\n",
      "        2.9075e-03, 4.7358e-03, 2.6681e-03, 3.6907e-03, 1.4173e-03, 4.5051e-03,\n",
      "        8.6028e-05, 1.1368e-02, 1.9897e-03, 1.3304e-03, 8.8717e-03, 5.2361e-03,\n",
      "        2.7095e-03, 5.8074e-03, 2.9304e-03, 1.3618e-04, 5.9787e-03, 1.1189e-02,\n",
      "        1.9415e-03, 8.6538e-03, 8.0615e-03, 1.4988e-03, 7.5393e-03, 6.5122e-03,\n",
      "        6.6503e-03, 2.7377e-03, 4.8420e-03, 1.4105e-03, 1.4962e-03, 3.8150e-03,\n",
      "        7.7938e-03, 7.0115e-04, 2.4628e-03, 9.0810e-04, 2.5820e-03, 2.2256e-03,\n",
      "        4.5615e-03, 3.2142e-03, 2.6144e-03, 4.2122e-03, 1.8767e-03, 2.8058e-03,\n",
      "        3.5514e-03, 6.4083e-03, 9.1819e-03, 3.4922e-03, 2.0869e-03, 1.7120e-03,\n",
      "        2.5493e-03, 3.4513e-03, 2.1516e-03, 3.9790e-03, 4.9661e-03, 2.7305e-03,\n",
      "        3.5566e-03, 2.2462e-03, 4.0786e-03, 5.1810e-03, 2.9077e-03, 9.2634e-03,\n",
      "        3.6219e-03, 3.7860e-03, 0.0000e+00, 8.9350e-03, 1.7282e-03, 6.2943e-03,\n",
      "        2.0623e-03, 3.9977e-03, 1.2699e-03, 2.0055e-03, 2.9720e-04, 1.4745e-02]) tensor(0.0457) tensor(4.7666)\n",
      "Chosen edges: tensor([[ 4,  4,  4, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 12],\n",
      "        [ 2, 51, 63,  2,  3, 15, 16, 37, 43, 47, 48, 51, 52, 63, 63]]) 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 32.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/50 | Train Loss: 1.9469 | Val Loss: 24.4340 | Val Accuracy: 0.3530\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 35.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/50 | Train Loss: 1.9398 | Val Loss: 24.3894 | Val Accuracy: 0.3553\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 32.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/50 | Train Loss: 1.9386 | Val Loss: 24.3772 | Val Accuracy: 0.3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 34.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/50 | Train Loss: 1.9379 | Val Loss: 24.3471 | Val Accuracy: 0.3559\n",
      "len_choose=[960, 15]\n",
      "Edge metrics: tensor([3.5340e-03, 1.8548e-03, 2.0615e-03, 2.2365e-03, 2.9461e-03, 4.5108e-03,\n",
      "        1.5433e-03, 8.7807e-05, 2.7144e-03, 4.8480e-03, 3.8451e-03, 4.7050e-04,\n",
      "        9.2388e-04, 3.1904e-03, 6.4095e-04, 1.5535e-03, 3.2296e-03, 2.0662e-03,\n",
      "        1.0268e-03, 1.3574e-03, 3.3077e-03, 2.1889e-03, 2.6276e-03, 2.3989e-03,\n",
      "        1.7914e-03, 2.4402e-03, 1.4158e-03, 2.7348e-03, 3.5685e-03, 3.7337e-03,\n",
      "        8.8396e-04, 6.0223e-03, 3.6970e-03, 3.1823e-03, 1.8901e-03, 1.9844e-03,\n",
      "        1.8863e-03, 2.8538e-03, 2.3939e-03, 3.3285e-03, 1.7976e-03, 2.9749e-03,\n",
      "        3.2054e-03, 8.7548e-04, 8.7506e-04, 1.8374e-03, 9.8553e-04, 1.2671e-03,\n",
      "        1.2003e-03, 5.2095e-03, 1.4828e-03, 1.2363e-03, 4.0678e-03, 9.4524e-04,\n",
      "        0.0000e+00, 3.1885e-03, 3.2911e-03, 2.1429e-03, 4.3618e-03, 1.2426e-03,\n",
      "        2.7808e-03, 1.6235e-03, 4.0200e-04, 5.1268e-03, 9.4767e-03, 1.8555e-03,\n",
      "        6.0972e-03, 6.4646e-03, 5.3755e-03, 7.7957e-03, 6.8364e-03, 5.4695e-04,\n",
      "        4.4071e-03, 1.3090e-02, 3.2368e-03, 4.8604e-03, 3.7748e-03, 4.0561e-03,\n",
      "        4.0045e-03, 6.3493e-03, 1.4649e-02, 1.0815e-02, 4.3151e-03, 7.0018e-03,\n",
      "        3.8082e-03, 6.2861e-03, 6.5376e-03, 1.4137e-03, 8.2370e-03, 1.0890e-03,\n",
      "        8.7311e-03, 7.9751e-03, 1.0420e-02, 7.3696e-03, 9.9599e-03, 8.1869e-03,\n",
      "        3.7050e-03, 5.9473e-03, 4.3350e-03, 7.1714e-03, 5.1147e-03, 1.0083e-02,\n",
      "        5.0892e-03, 3.3421e-03, 3.7262e-03, 6.5727e-03, 5.8527e-03, 9.2033e-03,\n",
      "        6.8770e-03, 5.0953e-03, 6.4627e-03, 6.6096e-03, 1.3145e-02, 5.5748e-03,\n",
      "        6.5790e-03, 1.7676e-02, 7.9716e-03, 7.5821e-03, 0.0000e+00, 8.6726e-03,\n",
      "        3.9393e-03, 6.5292e-03, 4.2414e-03, 8.8045e-03, 1.9724e-03, 5.9364e-03,\n",
      "        1.3714e-03, 2.1863e-02, 4.1384e-04, 1.7318e-04, 4.0545e-04, 1.5505e-04,\n",
      "        1.2245e-04, 6.8242e-04, 2.2111e-04, 6.9921e-06, 3.8903e-04, 8.0302e-04,\n",
      "        3.5130e-04, 1.8684e-04, 1.9563e-04, 1.8145e-04, 1.8297e-04, 2.4490e-04,\n",
      "        5.7731e-04, 2.0719e-04, 1.8452e-04, 1.0233e-04, 2.1300e-04, 3.5499e-04,\n",
      "        4.6510e-04, 2.2129e-04, 1.8465e-04, 1.5811e-04, 1.9236e-04, 3.4218e-04,\n",
      "        3.5206e-04, 5.1088e-04, 1.7129e-04, 7.3256e-04, 3.7702e-04, 2.9121e-04,\n",
      "        3.1784e-04, 3.6561e-04, 3.5599e-04, 3.0383e-04, 2.8724e-04, 3.2765e-04,\n",
      "        1.9563e-04, 2.0863e-04, 3.4306e-04, 1.9641e-04, 1.4218e-04, 1.9396e-04,\n",
      "        7.9528e-05, 8.6699e-05, 2.4401e-04, 6.3281e-04, 1.2731e-04, 4.9721e-04,\n",
      "        3.9287e-04, 2.2992e-04, 0.0000e+00, 4.9602e-04, 2.6210e-04, 3.9213e-04,\n",
      "        4.0064e-04, 2.6900e-04, 2.7651e-04, 1.3518e-04, 8.7504e-05, 9.0082e-04,\n",
      "        5.4150e-03, 1.2322e-03, 1.3190e-02, 7.1040e-03, 3.2978e-03, 7.4613e-03,\n",
      "        4.3758e-03, 9.3293e-04, 6.0903e-03, 2.0196e-02, 2.3402e-03, 1.1340e-02,\n",
      "        8.7211e-03, 1.8209e-03, 8.6879e-03, 9.6313e-03, 1.1022e-02, 5.6487e-03,\n",
      "        6.0615e-03, 2.9858e-03, 1.8074e-03, 6.8757e-03, 1.2165e-02, 1.1654e-03,\n",
      "        4.3972e-03, 1.2441e-03, 5.2969e-03, 4.8134e-03, 7.6482e-03, 5.2538e-03,\n",
      "        5.3744e-03, 8.2942e-03, 2.5207e-03, 6.0803e-03, 5.4265e-03, 8.2662e-03,\n",
      "        1.2199e-02, 5.5626e-03, 3.6301e-03, 2.0058e-03, 6.0690e-03, 7.0567e-03,\n",
      "        4.2775e-03, 5.6018e-03, 8.3618e-03, 3.6900e-03, 5.1264e-03, 2.6765e-03,\n",
      "        7.3091e-03, 5.7286e-03, 4.2428e-03, 1.5982e-02, 5.6216e-03, 5.9761e-03,\n",
      "        0.0000e+00, 1.5082e-02, 2.5900e-03, 9.6695e-03, 2.5583e-03, 6.1161e-03,\n",
      "        1.4277e-03, 3.6572e-03, 1.8280e-03, 2.3276e-02, 5.3808e-03, 1.3929e-03,\n",
      "        1.5967e-02, 1.1972e-02, 7.4727e-03, 4.0829e-03, 3.4810e-04, 5.1321e-03,\n",
      "        2.2124e-02, 3.8130e-03, 1.1133e-02, 7.2639e-03, 3.5803e-03, 6.9209e-03,\n",
      "        1.8260e-02, 1.8200e-02, 7.7665e-03, 4.7283e-03, 2.8514e-03, 5.8178e-03,\n",
      "        2.8708e-03, 8.0628e-03, 1.8631e-03, 6.2579e-03, 1.6308e-03, 8.0021e-03,\n",
      "        3.9043e-03, 1.8777e-02, 4.6668e-03, 1.2565e-02, 9.3705e-03, 4.4061e-03,\n",
      "        1.1497e-02, 3.3047e-03, 6.7485e-03, 7.8108e-03, 1.7939e-02, 5.9751e-03,\n",
      "        3.5571e-03, 4.8110e-03, 1.4033e-02, 2.7368e-03, 1.6492e-02, 1.5382e-02,\n",
      "        8.9171e-03, 1.1300e-02, 1.2645e-02, 1.8744e-02, 5.1330e-03, 1.3270e-02,\n",
      "        1.5737e-02, 1.2282e-02, 0.0000e+00, 2.0703e-02, 7.0846e-03, 6.2362e-03,\n",
      "        5.0064e-03, 5.1146e-03, 2.1377e-03, 1.2523e-02, 6.7075e-04, 1.5042e-03,\n",
      "        7.9547e-04, 7.4788e-03, 5.9809e-03, 1.7799e-03, 5.9898e-03, 1.4853e-03,\n",
      "        4.5696e-04, 5.4271e-03, 1.4387e-02, 7.2679e-04, 9.2559e-03, 5.9930e-03,\n",
      "        6.0097e-04, 6.4957e-03, 6.4549e-03, 6.0604e-03, 2.8182e-03, 4.4965e-03,\n",
      "        1.7677e-03, 5.5580e-04, 3.5102e-03, 8.5830e-03, 3.4716e-04, 2.5242e-03,\n",
      "        2.8069e-04, 2.1812e-03, 1.3215e-03, 2.7762e-03, 2.6731e-03, 2.5932e-03,\n",
      "        5.2917e-03, 1.1755e-03, 2.2087e-03, 4.3413e-03, 6.5166e-03, 7.8206e-03,\n",
      "        2.8200e-03, 1.0898e-03, 8.3477e-04, 4.6121e-03, 3.0584e-03, 1.2625e-03,\n",
      "        3.3625e-03, 6.4627e-03, 2.0298e-03, 6.7918e-03, 2.8270e-03, 3.4133e-03,\n",
      "        4.1544e-03, 2.4773e-03, 1.4349e-02, 2.0308e-03, 7.0797e-03, 0.0000e+00,\n",
      "        9.0874e-03, 6.1470e-04, 6.0848e-03, 8.7193e-04, 2.2736e-03, 6.6135e-04,\n",
      "        1.6010e-03, 1.2441e-03, 1.7849e-02, 3.6713e-03, 9.2275e-04, 4.9354e-03,\n",
      "        2.2999e-03, 1.1403e-03, 9.6232e-03, 3.8653e-03, 5.8900e-04, 6.2076e-03,\n",
      "        1.2154e-02, 2.2367e-03, 5.8549e-03, 6.0112e-03, 1.8344e-03, 6.1663e-03,\n",
      "        3.5837e-03, 8.9012e-03, 2.9254e-03, 6.3454e-03, 1.9252e-03, 1.2239e-03,\n",
      "        6.6516e-03, 9.9609e-03, 1.1097e-03, 2.2100e-03, 8.9365e-04, 2.2785e-03,\n",
      "        3.5346e-03, 2.6100e-03, 6.4641e-03, 2.2215e-03, 8.8205e-03, 3.0459e-03,\n",
      "        2.6901e-03, 5.4862e-03, 7.3506e-03, 8.1312e-03, 2.5556e-03, 1.8722e-03,\n",
      "        2.2288e-03, 4.4829e-03, 2.4305e-03, 2.9280e-03, 2.1423e-03, 2.9677e-03,\n",
      "        2.0609e-03, 1.6351e-03, 1.1229e-03, 3.0335e-03, 8.4514e-03, 1.5182e-03,\n",
      "        5.9439e-03, 2.5014e-03, 4.8582e-03, 0.0000e+00, 8.1986e-03, 1.3949e-03,\n",
      "        8.4979e-03, 2.6971e-03, 6.3479e-03, 1.5495e-03, 1.4161e-03, 1.9390e-03,\n",
      "        1.1168e-02, 4.2745e-03, 1.3405e-03, 9.0208e-03, 3.8527e-03, 1.5574e-03,\n",
      "        7.0400e-03, 4.3445e-03, 7.2718e-04, 5.4956e-03, 1.4800e-02, 1.5944e-03,\n",
      "        6.2253e-03, 6.5867e-03, 1.5877e-03, 6.4435e-03, 6.3628e-03, 7.0266e-03,\n",
      "        7.2585e-03, 6.3047e-03, 4.8848e-03, 9.3426e-04, 5.3240e-03, 9.8963e-03,\n",
      "        4.8860e-04, 6.9998e-03, 4.9882e-04, 4.2377e-03, 3.1014e-03, 5.7890e-03,\n",
      "        5.6766e-03, 3.1271e-03, 4.6113e-03, 1.5707e-03, 2.8484e-03, 4.5100e-03,\n",
      "        8.2981e-03, 9.2885e-03, 2.8210e-03, 2.6137e-03, 1.7022e-03, 5.2010e-03,\n",
      "        3.2615e-03, 4.1625e-03, 2.6443e-03, 4.4903e-03, 3.9952e-03, 2.8930e-03,\n",
      "        1.4746e-03, 4.3484e-03, 5.7604e-03, 2.0561e-03, 7.7045e-03, 3.3751e-03,\n",
      "        3.9565e-03, 0.0000e+00, 1.0453e-02, 1.5360e-03, 8.8585e-03, 2.0939e-03,\n",
      "        5.3618e-03, 1.0475e-03, 2.0411e-03, 1.5318e-03, 1.3997e-02, 7.4577e-03,\n",
      "        2.9805e-03, 8.0966e-03, 3.8237e-03, 2.6021e-03, 1.0312e-02, 6.0427e-03,\n",
      "        6.6936e-04, 4.6531e-03, 1.6395e-02, 1.7495e-03, 5.2872e-03, 5.0735e-03,\n",
      "        2.2644e-03, 5.4082e-03, 5.3153e-03, 1.0797e-02, 7.6357e-03, 5.4308e-03,\n",
      "        6.0373e-03, 2.1511e-03, 9.9126e-03, 1.1586e-02, 7.8617e-04, 6.0714e-03,\n",
      "        1.0019e-03, 5.3692e-03, 6.8855e-03, 8.7109e-03, 9.6721e-03, 6.0239e-03,\n",
      "        7.5778e-03, 2.5513e-03, 2.7385e-03, 6.6869e-03, 1.0487e-02, 8.1137e-03,\n",
      "        6.2934e-03, 3.5967e-03, 1.8736e-03, 3.5767e-03, 3.3014e-03, 6.7838e-03,\n",
      "        5.1183e-03, 3.8226e-03, 4.4298e-03, 2.5278e-03, 2.5359e-03, 8.1520e-03,\n",
      "        9.4656e-03, 3.1101e-03, 1.1443e-02, 6.7429e-03, 7.4733e-03, 0.0000e+00,\n",
      "        8.1295e-03, 2.1433e-03, 1.0130e-02, 2.0173e-03, 9.1211e-03, 1.3338e-03,\n",
      "        4.3660e-03, 2.2339e-03, 1.8516e-02, 3.5654e-03, 1.5866e-03, 1.0434e-03,\n",
      "        6.4588e-04, 5.4738e-04, 2.1359e-03, 2.1072e-03, 8.2007e-04, 6.0419e-04,\n",
      "        3.3976e-03, 2.5677e-04, 7.8627e-04, 7.2399e-04, 6.2431e-04, 6.8535e-04,\n",
      "        9.0235e-04, 2.4374e-03, 4.0147e-03, 2.1584e-03, 4.4153e-03, 2.6928e-04,\n",
      "        4.5784e-03, 2.8131e-03, 7.0099e-05, 3.5870e-03, 1.0924e-04, 1.5838e-03,\n",
      "        1.9879e-03, 2.2752e-03, 3.8568e-03, 1.4217e-03, 1.0888e-03, 3.0410e-04,\n",
      "        4.7611e-04, 3.1132e-03, 2.7351e-03, 7.7147e-04, 1.3217e-03, 9.6347e-04,\n",
      "        2.4699e-04, 5.2505e-04, 3.5304e-04, 3.3924e-03, 9.2452e-04, 6.3557e-04,\n",
      "        2.4617e-03, 5.1833e-04, 5.3854e-04, 2.2091e-03, 2.4710e-03, 6.2051e-04,\n",
      "        2.1508e-03, 1.4127e-03, 1.6076e-03, 0.0000e+00, 1.3283e-03, 3.8609e-04,\n",
      "        2.6128e-03, 3.4519e-04, 3.6089e-03, 1.5824e-04, 8.6899e-04, 4.5931e-04,\n",
      "        4.0583e-03, 4.2558e-03, 1.0494e-03, 1.3586e-02, 6.2759e-03, 4.1916e-03,\n",
      "        1.8009e-04, 4.4903e-03, 1.5298e-02, 4.5734e-03, 7.5009e-03, 3.7739e-03,\n",
      "        3.1781e-03, 4.2841e-03, 6.7148e-03, 2.3535e-03, 2.7552e-03, 6.6735e-03,\n",
      "        2.7534e-03, 4.2925e-03, 2.2183e-03, 4.8254e-03, 2.0932e-03, 6.2356e-03,\n",
      "        5.0417e-03, 1.6596e-02, 3.5772e-03, 1.1344e-02, 7.8662e-03, 3.7188e-03,\n",
      "        1.1327e-02, 2.3569e-03, 4.1418e-03, 5.2236e-03, 6.4542e-03, 4.3055e-03,\n",
      "        2.7923e-03, 1.3409e-02, 2.4557e-03, 1.5669e-02, 7.4811e-03, 1.2314e-02,\n",
      "        4.3339e-03, 1.3477e-02, 9.3562e-03, 0.0000e+00, 1.5383e-02, 7.5280e-03,\n",
      "        4.3808e-03, 5.3183e-03, 4.5987e-03, 2.3150e-03, 1.2910e-02, 6.2985e-04,\n",
      "        1.2550e-03, 8.6299e-04, 6.9039e-03, 4.4556e-03, 3.5857e-03, 4.8195e-03,\n",
      "        1.5440e-03, 1.4474e-04, 4.7687e-03, 9.2211e-03, 3.9678e-03, 3.8352e-03,\n",
      "        3.7944e-03, 2.1279e-03, 3.4535e-03, 5.0350e-03, 5.3693e-03, 1.9856e-03,\n",
      "        2.8627e-03, 1.0524e-03, 1.9797e-03, 1.7653e-03, 6.2029e-03, 9.8017e-04,\n",
      "        1.8394e-03, 1.2649e-03, 1.8795e-03, 1.0391e-03, 4.6179e-03, 2.3426e-03,\n",
      "        2.5253e-03, 6.6490e-03, 6.0543e-03, 5.2810e-03, 2.0218e-03, 4.4042e-03,\n",
      "        6.0323e-03, 3.2605e-03, 1.5970e-03, 5.0229e-03, 3.0400e-03, 4.9313e-03,\n",
      "        1.3669e-03, 3.6236e-03, 3.7381e-03, 2.5856e-03, 2.4480e-03, 2.7925e-03,\n",
      "        3.7317e-03, 4.4629e-03, 2.9534e-03, 8.2151e-03, 3.5207e-03, 2.0060e-03,\n",
      "        0.0000e+00, 7.9258e-03, 3.2351e-03, 4.6154e-03, 5.8171e-03, 2.0792e-03,\n",
      "        1.1667e-03, 2.5856e-03, 4.6804e-04, 1.1949e-02, 7.0851e-03, 2.0111e-03,\n",
      "        1.1583e-02, 7.4572e-03, 5.3705e-03, 6.3452e-03, 3.8339e-03, 6.8896e-04,\n",
      "        3.5550e-03, 1.5747e-02, 2.5027e-03, 5.9769e-03, 4.5101e-03, 2.6890e-03,\n",
      "        4.5338e-03, 9.3534e-03, 1.0499e-02, 6.9601e-03, 5.3396e-03, 4.5160e-03,\n",
      "        3.6648e-03, 5.0225e-03, 8.0689e-03, 9.4701e-04, 6.3795e-03, 7.2653e-04,\n",
      "        6.4504e-03, 4.9237e-03, 1.1925e-02, 5.4212e-03, 7.5852e-03, 5.7700e-03,\n",
      "        2.6329e-03, 5.7842e-03, 4.5694e-03, 6.1046e-03, 6.9808e-03, 8.6793e-03,\n",
      "        4.9210e-03, 2.5315e-03, 3.1429e-03, 6.9938e-03, 4.0324e-03, 7.7391e-03,\n",
      "        7.3194e-03, 6.7261e-03, 5.9705e-03, 5.8109e-03, 1.1361e-02, 5.7731e-03,\n",
      "        6.2361e-03, 1.4129e-02, 8.7909e-03, 4.9662e-03, 0.0000e+00, 1.0396e-02,\n",
      "        3.4500e-03, 6.5645e-03, 3.3461e-03, 4.6530e-03, 1.3410e-03, 6.6086e-03,\n",
      "        1.2202e-03, 3.8544e-03, 7.9901e-04, 6.6971e-03, 4.8257e-03, 5.1290e-03,\n",
      "        4.7085e-03, 2.9789e-03, 1.8223e-04, 3.5231e-03, 8.5054e-03, 2.3714e-03,\n",
      "        2.9715e-03, 2.6257e-03, 2.1355e-03, 2.7544e-03, 4.3206e-03, 7.0883e-03,\n",
      "        5.1876e-03, 1.7908e-03, 2.1332e-03, 2.4859e-03, 2.0964e-03, 5.9604e-03,\n",
      "        1.1726e-03, 4.0477e-03, 7.4612e-04, 4.5316e-03, 3.3366e-03, 9.5711e-03,\n",
      "        3.0628e-03, 6.2058e-03, 5.6475e-03, 2.9755e-03, 4.1650e-03, 1.8140e-03,\n",
      "        4.6052e-03, 4.4234e-03, 7.8447e-03, 3.7171e-03, 2.4642e-03, 2.3682e-03,\n",
      "        4.7243e-03, 2.0767e-03, 6.7767e-03, 3.4334e-03, 4.4379e-03, 3.1412e-03,\n",
      "        4.7707e-03, 8.6897e-03, 4.5407e-03, 4.4220e-03, 9.7362e-03, 7.6485e-03,\n",
      "        3.4240e-03, 0.0000e+00, 6.3900e-03, 3.1149e-03, 4.5749e-03, 2.9939e-03,\n",
      "        3.3465e-03, 1.4848e-03, 5.5095e-03, 4.5839e-04, 1.2685e-02, 2.1335e-03,\n",
      "        9.4928e-04, 9.0858e-03, 5.1883e-03, 2.7708e-03, 6.9725e-03, 2.8680e-03,\n",
      "        4.2359e-04, 6.8996e-03, 1.4072e-02, 1.8100e-03, 9.1619e-03, 7.8456e-03,\n",
      "        1.5046e-03, 7.6030e-03, 6.7515e-03, 7.3695e-03, 2.9105e-03, 5.3232e-03,\n",
      "        1.4911e-03, 1.6313e-03, 3.8606e-03, 8.2897e-03, 7.0629e-04, 2.4788e-03,\n",
      "        7.2913e-04, 2.3905e-03, 2.2056e-03, 4.7289e-03, 3.9315e-03, 2.6407e-03,\n",
      "        4.7821e-03, 2.0240e-03, 3.3961e-03, 3.8327e-03, 7.1286e-03, 9.2955e-03,\n",
      "        3.1974e-03, 1.9325e-03, 1.9960e-03, 3.0231e-03, 3.5728e-03, 2.0825e-03,\n",
      "        3.8598e-03, 5.4130e-03, 2.7148e-03, 4.1476e-03, 2.4939e-03, 4.1959e-03,\n",
      "        6.0029e-03, 3.0457e-03, 1.0453e-02, 3.3862e-03, 4.3441e-03, 0.0000e+00,\n",
      "        1.0735e-02, 1.7480e-03, 6.8292e-03, 2.3165e-03, 3.9344e-03, 1.1348e-03,\n",
      "        2.4128e-03, 1.2820e-03, 1.6619e-02, 1.9678e-03, 1.1745e-03, 3.4841e-03,\n",
      "        1.5504e-03, 1.8895e-03, 2.4431e-03, 8.5079e-04, 1.5930e-03, 2.3670e-03,\n",
      "        2.5752e-03, 1.3738e-03, 1.7496e-03, 1.8027e-03, 2.6958e-03, 1.6691e-03]) tensor(0.0233) tensor(4.2887)\n",
      "Chosen edges: tensor([[ 1,  1,  1,  1,  1,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  6,  7,  7,\n",
      "          8,  8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 12, 12, 12, 13, 14, 14],\n",
      "        [ 9, 16, 48, 51, 63,  2,  9, 22, 36, 51, 55, 63,  3,  4,  9, 15, 16, 28,\n",
      "         30, 37, 41, 43, 44, 47, 48, 50, 52, 53, 55, 61,  9, 51, 63,  9,  9, 63,\n",
      "          9, 63,  4,  9, 28, 41, 44, 46, 50, 55, 61, 63,  9, 28, 51, 63,  9, 63]]) 54\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 36.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/50 | Train Loss: 1.9340 | Val Loss: 24.3260 | Val Accuracy: 0.3545\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 33.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/50 | Train Loss: 1.9306 | Val Loss: 24.3200 | Val Accuracy: 0.3538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 38.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/50 | Train Loss: 1.9321 | Val Loss: 24.2822 | Val Accuracy: 0.3541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 33.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/50 | Train Loss: 1.9329 | Val Loss: 24.2802 | Val Accuracy: 0.3561\n",
      "len_choose=[960, 15, 54]\n",
      "Edge metrics: tensor([4.2369e-03, 2.5230e-03, 2.7471e-03, 2.4309e-03, 3.3015e-03, 6.0267e-03,\n",
      "        1.8617e-03, 3.4639e-04, 5.0265e-03, 5.7307e-03, 6.4335e-03, 3.5936e-04,\n",
      "        1.1110e-03, 5.1495e-03, 5.3547e-04, 1.4845e-03, 3.1281e-03, 2.3458e-03,\n",
      "        1.5029e-03, 1.4871e-03, 3.3537e-03, 2.5709e-03, 2.8785e-03, 1.9504e-03,\n",
      "        2.1264e-03, 2.5524e-03, 1.4665e-03, 3.3326e-03, 5.1595e-03, 4.2145e-03,\n",
      "        1.0688e-03, 8.5418e-03, 6.9365e-03, 5.2127e-03, 3.7212e-03, 2.4651e-03,\n",
      "        2.8219e-03, 3.5432e-03, 3.6769e-03, 5.5311e-03, 2.0959e-03, 4.2428e-03,\n",
      "        4.0130e-03, 9.8488e-04, 8.5992e-04, 3.4835e-03, 1.0917e-03, 1.4144e-03,\n",
      "        1.3398e-03, 6.5061e-03, 1.3244e-03, 1.2178e-03, 5.3655e-03, 9.6927e-04,\n",
      "        0.0000e+00, 3.4909e-03, 5.4529e-03, 2.4044e-03, 7.3110e-03, 1.1853e-03,\n",
      "        3.5683e-03, 1.6891e-03, 1.0220e-03, 5.2893e-03, 9.9442e-03, 1.7393e-03,\n",
      "        5.8584e-03, 6.4005e-03, 5.0987e-03, 7.2685e-03, 7.5403e-03, 1.4202e-03,\n",
      "        4.2983e-03, 3.5597e-03, 4.7792e-03, 4.1944e-03, 4.5980e-03, 3.8682e-03,\n",
      "        6.2613e-03, 1.1077e-02, 4.5616e-03, 7.2879e-03, 3.7885e-03, 5.8952e-03,\n",
      "        5.8731e-03, 1.5236e-03, 8.3746e-03, 1.3509e-03, 8.9464e-03, 8.6749e-03,\n",
      "        9.5180e-03, 7.1198e-03, 9.9445e-03, 7.5923e-03, 3.8428e-03, 6.0842e-03,\n",
      "        4.9772e-03, 7.8921e-03, 5.5421e-03, 1.0678e-02, 5.7873e-03, 3.2964e-03,\n",
      "        3.9254e-03, 6.7272e-03, 6.2130e-03, 9.6281e-03, 6.9267e-03, 6.5119e-03,\n",
      "        6.5177e-03, 6.7230e-03, 4.5812e-03, 6.0443e-03, 7.9564e-03, 6.7460e-03,\n",
      "        0.0000e+00, 8.4599e-03, 3.8953e-03, 6.4724e-03, 4.0832e-03, 8.1502e-03,\n",
      "        2.3942e-03, 5.6088e-03, 1.8073e-03, 4.3634e-04, 1.8289e-04, 3.7305e-04,\n",
      "        1.3801e-04, 1.0553e-04, 6.5857e-04, 2.4700e-04, 3.1041e-05, 3.5464e-04,\n",
      "        8.0781e-04, 3.8144e-04, 1.7862e-04, 2.1122e-04, 1.8907e-04, 1.7390e-04,\n",
      "        1.9551e-04, 5.3240e-04, 2.0157e-04, 1.9162e-04, 9.8081e-05, 1.9199e-04,\n",
      "        3.4894e-04, 4.0395e-04, 1.9590e-04, 1.8208e-04, 1.8133e-04, 1.8749e-04,\n",
      "        3.6712e-04, 3.1083e-04, 4.7525e-04, 1.6282e-04, 7.2261e-04, 3.9602e-04,\n",
      "        2.9947e-04, 3.6301e-04, 3.8541e-04, 3.8339e-04, 3.1069e-04, 3.0790e-04,\n",
      "        3.2725e-04, 2.0880e-04, 2.2819e-04, 3.5149e-04, 1.9770e-04, 1.4800e-04,\n",
      "        2.3270e-04, 7.0615e-05, 8.7521e-05, 2.3269e-04, 5.5662e-04, 1.0362e-04,\n",
      "        4.8380e-04, 3.6431e-04, 2.0291e-04, 0.0000e+00, 4.6699e-04, 2.7248e-04,\n",
      "        3.4463e-04, 4.0798e-04, 2.5153e-04, 2.7711e-04, 1.1856e-04, 1.3728e-04,\n",
      "        9.0205e-04, 5.5913e-03, 1.4827e-03, 7.1260e-03, 3.1296e-03, 7.6077e-03,\n",
      "        4.9942e-03, 1.7932e-03, 5.9123e-03, 2.6801e-03, 1.1690e-02, 9.4297e-03,\n",
      "        2.0389e-03, 8.8869e-03, 8.8173e-03, 1.0068e-02, 5.5871e-03, 6.3886e-03,\n",
      "        3.0660e-03, 1.8712e-03, 6.5507e-03, 1.1981e-03, 4.4435e-03, 1.5340e-03,\n",
      "        5.4215e-03, 5.1690e-03, 7.2211e-03, 4.9979e-03, 5.6202e-03, 8.3324e-03,\n",
      "        2.4554e-03, 5.9378e-03, 6.4120e-03, 9.2718e-03, 6.3051e-03, 3.9082e-03,\n",
      "        2.0826e-03, 6.4357e-03, 7.5557e-03, 4.4618e-03, 5.9121e-03, 9.4859e-03,\n",
      "        4.9825e-03, 4.9695e-03, 2.9668e-03, 7.7822e-03, 4.9802e-03, 3.6462e-03,\n",
      "        5.6603e-03, 5.9353e-03, 0.0000e+00, 2.8017e-03, 8.5237e-03, 2.6947e-03,\n",
      "        6.0733e-03, 1.6416e-03, 3.5565e-03, 2.4688e-03, 5.4735e-03, 1.5469e-03,\n",
      "        6.0742e-03, 4.4133e-03, 7.0910e-04, 4.7428e-03, 4.3541e-03, 1.0527e-02,\n",
      "        6.9872e-03, 4.1585e-03, 6.4778e-03, 7.4847e-03, 4.5665e-03, 2.7229e-03,\n",
      "        6.2824e-03, 2.3889e-03, 6.4068e-03, 1.9340e-03, 6.6429e-03, 2.0379e-03,\n",
      "        7.3239e-03, 4.0345e-03, 3.6610e-03, 7.5761e-03, 4.6312e-03, 1.1290e-02,\n",
      "        3.7903e-03, 6.6895e-03, 6.4756e-03, 6.6592e-03, 3.9170e-03, 4.4220e-03,\n",
      "        2.6295e-03, 1.0722e-02, 1.0939e-02, 3.9790e-03, 0.0000e+00, 7.2565e-03,\n",
      "        5.1574e-03, 4.7872e-03, 4.3342e-03, 2.5271e-03, 9.1478e-04, 1.6144e-03,\n",
      "        9.9457e-04, 7.0602e-03, 6.2109e-03, 1.4959e-03, 5.7623e-03, 1.6800e-03,\n",
      "        8.5565e-04, 5.0203e-03, 8.3103e-04, 9.6235e-03, 6.5279e-03, 6.5488e-04,\n",
      "        6.4141e-03, 5.6370e-03, 4.9324e-03, 2.7803e-03, 4.6123e-03, 1.7619e-03,\n",
      "        5.7650e-04, 3.4454e-03, 7.6659e-03, 2.9545e-04, 2.4598e-03, 3.4409e-04,\n",
      "        2.1295e-03, 1.4303e-03, 2.4928e-03, 2.1254e-03, 2.4255e-03, 5.2352e-03,\n",
      "        1.3293e-03, 2.4113e-03, 5.1733e-03, 7.2782e-03, 8.1485e-03, 2.8124e-03,\n",
      "        1.2204e-03, 8.7245e-04, 4.8612e-03, 3.3096e-03, 1.3912e-03, 3.2054e-03,\n",
      "        6.7781e-03, 2.5626e-03, 6.8892e-03, 2.5186e-03, 3.3522e-03, 3.4308e-03,\n",
      "        2.1478e-03, 1.9828e-03, 6.9976e-03, 0.0000e+00, 8.8997e-03, 5.7644e-04,\n",
      "        5.3800e-03, 9.5370e-04, 2.2278e-03, 6.6655e-04, 1.4679e-03, 1.6698e-03,\n",
      "        3.8754e-03, 1.0217e-03, 4.8750e-03, 2.2681e-03, 1.1403e-03, 9.6187e-03,\n",
      "        4.5744e-03, 1.2156e-03, 5.8926e-03, 2.4553e-03, 5.9568e-03, 6.4711e-03,\n",
      "        1.9824e-03, 6.0873e-03, 3.1291e-03, 8.1930e-03, 2.9366e-03, 6.8320e-03,\n",
      "        2.0227e-03, 1.1241e-03, 6.5672e-03, 9.1700e-03, 9.9456e-04, 2.2600e-03,\n",
      "        1.0277e-03, 2.3650e-03, 3.9068e-03, 2.4747e-03, 6.0437e-03, 2.1222e-03,\n",
      "        8.4166e-03, 3.3831e-03, 2.8072e-03, 6.6109e-03, 8.1359e-03, 8.5129e-03,\n",
      "        2.8127e-03, 2.0627e-03, 2.2159e-03, 4.8753e-03, 2.7404e-03, 3.2765e-03,\n",
      "        2.3410e-03, 3.4828e-03, 2.5064e-03, 1.5383e-03, 1.0624e-03, 3.1345e-03,\n",
      "        7.4656e-03, 1.2952e-03, 6.1432e-03, 2.5173e-03, 4.6178e-03, 0.0000e+00,\n",
      "        8.0402e-03, 1.5521e-03, 7.8769e-03, 2.7662e-03, 6.4579e-03, 1.6361e-03,\n",
      "        1.3658e-03, 2.5844e-03, 1.1933e-02, 4.4944e-03, 1.4347e-03, 8.5841e-03,\n",
      "        3.8797e-03, 1.3233e-03, 7.0297e-03, 4.8603e-03, 1.7061e-03, 5.2082e-03,\n",
      "        1.8091e-03, 6.3340e-03, 6.6193e-03, 1.8170e-03, 5.9858e-03, 5.5278e-03,\n",
      "        6.8624e-03, 7.4341e-03, 6.4386e-03, 5.0563e-03, 9.4213e-04, 5.2816e-03,\n",
      "        9.0667e-03, 3.6058e-04, 7.1580e-03, 5.6953e-04, 4.4218e-03, 3.7491e-03,\n",
      "        5.2845e-03, 5.3315e-03, 3.0191e-03, 4.6437e-03, 1.4861e-03, 2.7540e-03,\n",
      "        5.5351e-03, 8.9986e-03, 9.4364e-03, 3.1850e-03, 3.1065e-03, 1.6394e-03,\n",
      "        5.3605e-03, 3.4585e-03, 4.2971e-03, 2.6809e-03, 5.0105e-03, 4.6846e-03,\n",
      "        2.9407e-03, 1.5507e-03, 4.3905e-03, 5.3167e-03, 1.8492e-03, 8.8358e-03,\n",
      "        3.4211e-03, 3.7916e-03, 0.0000e+00, 9.9970e-03, 1.6304e-03, 8.1267e-03,\n",
      "        2.0202e-03, 5.0623e-03, 1.0176e-03, 2.1254e-03, 2.0489e-03, 7.1425e-03,\n",
      "        3.0315e-03, 7.7858e-03, 3.6553e-03, 2.5933e-03, 1.0089e-02, 6.3266e-03,\n",
      "        1.3996e-03, 4.4982e-03, 2.0220e-03, 5.5717e-03, 5.4535e-03, 2.4780e-03,\n",
      "        5.3677e-03, 4.7459e-03, 9.2922e-03, 6.9154e-03, 5.6918e-03, 5.8818e-03,\n",
      "        2.1050e-03, 9.2647e-03, 1.0383e-02, 7.1951e-04, 5.3550e-03, 1.1426e-03,\n",
      "        4.9926e-03, 6.6626e-03, 7.1049e-03, 8.8057e-03, 5.7502e-03, 7.5411e-03,\n",
      "        2.8917e-03, 2.8454e-03, 7.7699e-03, 1.1141e-02, 8.8269e-03, 5.8987e-03,\n",
      "        3.8338e-03, 1.9328e-03, 4.1135e-03, 3.4786e-03, 6.4328e-03, 5.2865e-03,\n",
      "        3.8467e-03, 5.1875e-03, 2.4272e-03, 2.6263e-03, 7.6289e-03, 8.3569e-03,\n",
      "        2.7731e-03, 1.2042e-02, 6.0792e-03, 6.8236e-03, 0.0000e+00, 8.0486e-03,\n",
      "        2.2134e-03, 9.0575e-03, 2.0256e-03, 8.1240e-03, 1.3737e-03, 4.0631e-03,\n",
      "        3.0376e-03, 3.5848e-03, 1.5636e-03, 1.0288e-03, 6.5198e-04, 4.8348e-04,\n",
      "        1.9685e-03, 2.3906e-03, 1.8849e-03, 5.7555e-04, 3.3784e-03, 2.9900e-04,\n",
      "        8.2019e-04, 7.9220e-04, 7.0467e-04, 6.9355e-04, 7.6012e-04, 2.0932e-03,\n",
      "        4.0608e-03, 2.2566e-03, 4.5818e-03, 2.6836e-04, 4.4830e-03, 2.4080e-03,\n",
      "        5.1705e-05, 3.7720e-03, 1.2719e-04, 1.6031e-03, 2.2320e-03, 1.8922e-03,\n",
      "        3.6686e-03, 1.3998e-03, 1.0988e-03, 3.2471e-04, 4.8436e-04, 3.6290e-03,\n",
      "        3.0569e-03, 9.0382e-04, 1.4373e-03, 1.0065e-03, 2.4356e-04, 5.8053e-04,\n",
      "        3.6621e-04, 3.5275e-03, 9.4154e-04, 6.5073e-04, 2.9067e-03, 5.4497e-04,\n",
      "        5.3537e-04, 2.2231e-03, 2.0648e-03, 5.3181e-04, 2.2633e-03, 1.4108e-03,\n",
      "        1.4442e-03, 0.0000e+00, 1.3184e-03, 3.9703e-04, 2.4419e-03, 3.3158e-04,\n",
      "        3.4289e-03, 1.6540e-04, 8.3113e-04, 7.1292e-04, 4.1898e-03, 4.6751e-03,\n",
      "        1.1261e-03, 6.2251e-03, 4.6905e-03, 8.4402e-04, 4.1193e-03, 4.9549e-03,\n",
      "        7.1305e-03, 4.6881e-03, 3.2146e-03, 4.1308e-03, 6.4349e-03, 2.5934e-03,\n",
      "        2.6196e-03, 8.7876e-03, 2.5629e-03, 3.8847e-03, 2.0069e-03, 4.7435e-03,\n",
      "        2.3019e-03, 6.3925e-03, 5.6508e-03, 3.2057e-03, 1.3765e-02, 8.4025e-03,\n",
      "        3.7239e-03, 1.2723e-02, 2.8097e-03, 4.5072e-03, 5.2630e-03, 8.1094e-03,\n",
      "        4.1205e-03, 2.9879e-03, 2.5205e-03, 9.8587e-03, 3.6127e-03, 1.0237e-02,\n",
      "        0.0000e+00, 8.0410e-03, 3.9919e-03, 5.3687e-03, 4.2670e-03, 2.3271e-03,\n",
      "        8.6650e-04, 1.3891e-03, 9.9434e-04, 6.7585e-03, 4.2411e-03, 3.3085e-03,\n",
      "        4.7078e-03, 1.7892e-03, 4.7546e-04, 4.5342e-03, 9.6715e-03, 5.2593e-03,\n",
      "        4.0749e-03, 4.1052e-03, 2.8394e-03, 3.4503e-03, 4.5811e-03, 4.9160e-03,\n",
      "        1.9724e-03, 2.9056e-03, 1.0340e-03, 2.1444e-03, 1.7389e-03, 5.7864e-03,\n",
      "        8.7770e-04, 1.8406e-03, 1.3626e-03, 1.8481e-03, 1.1326e-03, 4.2407e-03,\n",
      "        2.2058e-03, 2.4522e-03, 6.8512e-03, 6.5867e-03, 5.8152e-03, 2.3936e-03,\n",
      "        4.8216e-03, 6.3937e-03, 3.2635e-03, 1.8041e-03, 5.4710e-03, 3.3157e-03,\n",
      "        5.3083e-03, 1.4501e-03, 3.6837e-03, 3.8690e-03, 3.2770e-03, 2.3619e-03,\n",
      "        2.8081e-03, 3.6732e-03, 3.8917e-03, 2.6747e-03, 8.9493e-03, 3.5056e-03,\n",
      "        1.7220e-03, 0.0000e+00, 7.8152e-03, 3.5698e-03, 4.1591e-03, 6.4718e-03,\n",
      "        2.0337e-03, 1.2637e-03, 2.4272e-03, 6.5866e-04, 7.6497e-03, 2.0088e-03,\n",
      "        1.1508e-02, 6.9531e-03, 5.4424e-03, 6.3759e-03, 4.2466e-03, 1.9123e-03,\n",
      "        3.2406e-03, 2.8368e-03, 6.2209e-03, 4.9971e-03, 2.8895e-03, 4.6765e-03,\n",
      "        8.4461e-03, 1.0147e-02, 7.0834e-03, 5.3764e-03, 4.6550e-03, 3.9254e-03,\n",
      "        4.9414e-03, 7.0393e-03, 8.2056e-04, 6.3573e-03, 8.4292e-04, 6.4928e-03,\n",
      "        5.4073e-03, 5.2995e-03, 7.9992e-03, 5.7600e-03, 2.5678e-03, 5.8997e-03,\n",
      "        5.3146e-03, 6.1798e-03, 7.4868e-03, 9.4614e-03, 5.3957e-03, 2.4324e-03,\n",
      "        3.6931e-03, 7.1468e-03, 4.1514e-03, 8.2221e-03, 7.1444e-03, 8.3062e-03,\n",
      "        5.7778e-03, 6.0036e-03, 1.1700e-02, 5.0173e-03, 5.4733e-03, 8.9568e-03,\n",
      "        4.7998e-03, 0.0000e+00, 1.0498e-02, 3.7183e-03, 5.4823e-03, 3.0914e-03,\n",
      "        4.3796e-03, 1.3255e-03, 6.6167e-03, 1.6121e-03, 4.0927e-03, 9.1489e-04,\n",
      "        6.2082e-03, 4.6790e-03, 4.6917e-03, 4.6791e-03, 3.2539e-03, 5.4042e-04,\n",
      "        3.3766e-03, 8.7254e-03, 2.6825e-03, 3.1296e-03, 2.7047e-03, 2.3873e-03,\n",
      "        2.7472e-03, 3.9906e-03, 6.9429e-03, 5.1201e-03, 1.9426e-03, 2.0843e-03,\n",
      "        2.7944e-03, 1.9979e-03, 5.3506e-03, 1.2204e-03, 4.1633e-03, 9.6091e-04,\n",
      "        4.5121e-03, 3.6003e-03, 8.8972e-03, 2.6475e-03, 6.2727e-03, 5.6988e-03,\n",
      "        3.2582e-03, 4.4919e-03, 2.2307e-03, 5.0950e-03, 4.5859e-03, 7.9119e-03,\n",
      "        4.2503e-03, 2.6274e-03, 2.7536e-03, 4.8488e-03, 2.1056e-03, 6.9563e-03,\n",
      "        3.2774e-03, 5.3289e-03, 3.0621e-03, 4.8211e-03, 8.8407e-03, 3.8620e-03,\n",
      "        3.8567e-03, 1.0372e-02, 7.5000e-03, 3.2705e-03, 0.0000e+00, 6.0133e-03,\n",
      "        3.3025e-03, 4.1179e-03, 3.1601e-03, 3.1044e-03, 1.6859e-03, 5.1687e-03,\n",
      "        6.0445e-04, 2.1918e-03, 1.1420e-03, 8.4637e-03, 5.2747e-03, 2.6440e-03,\n",
      "        7.0348e-03, 3.2695e-03, 8.6059e-04, 6.8273e-03, 2.1309e-03, 9.1598e-03,\n",
      "        8.4871e-03, 1.7028e-03, 7.7088e-03, 5.8967e-03, 6.8111e-03, 2.8858e-03,\n",
      "        5.5059e-03, 1.4583e-03, 1.7197e-03, 3.6246e-03, 7.5410e-03, 6.5008e-04,\n",
      "        2.5475e-03, 9.4041e-04, 2.4025e-03, 2.5178e-03, 4.3920e-03, 3.7442e-03,\n",
      "        2.7150e-03, 4.9240e-03, 2.2379e-03, 3.4462e-03, 4.8024e-03, 7.6714e-03,\n",
      "        9.7048e-03, 3.3034e-03, 2.1277e-03, 2.0470e-03, 3.3461e-03, 3.8758e-03,\n",
      "        2.3645e-03, 3.9639e-03, 5.7991e-03, 3.2427e-03, 4.0948e-03, 2.4304e-03,\n",
      "        4.2208e-03, 5.3069e-03, 2.6591e-03, 1.1163e-02, 3.3008e-03, 3.9242e-03,\n",
      "        0.0000e+00, 1.0585e-02, 1.9200e-03, 6.1863e-03, 2.3854e-03, 4.0314e-03,\n",
      "        1.2213e-03, 2.1843e-03, 1.7782e-03, 1.6269e-03, 1.2402e-03, 2.8481e-03,\n",
      "        1.6994e-03, 1.7995e-03, 2.3433e-03, 9.1605e-04, 1.7420e-03, 2.5377e-03,\n",
      "        2.8316e-03, 1.3968e-03, 2.0887e-03, 1.9381e-03, 3.3063e-03, 1.8335e-03,\n",
      "        6.0623e-04, 5.1435e-04, 9.0239e-04, 3.3506e-04, 1.7888e-03, 8.6665e-04,\n",
      "        1.3794e-03, 5.9550e-04, 1.2686e-03, 5.9890e-04, 1.2565e-03, 1.9307e-03,\n",
      "        1.5935e-03, 1.5498e-03, 1.0305e-03, 2.0221e-03, 2.6110e-04, 1.2344e-03,\n",
      "        3.6823e-04, 1.0231e-03, 1.7090e-03, 1.4168e-03, 1.6123e-03, 1.3016e-03,\n",
      "        1.1987e-03, 1.4387e-03, 1.2707e-03, 3.6971e-08, 1.3832e-03, 1.2439e-03,\n",
      "        8.4434e-04, 1.4976e-03, 1.6094e-03, 4.1593e-04, 8.9573e-04, 7.0934e-04,\n",
      "        9.0459e-04, 1.6404e-03, 1.9069e-03, 4.5598e-04, 1.2022e-03, 1.6882e-03,\n",
      "        2.0694e-03, 1.4085e-03, 2.1307e-03, 1.0173e-03, 1.9062e-03, 7.7236e-04,\n",
      "        7.1649e-04, 3.0650e-04, 4.8308e-04, 6.4788e-04, 6.9065e-04, 8.0672e-04]) tensor(0.0138) tensor(3.6033)\n",
      "Chosen edges: tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,  5,  5,  5,  5,  5,  5,  6,\n",
      "          6,  6,  6,  6,  6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "          7,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          8,  8, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 12, 12, 12, 12,\n",
      "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 13, 13, 13, 13, 13,\n",
      "         13, 13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14],\n",
      "        [31, 32, 58,  0,  5,  6, 17, 19, 24, 26, 27, 28, 29, 30, 31, 35, 37, 43,\n",
      "         44, 52, 55, 59,  3,  5, 11, 12, 14, 15, 16, 28, 31, 35, 41, 44, 48, 57,\n",
      "         11, 12, 17, 26, 31, 33, 45, 46, 56,  2, 11, 22, 35, 36, 46, 53, 55,  5,\n",
      "         16, 22, 31, 35, 36, 49, 55, 57, 63,  2,  5, 17, 22, 24, 35, 36, 51, 55,\n",
      "         57,  0,  2,  5, 16, 17, 21, 22, 28, 29, 31, 34, 35, 36, 48, 49, 51, 55,\n",
      "         57, 59, 11, 20, 30, 31, 33, 38, 45, 53, 56,  9, 51, 55,  0,  2,  3, 15,\n",
      "         16, 17, 22, 30, 36, 37, 41, 43, 44, 45, 48, 52, 55,  9, 16, 28, 37, 43,\n",
      "         48, 51, 52,  2,  5, 11, 12, 14, 22, 35, 36, 51, 55]]) 139\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 27.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/50 | Train Loss: 1.9273 | Val Loss: 24.2603 | Val Accuracy: 0.3571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 27.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/50 | Train Loss: 1.9260 | Val Loss: 24.2256 | Val Accuracy: 0.3577\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 27.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/50 | Train Loss: 1.9254 | Val Loss: 24.2151 | Val Accuracy: 0.3585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 26.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/50 | Train Loss: 1.9251 | Val Loss: 24.2088 | Val Accuracy: 0.3597\n",
      "len_choose=[960, 15, 54, 139]\n",
      "Edge metrics: tensor([3.6524e-04, 5.2789e-04, 7.6194e-04, 3.9107e-04, 4.8437e-06, 7.2989e-04,\n",
      "        1.2088e-03, 1.5416e-07, 1.0318e-03, 1.2254e-03, 6.6398e-04, 6.8871e-04,\n",
      "        7.6178e-07, 8.2848e-04, 1.2002e-04, 3.9305e-04, 4.7075e-04, 6.3232e-04,\n",
      "        3.6793e-06, 8.1929e-04, 8.1992e-05, 5.6055e-04, 1.7818e-07, 3.3199e-04,\n",
      "        6.1207e-04, 9.1231e-04, 8.5853e-04, 8.4591e-04, 6.4448e-04, 5.1186e-06,\n",
      "        5.8675e-04, 6.5087e-04, 5.2974e-04, 3.2568e-04, 4.3488e-06, 6.9050e-04,\n",
      "        5.9089e-04, 4.4304e-04, 2.9035e-04, 3.8955e-04, 2.1997e-06, 1.1434e-03,\n",
      "        5.3018e-04, 1.2195e-03, 6.8700e-04, 1.0138e-04, 9.7298e-04, 1.1109e-04,\n",
      "        6.5514e-04, 7.2192e-04, 4.5967e-04, 9.9433e-04, 1.9292e-04, 4.2327e-04,\n",
      "        4.8300e-04, 3.3487e-04, 8.7506e-04, 6.1926e-04, 1.4883e-07, 8.5381e-04,\n",
      "        3.0677e-04, 6.7479e-04, 8.5761e-04, 1.8830e-08, 1.5278e-07, 6.7192e-04,\n",
      "        5.8646e-04, 6.5800e-04, 5.6513e-04, 9.0432e-04, 5.1899e-06, 7.1053e-04,\n",
      "        8.9176e-04, 4.6442e-04, 5.9777e-07, 2.9938e-04, 5.5422e-04, 7.6665e-04,\n",
      "        1.0292e-03, 4.6416e-04, 4.0790e-04, 8.9162e-04, 2.1775e-04, 6.8504e-04,\n",
      "        4.9233e-04, 2.1259e-04, 3.5507e-04, 5.7453e-04, 3.9776e-04, 2.2916e-07,\n",
      "        6.3360e-04, 1.1814e-03, 1.7260e-06, 1.1185e-03, 1.7729e-03, 5.5138e-04,\n",
      "        1.5021e-03, 6.0099e-04, 2.5304e-04, 1.4573e-03, 1.1115e-03, 3.7306e-04,\n",
      "        1.3726e-06, 2.0167e-07, 5.9984e-04, 8.5261e-04, 6.7549e-04, 1.0314e-03,\n",
      "        4.8125e-04, 5.0976e-04, 1.7036e-04, 1.3777e-04, 4.3372e-04, 6.6838e-04,\n",
      "        7.0807e-04, 6.3134e-04, 7.0466e-04, 2.8748e-07, 7.7594e-04, 8.0248e-04,\n",
      "        6.7974e-04, 7.0003e-08, 8.5906e-08, 2.1136e-04, 3.0615e-04, 5.2212e-04,\n",
      "        7.0829e-04, 2.3397e-04, 4.8966e-04, 2.9828e-04, 1.8370e-04, 5.3031e-04,\n",
      "        1.0237e-03, 7.7160e-04, 4.5615e-04, 5.8382e-04, 7.6735e-04, 1.2470e-06,\n",
      "        5.3257e-04]) tensor(0.0018) tensor(0.0743)\n",
      "Chosen edges: tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          2,  2],\n",
      "        [ 6,  8,  9, 25, 43, 45, 48, 53, 12, 15, 25, 34, 49, 53, 54, 57, 61, 62,\n",
      "          6, 31]]) 20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 23.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/50 | Train Loss: 1.9200 | Val Loss: 24.1971 | Val Accuracy: 0.3588\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 25.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/50 | Train Loss: 1.9145 | Val Loss: 24.1581 | Val Accuracy: 0.3587\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:01<00:00, 25.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/50 | Train Loss: 1.9157 | Val Loss: 24.1451 | Val Accuracy: 0.3596\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 24.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 31/50 | Train Loss: 1.9115 | Val Loss: 24.1097 | Val Accuracy: 0.3607\n",
      "len_choose=[960, 15, 54, 139, 20]\n",
      "Edge metrics: tensor([2.4615e-06, 2.0740e-04, 1.9546e-05, 6.4671e-04, 2.1284e-06, 3.4574e-07,\n",
      "        2.7247e-06, 5.1714e-07, 3.0925e-06, 1.3985e-04, 4.1531e-08, 3.0935e-06,\n",
      "        2.3961e-04, 2.0267e-06, 0.0000e+00, 3.9615e-04, 4.3908e-04, 2.4826e-06,\n",
      "        5.7151e-07, 9.9875e-07]) tensor(0.0006) tensor(0.0021)\n",
      "Chosen edges: tensor([[ 0,  0,  0],\n",
      "        [ 3, 18, 19]]) 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 20.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 32/50 | Train Loss: 1.9191 | Val Loss: 24.1177 | Val Accuracy: 0.3600\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 20.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 33/50 | Train Loss: 1.9111 | Val Loss: 24.0800 | Val Accuracy: 0.3631\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 23.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 34/50 | Train Loss: 1.9129 | Val Loss: 24.0754 | Val Accuracy: 0.3643\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 23.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 35/50 | Train Loss: 1.9100 | Val Loss: 24.0454 | Val Accuracy: 0.3630\n",
      "len_choose=[960, 15, 54, 139, 20, 3]\n",
      "Edge metrics: tensor([1.5296e-04, 7.6604e-07, 6.7721e-07]) tensor(0.0002) tensor(0.0002)\n",
      "Chosen edges: tensor([[0],\n",
      "        [0]]) 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 22.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 36/50 | Train Loss: 1.9031 | Val Loss: 24.0371 | Val Accuracy: 0.3642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 21.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 37/50 | Train Loss: 1.9078 | Val Loss: 24.0401 | Val Accuracy: 0.3634\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 19.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 38/50 | Train Loss: 1.9036 | Val Loss: 24.0135 | Val Accuracy: 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 21.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50 | Train Loss: 1.9060 | Val Loss: 24.0020 | Val Accuracy: 0.3650\n",
      "len_choose=[960, 15, 54, 139, 20, 3, 1]\n",
      "Edge metrics: tensor([0.0002]) tensor(0.0002) tensor(0.0002)\n",
      "Chosen edges: tensor([], size=(2, 0), dtype=torch.int64) 0\n",
      "Empty metric\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 21.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 40/50 | Train Loss: 1.9037 | Val Loss: 23.9983 | Val Accuracy: 0.3642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 21.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 41/50 | Train Loss: 1.9011 | Val Loss: 23.9896 | Val Accuracy: 0.3650\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 21.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 42/50 | Train Loss: 1.9015 | Val Loss: 23.9895 | Val Accuracy: 0.3628\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 22.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 43/50 | Train Loss: 1.8992 | Val Loss: 23.9803 | Val Accuracy: 0.3645\n",
      "len_choose=[960, 15, 54, 139, 20, 3, 1, 0]\n",
      "Edge metrics: tensor([1.6679e-03, 1.5908e-03, 2.4869e-03, 2.6996e-03, 4.2397e-04, 4.2162e-03,\n",
      "        9.0358e-05, 6.4197e-04, 2.8114e-03, 1.5033e-04, 6.1537e-04, 2.4295e-03,\n",
      "        1.5384e-03, 2.7697e-03, 1.8731e-03, 2.0597e-03, 1.9405e-03, 1.2455e-03,\n",
      "        1.0406e-03, 2.4513e-03, 2.3164e-03, 3.2701e-03, 8.3990e-04, 3.1568e-03,\n",
      "        2.5889e-03, 1.9910e-03, 1.5651e-03, 2.6201e-03, 2.2218e-03, 4.2327e-03,\n",
      "        5.6158e-04, 2.1999e-03, 2.5996e-03, 7.1255e-04, 9.5563e-04, 9.9027e-04,\n",
      "        4.4582e-03, 1.1488e-03, 2.7725e-04, 3.7526e-03, 0.0000e+00, 2.4410e-03,\n",
      "        3.0261e-03, 1.6075e-03, 8.3713e-04, 2.8928e-03, 1.1087e-03, 1.0747e-03,\n",
      "        4.1351e-03, 1.8684e-03, 5.9431e-03, 7.1192e-03, 6.5106e-03, 2.0274e-03,\n",
      "        3.9022e-03, 3.9355e-03, 4.7096e-03, 4.4907e-03, 4.0444e-03, 4.9097e-03,\n",
      "        4.1065e-03, 5.5341e-03, 6.4333e-03, 1.7755e-03, 4.3593e-03, 7.4447e-03,\n",
      "        5.6657e-03, 7.1634e-03, 4.2753e-03, 4.5735e-03, 6.5985e-03, 6.5947e-03,\n",
      "        7.5145e-03, 6.3938e-03, 6.2324e-03, 7.3876e-03, 4.6511e-03, 5.1639e-03,\n",
      "        2.6400e-03, 4.3441e-04, 1.4823e-04, 2.2272e-04, 6.2789e-05, 8.5888e-05,\n",
      "        4.8115e-04, 3.5215e-05, 2.6372e-04, 6.6262e-04, 3.8103e-04, 8.9116e-05,\n",
      "        1.3009e-04, 1.3138e-04, 1.0113e-04, 8.0963e-05, 3.6945e-04, 1.3377e-04,\n",
      "        1.5055e-04, 4.9411e-05, 1.9240e-04, 3.0438e-04, 2.6177e-04, 2.3035e-04,\n",
      "        1.1261e-04, 9.0706e-05, 1.3181e-04, 3.6849e-04, 1.7505e-04, 4.8649e-04,\n",
      "        1.0444e-04, 3.9399e-04, 2.0676e-04, 3.0859e-04, 2.4929e-04, 2.3252e-04,\n",
      "        2.7331e-04, 2.8124e-04, 3.7635e-04, 1.3154e-04, 1.1962e-04, 3.1451e-04,\n",
      "        1.1515e-04, 7.9714e-05, 1.4140e-04, 4.4976e-05, 4.6886e-05, 1.2436e-04,\n",
      "        4.9256e-04, 9.2899e-05, 1.6849e-04, 2.9525e-04, 1.1514e-04, 0.0000e+00,\n",
      "        3.3496e-04, 1.7992e-04, 2.2927e-04, 4.4214e-04, 2.1165e-04, 2.8574e-04,\n",
      "        6.8069e-05, 1.9607e-04, 7.5500e-04, 5.1758e-03, 1.9834e-03, 3.5778e-03,\n",
      "        5.0562e-03, 2.2138e-03, 4.6162e-03, 2.5820e-03, 1.9040e-03, 6.1500e-03,\n",
      "        7.0385e-03, 2.8957e-03, 2.0205e-03, 6.2605e-03, 1.2647e-03, 4.7168e-03,\n",
      "        6.8945e-04, 5.9357e-03, 4.4873e-03, 5.5148e-03, 6.0156e-03, 2.7005e-03,\n",
      "        6.9445e-03, 6.5422e-03, 6.2571e-03, 4.1407e-03, 2.4289e-03, 6.8928e-03,\n",
      "        4.2130e-03, 5.0268e-03, 5.0858e-03, 5.4751e-03, 2.6806e-03, 4.7294e-03,\n",
      "        5.7832e-03, 5.4414e-03, 6.5979e-03, 0.0000e+00, 2.8227e-03, 2.9436e-03,\n",
      "        6.3081e-03, 1.7632e-03, 3.3292e-03, 3.4147e-03, 5.8597e-03, 1.5634e-03,\n",
      "        7.1091e-03, 4.4802e-03, 1.1835e-03, 5.3421e-03, 4.4707e-03, 3.6815e-03,\n",
      "        7.2434e-03, 5.7594e-03, 2.4195e-03, 6.4443e-03, 2.4744e-03, 7.4627e-03,\n",
      "        2.0800e-03, 6.5891e-03, 1.1501e-03, 4.7464e-03, 5.4328e-03, 5.1907e-03,\n",
      "        3.7311e-03, 8.1456e-03, 8.4274e-03, 8.1289e-03, 4.6322e-03, 6.0370e-03,\n",
      "        3.1358e-03, 4.4741e-03, 0.0000e+00, 6.4893e-03, 5.8344e-03, 5.1560e-03,\n",
      "        2.9772e-03, 1.8320e-03, 1.7445e-03, 1.5200e-03, 6.5640e-03, 1.9055e-03,\n",
      "        4.6351e-03, 1.6378e-03, 1.1073e-03, 3.7250e-03, 8.9721e-04, 5.8429e-03,\n",
      "        5.3027e-04, 6.0994e-03, 5.2060e-03, 3.9219e-03, 3.0451e-03, 4.8825e-03,\n",
      "        1.7199e-03, 5.4877e-04, 3.5745e-03, 3.5378e-04, 2.5883e-03, 1.4757e-04,\n",
      "        2.3834e-03, 1.8265e-03, 2.4780e-03, 2.4140e-03, 2.9302e-03, 4.1198e-03,\n",
      "        1.3842e-03, 2.5263e-03, 5.1377e-03, 3.0260e-03, 1.4535e-03, 1.0593e-03,\n",
      "        4.2949e-03, 2.7960e-03, 1.3716e-03, 3.0122e-03, 7.0675e-03, 2.4229e-03,\n",
      "        2.2965e-03, 2.8665e-03, 2.6330e-03, 2.7655e-03, 1.9831e-03, 0.0000e+00,\n",
      "        4.9852e-04, 5.6239e-03, 1.0812e-03, 2.2988e-03, 7.7230e-04, 1.4722e-03,\n",
      "        2.3087e-03, 4.0452e-03, 1.0727e-03, 4.7903e-03, 1.6636e-03, 1.4100e-03,\n",
      "        4.5425e-03, 1.3315e-03, 5.1420e-03, 2.3980e-03, 5.5989e-03, 6.3464e-03,\n",
      "        1.8050e-03, 6.2580e-03, 2.4885e-03, 3.0416e-03, 7.7229e-03, 1.9165e-03,\n",
      "        9.5483e-04, 6.7076e-03, 9.9047e-04, 2.2192e-03, 3.4625e-04, 2.9421e-03,\n",
      "        4.5157e-03, 2.3601e-03, 7.2345e-03, 2.5399e-03, 3.4321e-03, 3.4350e-03,\n",
      "        6.8145e-03, 3.5906e-03, 2.5205e-03, 2.6380e-03, 4.7459e-03, 2.8462e-03,\n",
      "        3.4030e-03, 2.3202e-03, 3.5527e-03, 2.2754e-03, 1.8858e-03, 9.0790e-04,\n",
      "        3.0958e-03, 1.9120e-03, 5.1588e-03, 2.4902e-03, 5.0872e-03, 0.0000e+00,\n",
      "        1.3728e-03, 3.1242e-03, 7.1747e-03, 1.8554e-03, 1.3423e-03, 3.9612e-03,\n",
      "        4.3829e-03, 2.0476e-03, 3.1470e-03, 1.4605e-03, 5.0695e-03, 2.5656e-03,\n",
      "        4.6312e-03, 1.8174e-03, 6.2539e-03, 6.6871e-03, 1.6346e-03, 6.2969e-03,\n",
      "        4.3992e-03, 7.5771e-03, 7.7530e-03, 5.0727e-03, 7.2195e-04, 5.5115e-03,\n",
      "        3.1995e-04, 1.0229e-04, 5.3331e-03, 4.0842e-03, 4.9613e-03, 5.9372e-03,\n",
      "        3.3437e-03, 4.8731e-03, 1.6640e-03, 3.5584e-03, 5.8296e-03, 3.3188e-03,\n",
      "        3.2311e-03, 1.9799e-03, 6.5225e-03, 3.4055e-03, 4.2849e-03, 2.7655e-03,\n",
      "        4.9623e-03, 4.9825e-03, 3.4236e-03, 1.3471e-03, 4.1572e-03, 4.9406e-03,\n",
      "        2.8354e-03, 3.0815e-03, 4.4944e-03, 0.0000e+00, 1.2533e-03, 2.2754e-03,\n",
      "        5.6772e-03, 1.2357e-03, 2.0761e-03, 2.7056e-03, 4.0378e-03, 3.0568e-03,\n",
      "        3.0355e-03, 6.0290e-03, 2.0789e-03, 3.9859e-03, 2.1220e-03, 5.5068e-03,\n",
      "        5.5606e-03, 2.3853e-03, 5.3128e-03, 3.5543e-03, 6.9872e-03, 5.9599e-03,\n",
      "        1.8267e-03, 8.8473e-04, 6.1091e-03, 4.6957e-04, 6.0130e-03, 7.8711e-03,\n",
      "        6.5290e-03, 2.9591e-03, 3.0932e-03, 6.0230e-03, 4.3059e-03, 2.3471e-03,\n",
      "        4.1228e-03, 3.0720e-03, 6.7879e-03, 5.2726e-03, 3.9075e-03, 5.5453e-03,\n",
      "        3.2356e-03, 2.1050e-03, 3.2618e-03, 6.0829e-03, 8.0432e-03, 0.0000e+00,\n",
      "        2.0841e-03, 2.3840e-03, 1.6444e-03, 4.0584e-03, 4.5200e-03, 3.2624e-03,\n",
      "        1.8901e-03, 8.4846e-04, 6.4232e-04, 5.5130e-04, 1.4052e-03, 2.5662e-03,\n",
      "        2.5101e-03, 4.1981e-04, 4.7945e-03, 2.4225e-04, 7.3088e-04, 6.6951e-04,\n",
      "        6.3284e-04, 6.9736e-04, 5.0830e-04, 1.8657e-03, 5.1700e-03, 3.2032e-03,\n",
      "        5.1454e-03, 1.5785e-04, 4.7532e-03, 2.7210e-03, 4.4161e-05, 4.7111e-03,\n",
      "        1.8882e-05, 1.9672e-03, 2.2244e-03, 2.2310e-03, 3.9024e-03, 1.7308e-03,\n",
      "        8.9196e-04, 2.6330e-04, 4.5691e-04, 3.8426e-03, 4.3949e-03, 8.4731e-04,\n",
      "        1.6075e-03, 1.2721e-03, 2.3534e-04, 4.5892e-04, 2.3571e-04, 3.6234e-03,\n",
      "        9.1281e-04, 5.6020e-04, 3.3940e-03, 7.0158e-04, 3.1911e-04, 2.2014e-03,\n",
      "        1.8785e-03, 6.1000e-04, 2.0271e-03, 1.4394e-03, 1.8994e-03, 0.0000e+00,\n",
      "        1.2348e-03, 2.8415e-04, 2.2980e-03, 3.0766e-04, 3.7842e-03, 2.0295e-04,\n",
      "        7.8494e-04, 1.0247e-03, 5.7100e-03, 4.9201e-03, 1.1113e-03, 5.6810e-03,\n",
      "        3.9611e-03, 1.0076e-03, 3.7817e-03, 5.3621e-03, 4.4178e-03, 3.1806e-03,\n",
      "        4.1352e-03, 6.6236e-03, 2.5950e-03, 2.1995e-03, 2.3533e-03, 3.9633e-03,\n",
      "        2.1095e-03, 4.6538e-03, 1.7514e-03, 8.4020e-03, 6.2029e-03, 3.7270e-03,\n",
      "        4.1102e-03, 2.3795e-03, 4.9407e-03, 5.3409e-03, 4.9576e-03, 3.3535e-03,\n",
      "        2.4301e-03, 3.4908e-03, 0.0000e+00, 3.9699e-03, 6.5301e-03, 3.9770e-03,\n",
      "        2.6691e-03, 1.5057e-03, 1.4519e-03, 9.9265e-04, 6.8722e-03, 3.9102e-03,\n",
      "        3.9366e-03, 3.9940e-03, 1.7880e-03, 8.3612e-04, 4.0150e-03, 5.4355e-03,\n",
      "        4.3382e-03, 4.3515e-03, 1.9872e-03, 3.7665e-03, 4.2356e-03, 5.5359e-03,\n",
      "        2.3419e-03, 3.1021e-03, 9.5407e-04, 2.2140e-03, 1.6953e-03, 5.5866e-03,\n",
      "        1.0242e-03, 1.9342e-03, 5.5729e-04, 2.1428e-03, 1.2302e-03, 4.2413e-03,\n",
      "        2.6652e-03, 2.9764e-03, 6.2829e-03, 7.1537e-03, 6.1329e-03, 2.2026e-03,\n",
      "        4.6866e-03, 6.4855e-03, 3.1098e-03, 1.6542e-03, 6.9772e-03, 3.4451e-03,\n",
      "        4.8352e-03, 1.5455e-03, 3.6196e-03, 4.1178e-03, 3.5071e-03, 2.5469e-03,\n",
      "        2.8480e-03, 3.0969e-03, 3.9792e-03, 3.5506e-03, 3.8562e-03, 2.0673e-03,\n",
      "        0.0000e+00, 2.9053e-03, 4.4081e-03, 7.4729e-03, 1.9993e-03, 1.6702e-03,\n",
      "        2.6374e-03, 1.1301e-03, 2.5904e-03, 6.1801e-03, 6.4245e-03, 4.1567e-03,\n",
      "        2.9684e-03, 2.7305e-03, 2.9028e-03, 6.3376e-03, 5.1505e-03, 2.5493e-03,\n",
      "        4.5894e-03, 6.9548e-03, 5.2941e-03, 3.7001e-03, 5.2273e-03, 8.2974e-04,\n",
      "        7.4187e-03, 2.2213e-04, 7.2953e-03, 5.6014e-03, 5.6217e-03, 6.1404e-03,\n",
      "        2.8849e-03, 6.5544e-03, 5.7134e-03, 8.0900e-03, 5.9406e-03, 2.9819e-03,\n",
      "        4.4668e-03, 4.3506e-03, 5.5608e-03, 5.1808e-03, 4.6026e-03, 6.7079e-03,\n",
      "        6.2340e-03, 0.0000e+00, 4.0961e-03, 6.6673e-03, 3.5894e-03, 4.9964e-03,\n",
      "        1.5022e-03, 6.8492e-03, 2.5624e-03, 4.0002e-03, 1.1160e-03, 5.6702e-03,\n",
      "        4.6934e-03, 5.5342e-03, 4.0057e-03, 3.0438e-03, 7.8843e-04, 3.0280e-03,\n",
      "        2.6216e-03, 2.9650e-03, 2.9661e-03, 2.3308e-03, 2.9633e-03, 3.7879e-03,\n",
      "        5.7253e-03, 2.3524e-03, 1.6457e-03, 2.6202e-03, 1.8311e-03, 5.0738e-03,\n",
      "        1.3286e-03, 4.4836e-03, 4.8453e-04, 5.4023e-03, 3.1926e-03, 3.0978e-03,\n",
      "        7.1240e-03, 5.6346e-03, 3.5177e-03, 4.8277e-03, 1.8250e-03, 5.2201e-03,\n",
      "        4.7058e-03, 4.9930e-03, 3.1583e-03, 3.0128e-03, 4.5348e-03, 2.0546e-03,\n",
      "        3.1397e-03, 5.4802e-03, 3.1321e-03, 4.1395e-03, 3.7122e-03, 4.4016e-03,\n",
      "        3.3968e-03, 0.0000e+00, 6.9282e-03, 3.2503e-03, 4.2569e-03, 3.6354e-03,\n",
      "        2.8215e-03, 2.0099e-03, 5.3114e-03, 8.0174e-04, 2.1219e-03, 1.4293e-03,\n",
      "        5.0438e-03, 3.3271e-03, 3.0671e-03, 9.6883e-04, 5.4943e-03, 2.1876e-03,\n",
      "        1.5539e-03, 5.1122e-03, 6.9825e-03, 3.3160e-03, 5.5074e-03, 1.2576e-03,\n",
      "        1.7618e-03, 3.2346e-03, 6.0336e-04, 2.6851e-03, 2.8301e-04, 2.9227e-03,\n",
      "        2.5490e-03, 4.3653e-03, 4.0724e-03, 3.1804e-03, 4.3540e-03, 2.4247e-03,\n",
      "        3.7651e-03, 4.4661e-03, 3.2876e-03, 2.3229e-03, 2.4072e-03, 3.3572e-03,\n",
      "        3.7441e-03, 2.2280e-03, 3.5956e-03, 6.2056e-03, 3.1340e-03, 5.1470e-03,\n",
      "        2.2771e-03, 3.9155e-03, 4.7290e-03, 3.7507e-03, 3.4632e-03, 4.6153e-03,\n",
      "        0.0000e+00, 1.9916e-03, 5.9599e-03, 2.7260e-03, 4.1102e-03, 1.4474e-03,\n",
      "        2.2526e-03, 2.5451e-03, 1.7342e-03, 1.4777e-03, 4.8196e-03, 1.6907e-03,\n",
      "        1.9160e-03, 2.3682e-03, 1.0384e-03, 1.7715e-03, 2.3259e-03, 2.4196e-03,\n",
      "        1.4604e-03, 2.2877e-03, 2.4216e-03, 4.5316e-03, 2.4009e-03, 1.1148e-03,\n",
      "        4.5475e-04, 9.0837e-04, 6.1727e-04, 2.3604e-03, 8.5889e-04, 1.5772e-03,\n",
      "        6.5808e-04, 9.1070e-04, 4.3546e-04, 1.2981e-03, 2.8733e-03, 1.7437e-03,\n",
      "        1.8803e-03, 2.1893e-03, 2.0416e-03, 2.3171e-04, 1.3069e-03, 6.9963e-04,\n",
      "        9.3995e-04, 1.6138e-03, 1.4732e-03, 1.5995e-03, 1.3163e-03, 1.1318e-03,\n",
      "        1.5719e-03, 1.4746e-03, 7.1364e-07, 1.6448e-03, 1.2214e-03, 1.3311e-03,\n",
      "        2.0955e-03, 2.4830e-03, 5.0471e-04, 7.1834e-04, 1.3482e-03, 1.1724e-03,\n",
      "        2.0992e-03, 2.3070e-03, 1.5311e-03, 1.4766e-03, 1.3974e-03, 1.7527e-03,\n",
      "        1.3788e-03, 2.2705e-03, 1.0379e-03, 2.3297e-03, 1.3036e-03, 1.2190e-03,\n",
      "        3.9256e-04, 5.5052e-04, 1.1392e-03, 1.0248e-03, 1.8470e-03, 3.1123e-04,\n",
      "        7.4551e-04, 8.8330e-04, 4.5405e-04, 3.1935e-06, 8.7381e-04, 1.4262e-03,\n",
      "        4.3288e-07, 7.8260e-04, 1.2600e-03, 4.8365e-04, 8.5682e-04, 2.7751e-07,\n",
      "        1.0976e-03, 2.1238e-07, 6.0392e-04, 4.5170e-04, 8.9444e-04, 5.3352e-06,\n",
      "        8.3623e-04, 1.0852e-07, 3.9654e-04, 2.9366e-07, 3.3484e-04, 6.8046e-04,\n",
      "        1.0038e-03, 7.8404e-04, 6.1841e-04, 6.2726e-04, 5.5845e-06, 4.9217e-04,\n",
      "        5.7444e-04, 5.4393e-04, 3.0517e-04, 5.6578e-06, 7.8270e-04, 6.6983e-04,\n",
      "        5.6769e-04, 5.8515e-04, 2.9141e-04, 5.8764e-08, 1.1243e-03, 6.9977e-04,\n",
      "        1.2324e-03, 6.4796e-04, 2.1413e-04, 7.4509e-04, 2.3472e-04, 6.2632e-04,\n",
      "        5.2494e-04, 1.0050e-03, 1.5839e-03, 2.1583e-04, 5.2175e-04, 5.3162e-04,\n",
      "        3.2336e-04, 7.3622e-04, 4.9630e-04, 1.9980e-07, 6.5925e-04, 2.9271e-04,\n",
      "        5.3926e-04, 1.1627e-03, 5.0101e-07, 7.8543e-08, 8.3893e-04, 4.7660e-04,\n",
      "        7.0656e-04, 5.9480e-04, 7.8906e-04, 7.7018e-06, 8.2773e-04, 7.6781e-04,\n",
      "        3.9446e-04, 5.6035e-08, 2.5360e-04, 4.0300e-04, 8.5866e-04, 1.0721e-03,\n",
      "        3.5579e-04, 3.9428e-04, 7.9239e-04, 1.1257e-04, 6.7080e-04, 8.3595e-04,\n",
      "        7.8944e-08, 2.9569e-04, 4.5104e-04, 4.2425e-04, 6.4434e-07, 4.6724e-04,\n",
      "        1.0766e-03, 1.4700e-06, 1.3640e-03, 2.1369e-03, 5.4308e-04, 1.2327e-03,\n",
      "        9.0719e-04, 5.1812e-04, 1.1036e-03, 1.2767e-03, 6.3423e-04, 4.8541e-07,\n",
      "        5.1331e-07, 7.4721e-04, 7.3268e-04, 6.8484e-04, 9.6007e-04, 4.9542e-04,\n",
      "        7.5919e-04, 1.2431e-04, 2.8790e-04, 4.1463e-04, 5.2535e-04, 7.7727e-04,\n",
      "        5.0075e-04, 6.7770e-04, 4.0178e-07, 6.0790e-04, 7.1534e-04, 7.8141e-04,\n",
      "        7.7510e-07, 8.4380e-08, 3.6275e-04, 3.0675e-04, 5.9331e-04, 6.4797e-04,\n",
      "        3.5218e-04, 5.5423e-04, 3.3346e-04, 1.7980e-04, 4.8177e-04, 9.7244e-04,\n",
      "        7.7502e-04, 4.1558e-04, 5.3575e-04, 8.1097e-04, 2.4497e-06, 6.8720e-04,\n",
      "        2.4889e-06, 2.3378e-04, 2.2605e-05, 5.5719e-04, 1.8624e-06, 3.6536e-07,\n",
      "        2.5932e-06, 5.1944e-07, 3.0893e-06, 3.2782e-08, 2.6884e-08, 4.0894e-06,\n",
      "        2.3302e-04, 4.2464e-06, 0.0000e+00, 4.1063e-04, 5.9032e-04, 3.1335e-06,\n",
      "        6.4794e-07, 8.6192e-07, 1.8410e-04, 1.3263e-06, 5.8924e-07, 3.4148e-04]) tensor(0.0084) tensor(2.4754)\n",
      "Chosen edges: tensor([[ 0,  0,  0,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,  1,\n",
      "          1,  1,  1,  1,  1,  1,  1,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,\n",
      "          3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  3,  4,  4,  4,  4,  4,  4,\n",
      "          4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  4,  5,  5,\n",
      "          5,  5,  5,  5,  5,  5,  5,  5,  6,  6,  6,  6,  6,  6,  6,  6,  6,  6,\n",
      "          6,  6,  6,  6,  6,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  7,\n",
      "          7,  7,  7,  7,  7,  7,  7,  7,  7,  7,  8,  8,  8,  8,  8,  8,  8,  8,\n",
      "          8,  8,  8,  8,  8,  8,  8,  8,  8,  8,  9,  9,  9,  9,  9,  9,  9, 10,\n",
      "         10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 10, 11, 11, 11, 11, 11, 11, 11,\n",
      "         11, 11, 11, 11, 11, 11, 11, 11, 11, 11, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "         12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12, 12,\n",
      "         12, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13, 13,\n",
      "         13, 13, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14, 14,  4, 10],\n",
      "        [10, 39, 49,  2,  3,  4, 11, 13, 18, 21, 22, 32, 33, 36, 38, 39, 40, 41,\n",
      "         42, 45, 46, 47, 50, 56, 58,  0,  6,  8, 17, 18, 21, 24, 26, 27, 29, 30,\n",
      "         33, 34, 37, 40, 43, 45, 46, 49, 50, 52, 53, 59,  0,  5,  6,  8, 10, 14,\n",
      "         18, 20, 22, 24, 27, 29, 32, 35, 36, 38, 39, 40, 49, 57, 58, 59,  3,  5,\n",
      "         12, 14, 15, 18, 34, 40, 44, 57,  2,  6,  8, 11, 12, 14, 18, 21, 27, 29,\n",
      "         34, 40, 51, 53, 59,  0,  6,  8, 11, 12, 14, 15, 16, 18, 19, 21, 26, 28,\n",
      "         29, 31, 34, 40, 42, 44, 45, 49, 53, 59,  6, 11, 12, 14, 18, 19, 24, 26,\n",
      "         27, 30, 37, 38, 42, 43, 45, 52, 53, 62,  9, 17, 19, 21, 24, 35, 63,  0,\n",
      "          5, 10, 12, 17, 24, 26, 27, 35, 36, 39, 58,  2, 10, 11, 12, 15, 16, 22,\n",
      "         28, 31, 32, 33, 35, 36, 39, 41, 57, 58,  4,  5, 11, 12, 14, 18, 19, 21,\n",
      "         24, 26, 27, 29, 31, 33, 34, 35, 38, 40, 42, 46, 47, 49, 50, 53, 57, 59,\n",
      "         61,  2,  3,  4, 17, 22, 24, 26, 30, 31, 33, 35, 36, 38, 41, 45, 50, 55,\n",
      "         57, 61,  3,  8, 15, 16, 18, 28, 31, 34, 44, 46, 49, 53, 57, 66, 77]]) 233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 19.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 44/50 | Train Loss: 1.8934 | Val Loss: 23.9424 | Val Accuracy: 0.3653\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 17.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 45/50 | Train Loss: 1.8984 | Val Loss: 23.9270 | Val Accuracy: 0.3657\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 22.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 46/50 | Train Loss: 1.8941 | Val Loss: 23.8968 | Val Accuracy: 0.3645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 22.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 47/50 | Train Loss: 1.8905 | Val Loss: 23.9033 | Val Accuracy: 0.3653\n",
      "len_choose=[960, 15, 54, 139, 20, 3, 1, 0, 233]\n",
      "Edge metrics: tensor([6.1053e-04, 8.4127e-04, 3.5564e-04, 4.6255e-04, 6.9990e-05, 5.7671e-04,\n",
      "        6.1863e-06, 8.7581e-04, 6.5068e-06, 4.5608e-06, 5.6475e-07, 4.2080e-04,\n",
      "        1.7620e-06, 1.2835e-04, 8.0840e-04, 2.8347e-04, 2.8406e-06, 4.4979e-07,\n",
      "        1.3847e-04, 5.1350e-04, 7.6242e-06, 1.3083e-06, 5.4038e-08, 2.0895e-04,\n",
      "        5.6272e-04, 9.6075e-06, 3.2555e-04, 8.6782e-05, 5.2240e-06, 2.3436e-04,\n",
      "        2.4717e-04, 4.7081e-06, 5.2405e-06, 1.7794e-06, 2.3040e-04, 6.9843e-06,\n",
      "        4.9652e-04, 2.0781e-04, 8.7972e-06, 8.3007e-04, 4.9737e-05, 1.5010e-06,\n",
      "        3.9571e-06, 2.3012e-04, 3.5389e-04, 4.7794e-06, 3.2395e-04, 5.9520e-04,\n",
      "        3.1504e-06, 4.4503e-06, 1.6211e-06, 1.9140e-07, 2.7060e-06, 3.6826e-04,\n",
      "        4.4459e-06, 2.0751e-04, 4.6223e-05, 2.2139e-04, 2.8918e-06, 4.9165e-06,\n",
      "        9.9392e-07, 3.6992e-08, 4.5584e-04, 1.1725e-04, 4.6246e-05, 2.0603e-04,\n",
      "        1.9905e-06, 7.3108e-05, 2.0302e-04, 4.3998e-06, 4.7897e-04, 1.6753e-06,\n",
      "        5.6507e-04, 5.9883e-04, 2.0018e-04, 8.5614e-05, 4.9507e-04, 7.0767e-06,\n",
      "        4.5281e-04, 3.4339e-04, 5.1023e-06, 5.4255e-04, 1.2138e-06, 1.8324e-06,\n",
      "        2.0462e-04, 2.1057e-04, 1.2056e-04, 9.3646e-04, 3.9284e-04, 6.0354e-04,\n",
      "        2.7405e-04, 1.7169e-04, 1.8862e-06, 1.3764e-04, 9.8181e-04, 1.3573e-06,\n",
      "        4.7425e-04, 3.3615e-07, 3.7190e-05, 5.8754e-04, 2.7099e-04, 2.2725e-07,\n",
      "        2.1361e-04, 4.8663e-04, 4.9305e-04, 4.1268e-04, 1.3673e-04, 1.3849e-04,\n",
      "        2.1154e-04, 1.4910e-04, 3.4729e-04, 6.4100e-04, 2.0512e-04, 1.0699e-06,\n",
      "        3.7525e-05, 2.3626e-04, 1.3496e-07, 5.3049e-04, 7.0485e-04, 4.3296e-06,\n",
      "        3.2011e-06, 3.3198e-06, 1.0666e-04, 3.5425e-04, 4.1499e-04, 3.1953e-04,\n",
      "        9.7712e-04, 5.6735e-04, 1.2334e-04, 4.2067e-04, 5.9552e-04, 2.7427e-04,\n",
      "        7.7403e-09, 2.6857e-04, 3.6768e-04, 2.4750e-04, 3.0761e-06, 8.1621e-04,\n",
      "        1.1429e-03, 7.3199e-04, 7.3398e-04, 6.5714e-07, 1.6790e-06, 2.9219e-06,\n",
      "        4.8590e-06, 2.7145e-04, 2.2319e-06, 7.9036e-05, 4.8003e-06, 3.7877e-04,\n",
      "        1.1162e-04, 5.0544e-06, 5.6581e-06, 1.0533e-04, 8.2346e-04, 2.3660e-04,\n",
      "        2.1250e-04, 2.2718e-06, 1.8063e-04, 2.2229e-06, 4.1735e-06, 2.0224e-06,\n",
      "        8.3154e-07, 2.5060e-04, 1.1697e-03, 3.8868e-04, 1.2606e-06, 1.2205e-04,\n",
      "        1.2964e-03, 1.4161e-04, 1.7057e-06, 1.2495e-03, 5.5989e-04, 2.5470e-07,\n",
      "        3.7229e-04, 4.4427e-04, 1.7618e-04, 7.2943e-06, 6.7267e-04, 3.6022e-04,\n",
      "        2.8306e-04, 5.4115e-04, 4.6922e-04, 3.7886e-04, 1.4578e-04, 2.4864e-04,\n",
      "        3.7352e-06, 1.6571e-04, 1.1834e-04, 1.8071e-07, 1.3834e-04, 6.7661e-04,\n",
      "        4.1323e-04, 9.6088e-05, 3.9245e-04, 3.5979e-04, 2.0016e-04, 4.7963e-04,\n",
      "        5.6492e-07, 1.8416e-04, 2.0150e-06, 1.9410e-04, 1.6678e-04, 4.4334e-06,\n",
      "        1.6053e-06, 5.1801e-04, 3.6785e-04, 2.1092e-04, 8.5259e-08, 4.3476e-06,\n",
      "        1.4193e-04, 2.0707e-06, 3.2911e-04, 2.9253e-06, 3.8889e-04, 3.9440e-04,\n",
      "        3.3710e-06, 8.8981e-05, 6.5836e-05, 3.2118e-04, 2.3461e-04, 3.6515e-07,\n",
      "        2.7096e-04, 3.2896e-06, 1.2294e-04, 1.0864e-04, 1.1658e-04, 3.7233e-04,\n",
      "        1.5482e-04, 2.0120e-04, 3.3564e-04, 4.4789e-03, 4.5875e-03]) tensor(0.0046) tensor(0.0649)\n",
      "Chosen edges: tensor([[7, 7],\n",
      "        [4, 7]]) 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 18.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 48/50 | Train Loss: 1.8940 | Val Loss: 23.8943 | Val Accuracy: 0.3654\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:03<00:00, 16.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/50 | Train Loss: 1.8891 | Val Loss: 23.8696 | Val Accuracy: 0.3663\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 51/51 [00:02<00:00, 19.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/50 | Train Loss: 1.8894 | Val Loss: 23.8573 | Val Accuracy: 0.3660\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "        .wandb-row {\n",
       "            display: flex;\n",
       "            flex-direction: row;\n",
       "            flex-wrap: wrap;\n",
       "            justify-content: flex-start;\n",
       "            width: 100%;\n",
       "        }\n",
       "        .wandb-col {\n",
       "            display: flex;\n",
       "            flex-direction: column;\n",
       "            flex-basis: 100%;\n",
       "            flex: 1;\n",
       "            padding: 10px;\n",
       "        }\n",
       "    </style>\n",
       "<div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>len</td><td>███▂▁▁▁█▃</td></tr><tr><td>len_choose</td><td>▁▃▅▂▁▁▁█▁</td></tr><tr><td>max</td><td>█▅▃▁▁▁▁▂▂</td></tr><tr><td>sum</td><td>█▇▆▁▁▁▁▅▁</td></tr><tr><td>train_loss</td><td>█▅▄▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▅▆▆▆▆▇▇▇▇▇▇▇▇▇▇▇▇▇▇▇█▇▇████████████████</td></tr><tr><td>val_loss</td><td>█▅▃▃▂▂▂▂▂▂▂▂▂▂▂▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>len</td><td>233</td></tr><tr><td>len_choose</td><td>2</td></tr><tr><td>max</td><td>0.00459</td></tr><tr><td>sum</td><td>0.06488</td></tr><tr><td>train_loss</td><td>1.88942</td></tr><tr><td>val_accuracy</td><td>0.36604</td></tr><tr><td>val_loss</td><td>23.85734</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">titanic-mul, num_epochs: 50, metric: AbsGradientEdgeMetric, aggregation_mode: mean, choose_threshold: 0.5, window_size: 3, threshold: 0.05, lr: 0.0005</strong> at: <a href='https://wandb.ai/fedornigretuk/self-expanding-nets/runs/me4h3nmp' target=\"_blank\">https://wandb.ai/fedornigretuk/self-expanding-nets/runs/me4h3nmp</a><br/> View project at: <a href='https://wandb.ai/fedornigretuk/self-expanding-nets' target=\"_blank\">https://wandb.ai/fedornigretuk/self-expanding-nets</a><br/>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250212_191502-me4h3nmp\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dense_model = MulticlassFCN(input_size=X.shape[1])\n",
    "sparse_model = convert_dense_to_sparse_network(dense_model)\n",
    "wandb.finish()\n",
    "wandb.init(\n",
    "    project=\"self-expanding-nets\",\n",
    "    name=f\"titanic-mul, {name}\",\n",
    "    tags=[\"complex model\", \"titanic\", \"multiclass\", hyperparams[\"metric\"].__class__.__name__],\n",
    "    group=\"new freeze 2\"\n",
    ")\n",
    "\n",
    "train_sparse_recursive(sparse_model, train_loader, val_loader,\n",
    "                       edge_replacement_func=edge_replacement_func_new_layer, **hyperparams)\n",
    "wandb.finish()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533bf1b57447aa62",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-02-11T21:06:17.697345400Z",
     "start_time": "2025-02-11T11:19:18.201889Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
