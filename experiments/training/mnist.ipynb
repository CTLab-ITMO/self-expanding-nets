{
 "cells": [
  {
   "cell_type": "code",
   "id": "932f4bdded4b6539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:54.105874Z",
     "start_time": "2024-12-09T19:48:54.097352Z"
    }
   },
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm"
   ],
   "outputs": [],
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "id": "a089a23845b1066b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:54.117412Z",
     "start_time": "2024-12-09T19:48:54.112846Z"
    }
   },
   "source": [
    "from senmodel.model.utils import *\n",
    "from senmodel.metrics.nonlinearity_metrics import *\n",
    "from senmodel.metrics.edge_finder import *"
   ],
   "outputs": [],
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "id": "888ee10c0aa4d1f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:54.130357Z",
     "start_time": "2024-12-09T19:48:54.119817Z"
    }
   },
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ],
   "outputs": [],
   "execution_count": 27
  },
  {
   "cell_type": "code",
   "id": "7ab06250d4252047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:54.144478Z",
     "start_time": "2024-12-09T19:48:54.135444Z"
    }
   },
   "source": [
    "def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func=None):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_targets = []\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_targets, all_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        if edge_replacement_func and epoch % 2 == 0 and epoch != 0:\n",
    "            edge_replacement_func(model, optimizer, val_loader, metric)\n",
    "        wandb.log({'val loss': val_loss, 'val accuracy': val_accuracy, 'train loss': train_loss})\n",
    "\n",
    "\n",
    "def edge_replacement_func_new_layer(model, optim, val_loader, metric):\n",
    "    layer = model.fc1\n",
    "    ef = EdgeFinder(metric, val_loader, device)\n",
    "    print(\"values:\", ef.calculate_edge_metric_for_dataloader(model))\n",
    "    chosen_edges = ef.choose_edges_top_k(model, 256)\n",
    "    print(\"choose:\", chosen_edges)\n",
    "    layer.replace_many(*chosen_edges)\n",
    "    optim.add_param_group({'params': layer.embed_linears[-1].weight_values})\n"
   ],
   "outputs": [],
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "id": "1aff98b408abbf8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:54.155541Z",
     "start_time": "2024-12-09T19:48:54.150507Z"
    }
   },
   "source": [
    "# Define the model\n",
    "class SimpleFCN(nn.Module):\n",
    "    def __init__(self, input_size=28 * 28):\n",
    "        super(SimpleFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "id": "90353a5a49cd1022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:54.204898Z",
     "start_time": "2024-12-09T19:48:54.160013Z"
    }
   },
   "source": [
    "# Dataset and Dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "# Load dataset and split into train/validation sets\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ],
   "outputs": [],
   "execution_count": 30
  },
  {
   "cell_type": "code",
   "id": "824f8403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:55.823342Z",
     "start_time": "2024-12-09T19:48:54.214073Z"
    }
   },
   "source": [
    "label_dict = {}\n",
    "for i in val_dataset:\n",
    "    if i[1] not in label_dict.keys():\n",
    "        label_dict[i[1]] = 0\n",
    "    else:\n",
    "        label_dict[i[1]] += 1\n",
    "label_dict"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 1179,\n",
       " 7: 1285,\n",
       " 9: 1139,\n",
       " 5: 1121,\n",
       " 3: 1193,\n",
       " 6: 1191,\n",
       " 8: 1150,\n",
       " 0: 1225,\n",
       " 1: 1353,\n",
       " 2: 1154}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 31
  },
  {
   "cell_type": "code",
   "id": "dcb8129e6befdf70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:55.846980Z",
     "start_time": "2024-12-09T19:48:55.826416Z"
    }
   },
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "metrics = [\n",
    "    GradientMeanEdgeMetric(criterion),\n",
    "    PerturbationSensitivityEdgeMetric(criterion),\n",
    "]\n",
    "model = SimpleFCN()\n",
    "sparse_model = convert_dense_to_sparse_network(model)\n",
    "sparse_linear = deepcopy(sparse_model.fc1)\n",
    "sparse_model.fc1.weight_indices"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ...,   9,   9,   9],\n",
       "        [  0,   1,   2,  ..., 781, 782, 783]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 32
  },
  {
   "cell_type": "code",
   "id": "589d62a1",
   "metadata": {},
   "source": [
    "sparse_model.fc1.weight_indices[:, :50]"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "id": "77e8399a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:56.139511Z",
     "start_time": "2024-12-09T19:48:56.134633Z"
    }
   },
   "source": [
    "import wandb\n",
    "wandb.login()"
   ],
   "outputs": [],
   "execution_count": 34
  },
  {
   "cell_type": "code",
   "id": "aeb264fa",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:48:56.207062Z",
     "start_time": "2024-12-09T19:48:56.202790Z"
    }
   },
   "source": [
    "run = wandb.init(\n",
    "    project=\"self-expanding-nets\",\n",
    "    name=f\"replace=(8epoch, 256edge), lr=5e-5, 1 metric\",\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 35
  },
  {
   "cell_type": "code",
   "id": "fb8258dcf13e03d1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:51:50.190377Z",
     "start_time": "2024-12-09T19:48:56.303936Z"
    }
   },
   "source": [
    "train_sparse_recursive(sparse_model, train_loader, val_loader, 64, metrics[0],\n",
    "                       edge_replacement_func=edge_replacement_func_new_layer)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:12<00:00, 61.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64, Train Loss: 1.7941, Val Loss: 1.3948, Val Accuracy: 0.7672\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 62.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/64, Train Loss: 1.1640, Val Loss: 0.9907, Val Accuracy: 0.8234\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:12<00:00, 61.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/64, Train Loss: 0.8757, Val Loss: 0.7890, Val Accuracy: 0.8393\n",
      "values: tensor([0., 0., 0.,  ..., 0., 0., 0.])\n",
      "choose: tensor([[  1,   1,   1,   1,   5,   1,   1,   5,   1,   1,   5,   1,   5,   5,\n",
      "           5,   1,   5,   1,   9,   1,   9,   1,   5,   1,   1,   4,   5,   4,\n",
      "           1,   9,   8,   9,   7,   9,   4,   4,   8,   7,   4,   8,   8,   4,\n",
      "           5,   5,   5,   8,   4,   5,   4,   1,   4,   9,   9,   7,   4,   5,\n",
      "           4,   1,   9,   8,   5,   5,   5,   0,   4,   4,   8,   9,   8,   9,\n",
      "           9,   8,   5,   4,   4,   7,   8,   9,   5,   9,   4,   5,   8,   5,\n",
      "           4,   7,   4,   9,   9,   9,   5,   8,   3,   0,   5,   9,   8,   5,\n",
      "           7,   4,   0,   8,   4,   8,   9,   8,   0,   5,   8,   7,   8,   8,\n",
      "           4,   5,   3,   9,   5,   8,   8,   5,   5,   9,   7,   5,   8,   8,\n",
      "           8,   1,   7,   9,   0,   8,   9,   8,   8,   8,   9,   5,   1,   8,\n",
      "           8,   9,   5,   4,   8,   8,   8,   5,   7,   0,   8,   4,   0,   5,\n",
      "           8,   3,   7,   4,   7,   8,   3,   8,   9,   5,   5,   9,   4,   8,\n",
      "           4,   5,   8,   4,   3,   5,   5,   5,   5,   9,   3,   7,   7,   4,\n",
      "           5,   1,   7,   9,   5,   9,   9,   9,   8,   7,   5,   8,   5,   9,\n",
      "           4,   5,   4,   9,   5,   3,   8,   7,   5,   5,   5,   8,   5,   3,\n",
      "           4,   7,   8,   9,   8,   9,   9,   9,   3,   8,   5,   8,   5,   5,\n",
      "           4,   7,   5,   5,   5,   9,   4,   7,   4,   3,   0,   5,   6,   8,\n",
      "           7,   7,   8,   8,   8,   8,   8,   8,   8,   7,   3,   5,   4,   1,\n",
      "           8,   8,   5,   4],\n",
      "        [378, 406, 350, 434, 347, 323, 351, 375, 462, 322, 374, 379, 348, 376,\n",
      "         346, 461, 319, 433, 211, 295, 212, 489, 320, 490, 407, 401, 403, 436,\n",
      "         405, 210, 406, 408, 269, 436, 463, 464, 433, 268, 408, 434, 405, 409,\n",
      "         404, 318, 402, 407, 402, 349, 437, 294, 374, 409, 237, 297, 430, 292,\n",
      "         429, 517, 380, 435, 291, 631, 377, 407, 435, 211, 657, 437, 460, 381,\n",
      "         213, 656, 321, 373, 381, 240, 461, 239, 632, 238, 428, 628, 432, 627,\n",
      "         400, 241, 431, 353, 464, 240, 630, 210, 378, 435, 629, 463, 183, 373,\n",
      "         325, 462, 408, 379, 380, 209, 435, 353, 434, 656, 211, 270, 380, 488,\n",
      "         491, 293, 379, 354, 657, 408, 182, 345, 655, 241, 267, 658, 436, 352,\n",
      "         630, 518, 235, 382, 380, 404, 236, 181, 212, 213, 264, 626, 377, 658,\n",
      "         629, 326, 208, 346, 184, 325, 628, 182, 236, 406, 487, 210, 379, 184,\n",
      "         462, 350, 296, 353, 239, 573, 351, 298, 209, 604, 605, 291, 212, 378,\n",
      "         492, 207, 377, 239, 377, 405, 290, 266, 378, 318, 380, 405, 298, 465,\n",
      "         183, 267, 436, 325, 212, 290, 491, 269, 185, 238, 625, 240, 209, 352,\n",
      "         432, 317, 238, 263, 659, 352, 515, 234, 181, 235, 603, 463, 600, 406,\n",
      "         434, 463, 437, 465, 241, 346, 407, 492, 208, 237, 211, 326, 265, 213,\n",
      "         433, 491, 263, 654, 186, 410, 461, 237, 403, 407, 462, 185, 572, 239,\n",
      "         353, 326, 572, 351, 235, 242, 376, 659, 214, 464, 290, 350, 325, 435,\n",
      "         208, 514, 597, 407]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:14<00:00, 53.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/64, Train Loss: 2.2841, Val Loss: 2.0928, Val Accuracy: 0.4285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:14<00:00, 50.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/64, Train Loss: 1.9736, Val Loss: 1.8260, Val Accuracy: 0.4697\n",
      "values: tensor([0.0000, 0.0000, 0.0000,  ..., 0.3778, 0.5325, 0.2357])\n",
      "choose: tensor([[   8,    8,    8,    8,    8,    8,    8,    8,    8,    5,    8,    5,\n",
      "            8,    5,    8,    8,    8,    8,    8,    8,    5,    8,    5,    8,\n",
      "            8,    8,    8,    5,    8,    5,    8,    5,    8,    8,    5,    5,\n",
      "            5,    8,    8,    5,    8,    8,    8,    5,    5,    8,    8,    8,\n",
      "            5,    8,    8,    5,    8,    8,    8,    5,    8,    5,    8,    8,\n",
      "            8,    8,    5,    5,    8,    8,    8,    5,    8,    8,    5,    8,\n",
      "            8,    5,    5,    5,    8,    8,    8,    5,    8,    5,    5,    5,\n",
      "            5,    5,    8,    8,    5,    8,    5,    8,    8,    8,    8,    5,\n",
      "            5,    8,    8,    5,    5,    8,    5,    5,    8,    8,    8,    5,\n",
      "            8,    8,    5,    8,    5,    5,    8,    8,    5,    0,    8,    5,\n",
      "            8,    0,    5,    5,    8,    8,    5,    5,    0,    8,    0,    5,\n",
      "            5,    5,    8,    6,    0,    0,    8,    0,    5,    3,    0,    8,\n",
      "            6,    8,    0,    3,    6,    0,    6,    8,    5,    5,    0,    8,\n",
      "            3,    3,    8,    5,    5,    0,    3,    8,    0,    6,    5,    5,\n",
      "            5,    8,    5,    3,    8,    5,    3,    6,    5,    5,    3,    6,\n",
      "            5,    5,    5,    5,    5,    5,    3,    8,    5,    5,    8,    8,\n",
      "            0,    8,    3,    5,    6,    6,    0,    0,    5,    6,    5,    8,\n",
      "            5,    5,    5,    8,    8,    8,    8,    0,    3,    0,    3,    8,\n",
      "            0,    0,    3,    8,    0,    3,    3,    5,    5,    0,    5,    5,\n",
      "            0,    6,    0,    5,    8,    0,    6,    0,    3,    0,    6,    6,\n",
      "            5,    8,    5,    5,    5,    0,    5,    6,    0,    0,    0,    5,\n",
      "            5,    0,    8,    3],\n",
      "        [ 600,  601,  599,  909,  574,  571,  602,  270,  297,  577,  324,  602,\n",
      "          269,  210,  381,  598,  545, 1030,  575,  544,  576,  546,  550,  570,\n",
      "          951,  543,  627,  598,  489,  601,  409,  867,  186,  490,  578,  599,\n",
      "         1019,  901,  517,  523,  547,  603,  902,  156,  155,  576,  626,  243,\n",
      "          549,  516,  518,  495,  542,  548,  464,  522,  155,  238,  597,  180,\n",
      "          296,  215,  551,  214,  154,  350,  569,  239,  549,  271,  237,  156,\n",
      "          491,  467,  154,  575,  908,  519,  924,  468,  236,  966,  496,  157,\n",
      "          947,  931,  354,  323,  240,  207,  874,  268,  625,  521,  520, 1004,\n",
      "          596,  577,  459,  440, 1038,  465,  180,  439,  492,  153,  238,  401,\n",
      "          541,  604,  494,  843,  241,  236,  157,  299,  524,  627,  493,  568,\n",
      "          431,  628,  569,  990,  550,  522,  215,  264,  626,  382,  213,  606,\n",
      "          242,  153,  998,  573,  184,  629,  930,  185,  412,  182,  214,  486,\n",
      "          574,  596,  597,  183,  571,  212,  575,  403,  548,  579,  598,  410,\n",
      "          629,  630,  568,  907,  411,  211,  181,  494,  183,  543,  400,  243,\n",
      "          267,  179,  428,  628,  438,  624,  349,  542, 1012,  521,  376,  576,\n",
      "          294,  574,  429,  466,  456,  187,  184,  655,  570,  540,  187,  466,\n",
      "          210,  829,  631,  441,  514,  601,  599,  630,  633,  549,  926,  885,\n",
      "          469,  862,  158,  458,  624,  513,  654,  568,  324,  625,  180,  889,\n",
      "          186,  603,  323,  327,  602,  604,  627,  484,  179,  215,  322,  372,\n",
      "          596,  602,  243,  567,  578,  237,  544,  601,  656,  600,  600,  548,\n",
      "          512,  631,  413,  539,  794,  242,  552,  486,  483,  511,  373,  438,\n",
      "          384,  400,  152,  603]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:15<00:00, 48.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/64, Train Loss: 5.8257, Val Loss: 5.0973, Val Accuracy: 0.1629\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:16<00:00, 46.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/64, Train Loss: 4.6312, Val Loss: 4.0646, Val Accuracy: 0.2283\n",
      "values: tensor([0.0000, 0.0000, 0.0000,  ..., 0.1098, 0.0800, 0.0884])\n",
      "choose: tensor([[   8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    8,    1,    8,    8,    8,    8,    8,    8,\n",
      "            8,    8,    8,    8,    6,    8,    8,    8,    8,    8,    8,    6,\n",
      "            8,    1,    8,    8,    3,    8,    6,    8,    6,    6,    6,    6,\n",
      "            2,    7,    2,    2,    2,    6,    2,    6,    6,    2,    2,    8,\n",
      "            6,    6,    6,    2],\n",
      "        [1040, 1056, 1070, 1120,  264, 1195,  263, 1058, 1078,  265,  430, 1158,\n",
      "          402, 1094,  291,  267,  355,  266,  374,  262,  429,  383,  290,  401,\n",
      "          346,  292,  457,  375,  318,  234,  411,  373,  319, 1046,  295,  347,\n",
      "          345,  439, 1117,  485, 1137, 1259,  293,  467,  605, 1072,  317, 1057,\n",
      "         1096,  495, 1080, 1247,  294, 1203,  272,  523,  320,  289,  244, 1118,\n",
      "          349,  348,  322,  428,  206, 1043,  261,  300,  456,  400, 1003, 1160,\n",
      "         1089,  632,  321, 1191,  551, 1146,  372,  484,  328,  216, 1144, 1085,\n",
      "          540,  233, 1148,  512, 1230,  866,  158, 1249, 1169,  356, 1086,  344,\n",
      "         1116, 1050,  384, 1198, 1134, 1021, 1183,  918,  412,  316,  440,  860,\n",
      "         1209,  468, 1165, 1077,  934, 1272, 1133,  496,  606, 1065,  205, 1145,\n",
      "          288,  579,  127,  178, 1036, 1092, 1255,  653,  524,  128,  945,  567,\n",
      "          938, 1098, 1037, 1127, 1231, 1174,  260,  539,  126, 1178,  188,  455,\n",
      "          910,  633,  483,  427,  511,  850,  159,  245, 1138,  595,  852,  273,\n",
      "         1054,  151, 1042,  399,  919,  552,  232,  129,  684, 1045, 1059, 1073,\n",
      "          301,  683,  954, 1066,  217,  125,  371,  685,  660, 1112, 1164, 1061,\n",
      "          329,  469, 1029,  343, 1154,  441,  177,  943,  607,  623,  652,  497,\n",
      "          204, 1028,  413,  682,  357,  686,  538,  130, 1105,  895,  385,  580,\n",
      "          566,  315,  525,  160,  510,  801,  634,  287,  259,  124,  150,  189,\n",
      "          482, 1149, 1025,  594, 1175,  454, 1141, 1041, 1227,  231,  553, 1287,\n",
      "          661,  841, 1068,  875, 1197,  426,  515,  687,  522, 1236,  570,  550,\n",
      "          569,  859,  462,  490,  570,  577,  489,  485,  545,  461,  571, 1093,\n",
      "          547,  457,  458,  463]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:16<00:00, 46.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/64, Train Loss: 5.3209, Val Loss: 4.5455, Val Accuracy: 0.2259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:16<00:00, 45.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/64, Train Loss: 4.0046, Val Loss: 3.4429, Val Accuracy: 0.2991\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[36], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m \u001B[43mtrain_sparse_recursive\u001B[49m\u001B[43m(\u001B[49m\u001B[43msparse_model\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m64\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetrics\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m,\u001B[49m\n\u001B[0;32m      2\u001B[0m \u001B[43m                       \u001B[49m\u001B[43medge_replacement_func\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43medge_replacement_func_new_layer\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[28], line 40\u001B[0m, in \u001B[0;36mtrain_sparse_recursive\u001B[1;34m(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func)\u001B[0m\n\u001B[0;32m     36\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mEpoch \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mepoch\u001B[38;5;250m \u001B[39m\u001B[38;5;241m+\u001B[39m\u001B[38;5;250m \u001B[39m\u001B[38;5;241m1\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m/\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mnum_epochs\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Train Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mtrain_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[0;32m     37\u001B[0m       \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVal Loss: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_loss\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m, Val Accuracy: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mval_accuracy\u001B[38;5;132;01m:\u001B[39;00m\u001B[38;5;124m.4f\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     39\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m edge_replacement_func \u001B[38;5;129;01mand\u001B[39;00m epoch \u001B[38;5;241m%\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m \u001B[38;5;129;01mand\u001B[39;00m epoch \u001B[38;5;241m!=\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m---> 40\u001B[0m     \u001B[43medge_replacement_func\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43moptimizer\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[28], line 47\u001B[0m, in \u001B[0;36medge_replacement_func_new_layer\u001B[1;34m(model, optim, val_loader, metric)\u001B[0m\n\u001B[0;32m     45\u001B[0m layer \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mfc1\n\u001B[0;32m     46\u001B[0m ef \u001B[38;5;241m=\u001B[39m EdgeFinder(metric, val_loader, device)\n\u001B[1;32m---> 47\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mvalues:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43mef\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcalculate_edge_metric_for_dataloader\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m)\u001B[49m)\n\u001B[0;32m     48\u001B[0m chosen_edges \u001B[38;5;241m=\u001B[39m ef\u001B[38;5;241m.\u001B[39mchoose_edges_top_k(model, \u001B[38;5;241m256\u001B[39m)\n\u001B[0;32m     49\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mchoose:\u001B[39m\u001B[38;5;124m\"\u001B[39m, chosen_edges)\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\senmodel\\metrics\\edge_finder.py:15\u001B[0m, in \u001B[0;36mEdgeFinder.calculate_edge_metric_for_dataloader\u001B[1;34m(self, model)\u001B[0m\n\u001B[0;32m     13\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mcalculate_edge_metric_for_dataloader\u001B[39m(\u001B[38;5;28mself\u001B[39m, model):\n\u001B[0;32m     14\u001B[0m     accumulated_grads \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m \u001B[43m    \u001B[49m\u001B[38;5;28;43;01mfor\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;129;43;01min\u001B[39;49;00m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataloader\u001B[49m\u001B[43m:\u001B[49m\n\u001B[0;32m     16\u001B[0m \u001B[43m        \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdevice\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     18\u001B[0m \u001B[43m        \u001B[49m\u001B[43mmetric\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mmetric\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcalculate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtarget\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:701\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    698\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    699\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[0;32m    700\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[1;32m--> 701\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    702\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    703\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m (\n\u001B[0;32m    704\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable\n\u001B[0;32m    705\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    706\u001B[0m     \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called\n\u001B[0;32m    707\u001B[0m ):\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:757\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[1;34m(self)\u001B[0m\n\u001B[0;32m    755\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[0;32m    756\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m--> 757\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m    758\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[0;32m    759\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[1;34m(self, possibly_batched_index)\u001B[0m\n\u001B[0;32m     48\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[0;32m     49\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[1;32m---> 50\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     51\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m     52\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[1;34m(self, indices)\u001B[0m\n\u001B[0;32m    418\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[0;32m    419\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 420\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torchvision\\datasets\\mnist.py:146\u001B[0m, in \u001B[0;36mMNIST.__getitem__\u001B[1;34m(self, index)\u001B[0m\n\u001B[0;32m    143\u001B[0m img \u001B[38;5;241m=\u001B[39m Image\u001B[38;5;241m.\u001B[39mfromarray(img\u001B[38;5;241m.\u001B[39mnumpy(), mode\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mL\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m    145\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m--> 146\u001B[0m     img \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    148\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m    149\u001B[0m     target \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtarget_transform(target)\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:95\u001B[0m, in \u001B[0;36mCompose.__call__\u001B[1;34m(self, img)\u001B[0m\n\u001B[0;32m     93\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, img):\n\u001B[0;32m     94\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m t \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransforms:\n\u001B[1;32m---> 95\u001B[0m         img \u001B[38;5;241m=\u001B[39m \u001B[43mt\u001B[49m\u001B[43m(\u001B[49m\u001B[43mimg\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     96\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torchvision\\transforms\\transforms.py:137\u001B[0m, in \u001B[0;36mToTensor.__call__\u001B[1;34m(self, pic)\u001B[0m\n\u001B[0;32m    129\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m__call__\u001B[39m(\u001B[38;5;28mself\u001B[39m, pic):\n\u001B[0;32m    130\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[0;32m    131\u001B[0m \u001B[38;5;124;03m    Args:\u001B[39;00m\n\u001B[0;32m    132\u001B[0m \u001B[38;5;124;03m        pic (PIL Image or numpy.ndarray): Image to be converted to tensor.\u001B[39;00m\n\u001B[1;32m   (...)\u001B[0m\n\u001B[0;32m    135\u001B[0m \u001B[38;5;124;03m        Tensor: Converted image.\u001B[39;00m\n\u001B[0;32m    136\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[1;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mF\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto_tensor\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpic\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32mD:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torchvision\\transforms\\functional.py:176\u001B[0m, in \u001B[0;36mto_tensor\u001B[1;34m(pic)\u001B[0m\n\u001B[0;32m    174\u001B[0m img \u001B[38;5;241m=\u001B[39m img\u001B[38;5;241m.\u001B[39mpermute((\u001B[38;5;241m2\u001B[39m, \u001B[38;5;241m0\u001B[39m, \u001B[38;5;241m1\u001B[39m))\u001B[38;5;241m.\u001B[39mcontiguous()\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(img, torch\u001B[38;5;241m.\u001B[39mByteTensor):\n\u001B[1;32m--> 176\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mimg\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mto\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_float_dtype\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241m.\u001B[39mdiv(\u001B[38;5;241m255\u001B[39m)\n\u001B[0;32m    177\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    178\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m img\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 36
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f89610af467b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-09T19:51:50.214874400Z",
     "start_time": "2024-12-03T16:22:21.589616Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-expanding-nets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
