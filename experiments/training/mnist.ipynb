{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932f4bdded4b6539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.334745Z",
     "start_time": "2025-01-21T14:31:20.096324Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a089a23845b1066b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.350457Z",
     "start_time": "2025-01-21T14:31:25.338930Z"
    }
   },
   "outputs": [],
   "source": [
    "from senmodel.model.utils import *\n",
    "from senmodel.metrics.nonlinearity_metrics import *\n",
    "from senmodel.metrics.edge_finder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888ee10c0aa4d1f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.520919Z",
     "start_time": "2025-01-21T14:31:25.513942Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a936039c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_params_amount(model):\n",
    "    amount = 0\n",
    "    for linear in model.embed_linears:\n",
    "        amount += linear.weight_size[0] * linear.weight_size[0]\n",
    "    amount += model.weight_size[0] * model.weight_size[1]\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "28b44164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_zero_params_amount(model, eps=1e-8):\n",
    "    amount = 0\n",
    "    for linear in model.embed_linears:\n",
    "        amount += linear.weight_values[linear.weight_values < eps].shape[0]\n",
    "    amount += model.weight_values[model.weight_values < eps].shape[0]\n",
    "    return amount"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7ab06250d4252047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.536476Z",
     "start_time": "2025-01-21T14:31:25.528255Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func=None, window_size=5, threshold=0.02):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    replace_epoch = [0]\n",
    "    val_losses = []\n",
    "    len_choose = get_model_last_layer(model).count_replaces\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        t0 = time.time()\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for i, (inputs, targets) in enumerate(tqdm(train_loader)):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "\n",
    "            # if len(len_choose) > 3 and i > window_size:\n",
    "            #     freeze_all_but_last(model)\n",
    "\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "        \n",
    "        if len(replace_epoch) > 1:\n",
    "            for g in optimizer.param_groups:\n",
    "                g['lr'] *= 0.9\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_time = time.time() - t0\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_targets = []\n",
    "        all_preds = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "\n",
    "        val_loss /= len(val_loader)\n",
    "        val_accuracy = accuracy_score(all_targets, all_preds)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        new_l = dict()\n",
    "        # if edge_replacement_func and epoch % 8 == 0 and epoch != 0:\n",
    "        #     new_l = edge_replacement_func(model, optimizer, val_loader, metric)\n",
    "        val_losses.append(val_loss)\n",
    "        if len(val_losses) > window_size and epoch - replace_epoch[-1] > 8:\n",
    "            recent_changes = [abs(val_losses[i] - val_losses[i - 1]) for i in range(-window_size, 0)]\n",
    "            avg_change = sum(recent_changes) / window_size\n",
    "            if avg_change < threshold:\n",
    "                len_ch = len_choose[-1]\n",
    "                new_l = edge_replacement_func(model, optimizer, val_loader, metric, 0.3, 'mean', len_ch)\n",
    "                len_choose = get_model_last_layer(model).count_replaces\n",
    "                replace_epoch += [epoch]\n",
    "                if len(replace_epoch) == 2:\n",
    "                    for g in optimizer.param_groups:\n",
    "                        g['lr'] *= 200\n",
    "            print(torch.unique(get_model_last_layer(model).weight_indices[0]))\n",
    "\n",
    "        print(new_l)\n",
    "        params_amount = get_params_amount(model.fc1)\n",
    "        zero_params_amount = get_zero_params_amount(model.fc1)\n",
    "        wandb.log({'val loss': val_loss, 'val accuracy': val_accuracy,\n",
    "                    'train loss': train_loss, 'params amount': params_amount,\n",
    "                      'zero params amount': zero_params_amount, 'train time': train_time,\n",
    "                        'params ratio': (params_amount - zero_params_amount) / params_amount,\n",
    "                          'lr': optimizer.param_groups[0]['lr']} | new_l)\n",
    "\n",
    "\n",
    "def edge_replacement_func_new_layer(model, optim, val_loader, metric, choose_threshold, aggregation_mode='mean', len_choose=None):\n",
    "    layer = get_model_last_layer(model)\n",
    "    ef = EdgeFinder(metric, val_loader, device, aggregation_mode)\n",
    "    vals = ef.calculate_edge_metric_for_dataloader(model, len_choose, False)\n",
    "    print(\"Edge metrics:\", vals, max(vals, default=0), sum(vals))\n",
    "    chosen_edges = ef.choose_edges_threshold(model, choose_threshold, len_choose)\n",
    "    print(\"Chosen edges:\", chosen_edges, len(chosen_edges[0]))\n",
    "    layer.replace_many(*chosen_edges)\n",
    "\n",
    "    if len(chosen_edges[0]) > 0:\n",
    "        optim.add_param_group({'params': layer.embed_linears[-1].weight_values})\n",
    "        # optim.add_param_group({'params': layer.weight_values})\n",
    "    else:\n",
    "        print(\"Empty metric\")\n",
    "\n",
    "    return {'max': max(vals, default=0), 'sum': sum(vals), 'len': len(vals), 'len_choose': layer.count_replaces[-1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aff98b408abbf8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.547124Z",
     "start_time": "2025-01-21T14:31:25.543666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class SimpleFCN(nn.Module):\n",
    "    def __init__(self, input_size=28 * 28):\n",
    "        super(SimpleFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "90353a5a49cd1022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.590348Z",
     "start_time": "2025-01-21T14:31:25.554956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset and Dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "# Load dataset and split into train/validation sets\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dcb8129e6befdf70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:26.821483Z",
     "start_time": "2025-01-21T14:31:26.807650Z"
    }
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "metrics = [\n",
    "    MagnitudeL2Metric(criterion),\n",
    "    SNIPMetric(criterion),\n",
    "    # GradientMeanEdgeMetric(criterion),\n",
    "    PerturbationSensitivityEdgeMetric(criterion),\n",
    "]\n",
    "model = SimpleFCN()\n",
    "sparse_model = convert_dense_to_sparse_network(model)\n",
    "sparse_linear = deepcopy(sparse_model.fc1)\n",
    "# sparse_model.fc1.weight_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "77e8399a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:30.645772Z",
     "start_time": "2025-01-21T14:31:27.560914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mvanyamironov\u001b[0m to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a4cee60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/Users/ivanmironov/Projects/self-expanding-nets/experiments/training/wandb/run-20250305_123807-ibeh8p0t</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/vanyamironov/self-expanding-nets/runs/ibeh8p0t' target=\"_blank\">replace=(auto epoch, threshold 0.15), lr=5e-5, magnetic l2 metric</a></strong> to <a href='https://wandb.ai/vanyamironov/self-expanding-nets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/vanyamironov/self-expanding-nets' target=\"_blank\">https://wandb.ai/vanyamironov/self-expanding-nets</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/vanyamironov/self-expanding-nets/runs/ibeh8p0t' target=\"_blank\">https://wandb.ai/vanyamironov/self-expanding-nets/runs/ibeh8p0t</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "run = wandb.init(\n",
    "    project=\"self-expanding-nets\",\n",
    "    name=f\"replace=(auto epoch, threshold 0.15), lr=5e-5, magnetic l2 metric\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3b3534e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 341.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/64, Train Loss: 1.4805, Val Loss: 0.9977, Val Accuracy: 0.8192\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 352.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/64, Train Loss: 0.8088, Val Loss: 0.6845, Val Accuracy: 0.8537\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 325.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/64, Train Loss: 0.6078, Val Loss: 0.5553, Val Accuracy: 0.8697\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 343.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/64, Train Loss: 0.5127, Val Loss: 0.4850, Val Accuracy: 0.8792\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 357.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/64, Train Loss: 0.4573, Val Loss: 0.4409, Val Accuracy: 0.8873\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 360.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/64, Train Loss: 0.4211, Val Loss: 0.4107, Val Accuracy: 0.8931\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 366.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/64, Train Loss: 0.3956, Val Loss: 0.3892, Val Accuracy: 0.8962\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 300.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/64, Train Loss: 0.3769, Val Loss: 0.3726, Val Accuracy: 0.9004\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 354.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/64, Train Loss: 0.3626, Val Loss: 0.3603, Val Accuracy: 0.9035\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:02<00:00, 365.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/64, Train Loss: 0.3513, Val Loss: 0.3504, Val Accuracy: 0.9048\n",
      "Edge metrics: tensor([4.5293e-04, 8.9955e-04, 1.1603e-03,  ..., 4.7842e-04, 9.6693e-05,\n",
      "        8.1587e-04], grad_fn=<DivBackward0>) tensor(0.1472, grad_fn=<UnbindBackward0>) tensor(83.5764, grad_fn=<AddBackward0>)\n",
      "Chosen edges: tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,\n",
      "           1,   1,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   2,\n",
      "           2,   2,   2,   2,   2,   2,   2,   2,   2,   2,   3,   3,   3,   3,\n",
      "           3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,   3,\n",
      "           3,   3,   3,   3,   3,   3,   3,   3,   3,   4,   4,   4,   4,   4,\n",
      "           4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
      "           4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
      "           4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   4,\n",
      "           4,   4,   4,   4,   4,   4,   4,   4,   4,   4,   5,   5,   5,   5,\n",
      "           5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,\n",
      "           5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   5,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,   6,\n",
      "           6,   6,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "           7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "           7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,   7,\n",
      "           7,   7,   7,   7,   7,   7,   7,   7,   8,   8,   8,   8,   8,   8,\n",
      "           8,   8,   8,   8,   8,   8,   8,   8,   8,   9,   9,   9,   9,   9,\n",
      "           9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
      "           9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
      "           9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,   9,\n",
      "           9,   9,   9,   9,   9,   9,   9,   9,   9,   9],\n",
      "        [ 71, 193, 221, 249, 277, 323, 324, 350, 351, 352, 353, 377, 378, 379,\n",
      "         380, 381, 405, 406, 407, 408, 432, 433, 434, 435, 436, 460, 461, 462,\n",
      "         463, 464, 488, 489, 490, 491, 518, 707, 708, 710, 711, 713, 714, 715,\n",
      "         716, 743, 102, 221, 233, 248, 249, 274, 275, 276, 277, 294, 295, 302,\n",
      "         303, 304, 319, 322, 323, 347, 350, 351, 374, 375, 376, 378, 379, 402,\n",
      "         403, 405, 406, 431, 434, 437, 440, 461, 462, 465, 466, 467, 482, 489,\n",
      "         493, 494, 509, 510, 511, 517, 537, 683, 708, 709, 710, 711, 712, 714,\n",
      "         715, 716, 191, 192, 220, 248, 249, 276, 277, 315, 316, 317, 318, 319,\n",
      "         320, 321, 322, 342, 343, 344, 345, 346, 347, 348, 349, 350, 369, 370,\n",
      "         371, 372, 375, 397, 501, 707, 708, 709, 710, 711, 164, 220, 221, 248,\n",
      "         249, 276, 277, 289, 290, 291, 292, 304, 317, 318, 332, 343, 360, 456,\n",
      "         485, 486, 487, 488, 513, 514, 515, 516, 517,  66,  67,  68,  72,  95,\n",
      "          96,  97,  98,  99, 100, 182, 209, 210, 211, 212, 238, 239, 266, 267,\n",
      "         294, 322, 346, 374, 375, 436, 437, 464, 540, 541, 542, 555, 565, 566,\n",
      "         567, 568, 569, 570, 571, 594, 595, 596, 597, 621, 712, 713, 717, 737,\n",
      "         738, 739, 740, 741, 742, 743, 744, 745, 746, 748,  70, 192, 220, 221,\n",
      "         228, 247, 248, 249, 275, 276, 277, 304, 305, 326, 327, 328, 329, 330,\n",
      "         356, 357, 358, 359, 386, 387, 388, 485, 486, 487, 488, 103, 104, 132,\n",
      "         241, 242, 243, 244, 248, 249, 268, 269, 270, 271, 276, 277, 296, 297,\n",
      "         298, 323, 480, 508, 592, 621, 622, 651, 652, 653, 656, 679, 680, 681,\n",
      "         682, 683, 684, 685, 686, 687, 688, 691, 692, 709, 713, 714, 715, 716,\n",
      "         717, 718, 120, 121, 122, 127, 128, 130, 131, 154, 157, 159, 160, 162,\n",
      "         163, 164, 192, 221, 248, 249, 276, 277, 296, 349, 350, 374, 375, 376,\n",
      "         377, 378, 402, 403, 404, 405, 406, 429, 430, 431, 432, 433, 458, 538,\n",
      "         539, 580, 581, 582, 583, 608, 610, 611,  68,  69,  70,  71,  72,  98,\n",
      "         101, 103, 501, 529, 563, 708, 743, 744, 747,  70,  71,  73,  95,  96,\n",
      "          97,  98,  99, 100, 101, 103, 104, 127, 128, 129, 130, 131, 133, 134,\n",
      "         146, 156, 157, 158, 159, 160, 161, 162, 163, 164, 173, 190, 191, 192,\n",
      "         200, 201, 203, 210, 211, 212, 218, 219, 220, 221, 247, 248, 249, 276,\n",
      "         277, 416, 443, 444, 471, 499, 500, 528, 568, 569]]) 416\n",
      "amount of added edges: torch.Size([416]) torch.Size([110240, 2])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "{'max': tensor(0.1472, grad_fn=<UnbindBackward0>), 'sum': tensor(83.5764, grad_fn=<AddBackward0>), 'len': 7840, 'len_choose': 416}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:10<00:00, 70.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/64, Train Loss: 0.2765, Val Loss: 0.1969, Val Accuracy: 0.9426\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 68.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/64, Train Loss: 0.1643, Val Loss: 0.1546, Val Accuracy: 0.9547\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:10<00:00, 69.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/64, Train Loss: 0.1295, Val Loss: 0.1417, Val Accuracy: 0.9573\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:10<00:00, 69.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/64, Train Loss: 0.1061, Val Loss: 0.1322, Val Accuracy: 0.9613\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 67.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/64, Train Loss: 0.0871, Val Loss: 0.1221, Val Accuracy: 0.9629\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 65.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/64, Train Loss: 0.0736, Val Loss: 0.1183, Val Accuracy: 0.9643\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 63.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/64, Train Loss: 0.0612, Val Loss: 0.1145, Val Accuracy: 0.9650\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 64.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/64, Train Loss: 0.0512, Val Loss: 0.1115, Val Accuracy: 0.9678\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 64.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/64, Train Loss: 0.0449, Val Loss: 0.1126, Val Accuracy: 0.9669\n",
      "Edge metrics: tensor([4.9067e-18, 3.9460e-17, 4.9268e-17, 8.6395e-18, 6.9496e-17, 6.4943e-02,\n",
      "        5.3338e-18, 6.4009e-17, 5.3540e-17, 8.8893e-17, 9.5128e-17, 3.5819e-17,\n",
      "        7.5560e-17, 9.7663e-17, 1.3535e-17, 5.7168e-02, 1.4683e-17, 2.3340e-17,\n",
      "        8.6799e-17, 5.2629e-17, 2.5155e-19, 5.5021e-17, 4.0780e-17, 3.7745e-17,\n",
      "        1.8361e-18, 6.4806e-02, 4.4219e-18, 6.9759e-17, 8.8687e-17, 9.7160e-17,\n",
      "        1.1903e-17, 1.2384e-17, 7.8895e-17, 1.2594e-17, 9.9333e-17, 4.7687e-02,\n",
      "        6.7982e-18, 1.8496e-17, 6.7472e-17, 1.9362e-17, 9.9655e-17, 3.0080e-17,\n",
      "        4.7290e-17, 6.0632e-17, 5.1488e-18, 5.8120e-02, 4.6361e-17, 2.3668e-17,\n",
      "        8.9767e-17, 5.4241e-17, 9.9747e-18, 5.8591e-17, 1.3272e-17, 7.3562e-17,\n",
      "        6.0292e-17, 7.3258e-02, 3.5941e-18, 1.2298e-17, 9.2160e-17, 3.9396e-17,\n",
      "        8.5536e-17, 1.7264e-17, 3.2688e-18, 4.3070e-17, 5.2301e-17, 7.7616e-02,\n",
      "        1.6602e-17, 2.5994e-17, 9.6174e-17, 7.8308e-18, 2.2348e-17, 2.7091e-17,\n",
      "        1.2812e-17, 5.2643e-17, 1.8833e-17, 5.2775e-02, 2.7550e-17, 3.2752e-17,\n",
      "        7.4044e-17, 2.8472e-19, 2.7973e-18, 7.7092e-17, 9.9472e-17, 7.7808e-17,\n",
      "        1.2149e-17, 4.6837e-02, 5.5017e-19, 3.5190e-17, 6.8832e-18, 2.8984e-17,\n",
      "        7.7953e-17, 7.0443e-17, 7.2808e-17, 4.5296e-17, 2.1401e-17, 5.7298e-02,\n",
      "        2.8134e-17, 9.0691e-17, 8.0593e-17, 4.1513e-17, 5.1570e-18, 6.6194e-17,\n",
      "        7.4844e-17, 6.8534e-20, 6.4982e-17, 9.3731e-02, 1.1980e-17, 1.9808e-18,\n",
      "        2.7785e-17, 1.2767e-17, 5.0245e-18, 9.5115e-17, 4.7206e-19, 2.0071e-17,\n",
      "        2.7229e-17, 1.0992e-01, 3.6715e-17, 4.4062e-18, 7.8029e-17, 4.1969e-17,\n",
      "        1.0532e-17, 4.7934e-17, 1.6291e-17, 5.9225e-19, 9.1880e-17, 1.1245e-01,\n",
      "        3.4954e-17, 8.9586e-17, 3.4667e-18, 9.3500e-18, 7.9819e-18, 6.2185e-17,\n",
      "        5.5450e-18, 1.6342e-17, 7.1594e-17, 6.1104e-02, 7.3349e-20, 8.6298e-17,\n",
      "        5.9106e-17, 4.9218e-17, 4.4013e-17, 9.5569e-19, 4.3835e-18, 3.1726e-18,\n",
      "        2.3803e-17, 6.7257e-02, 5.7102e-17, 2.4623e-17, 5.6521e-17, 3.2860e-18,\n",
      "        7.0656e-17, 3.1717e-17, 2.2273e-18, 3.9628e-17, 4.2777e-17, 8.0990e-02,\n",
      "        5.2242e-17, 7.1374e-18, 4.9374e-18, 4.0752e-17, 4.7563e-17, 2.2448e-21,\n",
      "        2.2611e-17, 8.7649e-17, 8.8426e-20, 8.0873e-02, 2.2155e-17, 1.3027e-17,\n",
      "        1.0232e-18, 2.2133e-17, 2.4939e-18, 7.1428e-18, 7.4251e-17, 3.7459e-17,\n",
      "        1.1567e-18, 6.1533e-02, 2.2753e-17, 4.9696e-17, 4.1957e-17, 7.2944e-17,\n",
      "        1.1208e-18, 1.1269e-18, 5.6282e-19, 6.3383e-17, 8.6654e-18, 5.1566e-02,\n",
      "        2.6142e-17, 5.7700e-17, 1.4788e-17, 5.2564e-17, 1.0349e-17, 3.8015e-17,\n",
      "        3.2715e-17, 4.3101e-17, 2.7524e-19, 6.5780e-02, 2.6597e-17, 9.7168e-18,\n",
      "        1.1568e-17, 1.7966e-17, 8.8554e-17, 7.1386e-17, 7.6852e-18, 6.9988e-17,\n",
      "        4.0545e-17, 4.5590e-02, 5.4341e-17, 2.5577e-19, 4.5675e-18, 5.1463e-17,\n",
      "        5.6449e-18, 1.1140e-17, 5.5135e-19, 7.2089e-17, 4.6401e-17, 6.8167e-02,\n",
      "        3.5751e-18, 9.9010e-19, 9.5780e-17, 8.9062e-17, 3.0218e-17, 4.5676e-18,\n",
      "        7.7461e-17, 9.0057e-17, 7.9416e-17, 5.2737e-02, 2.9241e-17, 8.3503e-17,\n",
      "        1.4792e-19, 6.2993e-18, 3.2373e-18, 1.4188e-20, 9.3307e-17, 4.4650e-20,\n",
      "        3.0216e-17, 4.6936e-02, 5.7811e-17, 9.7944e-17, 5.5248e-18, 1.9343e-17,\n",
      "        2.6080e-17, 3.9318e-17, 2.6451e-17, 2.4434e-17, 3.6929e-18, 4.7556e-02,\n",
      "        3.7756e-17, 8.4815e-19, 6.4408e-18, 2.0220e-19, 3.0583e-17, 4.5764e-18,\n",
      "        8.1877e-18, 1.9638e-17, 1.0037e-17, 8.0744e-02, 1.8051e-17, 4.1841e-17,\n",
      "        4.0556e-17, 3.9062e-17, 1.3485e-18, 5.2770e-17, 2.2836e-17, 2.9692e-17,\n",
      "        7.5072e-18, 7.5577e-02, 8.3872e-17, 3.6169e-17, 8.1116e-17, 5.9804e-17,\n",
      "        6.0797e-17, 3.9796e-17, 3.4348e-17, 5.0352e-19, 1.9231e-18, 7.0255e-02,\n",
      "        8.4873e-20, 1.6784e-17, 2.5402e-17, 1.0721e-17, 8.0462e-17, 3.4268e-18,\n",
      "        7.7683e-17, 4.1154e-17, 7.0166e-17, 5.2674e-02, 8.2289e-18, 2.4379e-17,\n",
      "        3.7024e-18, 1.9335e-17, 6.9295e-19, 1.0798e-19, 3.7719e-18, 7.2060e-17,\n",
      "        3.0020e-17, 5.5641e-02, 9.6944e-17, 5.2830e-18, 2.4040e-17, 6.2738e-17,\n",
      "        1.4158e-17, 6.6779e-17, 9.1836e-17, 1.9234e-17, 6.2026e-17, 5.2397e-02,\n",
      "        9.2913e-17, 9.2686e-17, 3.4113e-17, 3.6758e-17, 4.5739e-19, 2.4183e-18,\n",
      "        6.1133e-17, 1.7821e-17, 8.3855e-17, 5.5269e-02, 3.0120e-18, 6.1620e-17,\n",
      "        4.3144e-17, 6.5248e-17, 7.3608e-17, 3.4007e-17, 3.9710e-17, 5.6799e-17,\n",
      "        4.8501e-17, 6.0679e-02, 6.1299e-18, 4.6431e-17, 2.8645e-17, 7.2145e-17,\n",
      "        3.5174e-18, 1.2369e-18, 6.0211e-17, 6.8711e-17, 2.2220e-17, 6.0546e-02,\n",
      "        8.6688e-19, 9.1052e-19, 2.3214e-18, 5.4289e-18, 5.2801e-20, 3.2615e-17,\n",
      "        4.8779e-17, 6.6774e-17, 7.8335e-18, 4.9623e-02, 2.1437e-17, 1.0840e-17,\n",
      "        1.7958e-17, 5.7150e-17, 1.0738e-18, 7.3422e-17, 7.6886e-17, 5.1215e-17,\n",
      "        4.2125e-17, 7.5242e-02, 4.2690e-19, 6.1536e-17, 6.4579e-18, 2.7619e-19,\n",
      "        3.8585e-18, 1.3697e-17, 6.7040e-18, 3.6973e-17, 6.0594e-18, 5.5801e-02,\n",
      "        3.7684e-17, 1.3292e-17, 3.5672e-17, 9.0831e-17, 3.6494e-17, 3.1350e-17,\n",
      "        2.5055e-17, 4.7654e-18, 9.2093e-17, 4.6862e-02, 1.0220e-17, 4.3754e-17,\n",
      "        2.4960e-17, 3.0270e-17, 3.7622e-18, 1.0245e-18, 5.2178e-18, 6.7913e-17,\n",
      "        1.4496e-17, 6.4025e-02, 3.7152e-17, 5.6891e-17, 5.4518e-17, 4.7561e-19,\n",
      "        1.5702e-17, 4.9523e-18, 3.4118e-17, 5.5262e-17, 7.7413e-18, 4.4866e-02,\n",
      "        3.9793e-17, 4.5403e-17, 2.2110e-17, 4.9643e-19, 1.5712e-17, 2.6782e-18,\n",
      "        2.7157e-18, 9.3746e-17, 1.2792e-18, 5.3557e-02, 4.3395e-17, 6.1717e-17,\n",
      "        7.3889e-17, 4.4106e-18, 1.4482e-20, 7.5962e-18, 7.2382e-17, 8.0093e-18,\n",
      "        8.2433e-19, 6.2039e-02], grad_fn=<DivBackward0>) tensor(0.1125, grad_fn=<UnbindBackward0>) tensor(2.6625, grad_fn=<AddBackward0>)\n",
      "Chosen edges: tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0],\n",
      "        [  5,  15,  25,  35,  45,  55,  65,  76,  86,  96, 106, 116, 126, 136,\n",
      "         146, 156, 166, 176, 186, 197, 207, 217, 228, 238, 248, 259, 269, 280,\n",
      "         290, 300, 310, 320, 332, 342, 356, 366, 376, 391, 401, 415, 425, 440]]) 42\n",
      "amount of added edges: torch.Size([42]) torch.Size([1722, 2])\n",
      "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
      "{'max': tensor(0.1125, grad_fn=<UnbindBackward0>), 'sum': tensor(2.6625, grad_fn=<AddBackward0>), 'len': 416, 'len_choose': 42}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 66.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/64, Train Loss: 0.0377, Val Loss: 0.1074, Val Accuracy: 0.9690\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:12<00:00, 59.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/64, Train Loss: 0.0328, Val Loss: 0.1070, Val Accuracy: 0.9684\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 63.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/64, Train Loss: 0.0284, Val Loss: 0.1090, Val Accuracy: 0.9693\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:11<00:00, 63.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/64, Train Loss: 0.0245, Val Loss: 0.1056, Val Accuracy: 0.9701\n",
      "{}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 9/750 [00:00<00:16, 45.86it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mtrain_sparse_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m64\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m                       \u001b[49m\u001b[43medge_replacement_func\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43medge_replacement_func_new_layer\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[6], line 18\u001b[0m, in \u001b[0;36mtrain_sparse_recursive\u001b[0;34m(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func, window_size, threshold)\u001b[0m\n\u001b[1;32m     15\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs, targets)\n\u001b[1;32m     17\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m---> 18\u001b[0m \u001b[43mloss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;66;03m# if len(len_choose) > 3 and i > window_size:\u001b[39;00m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m#     freeze_all_but_last(model)\u001b[39;00m\n\u001b[1;32m     23\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mstep()\n",
      "File \u001b[0;32m~/anaconda3/envs/self-expanding-nets/lib/python3.12/site-packages/torch/_tensor.py:626\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    616\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    617\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    618\u001b[0m         Tensor\u001b[38;5;241m.\u001b[39mbackward,\n\u001b[1;32m    619\u001b[0m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    624\u001b[0m         inputs\u001b[38;5;241m=\u001b[39minputs,\n\u001b[1;32m    625\u001b[0m     )\n\u001b[0;32m--> 626\u001b[0m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mautograd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    627\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs\u001b[49m\n\u001b[1;32m    628\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/self-expanding-nets/lib/python3.12/site-packages/torch/autograd/__init__.py:347\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    342\u001b[0m     retain_graph \u001b[38;5;241m=\u001b[39m create_graph\n\u001b[1;32m    344\u001b[0m \u001b[38;5;66;03m# The reason we repeat the same comment below is that\u001b[39;00m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;66;03m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    346\u001b[0m \u001b[38;5;66;03m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 347\u001b[0m \u001b[43m_engine_run_backward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    348\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    349\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    350\u001b[0m \u001b[43m    \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    351\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    352\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    353\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_unreachable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    354\u001b[0m \u001b[43m    \u001b[49m\u001b[43maccumulate_grad\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/self-expanding-nets/lib/python3.12/site-packages/torch/autograd/graph.py:823\u001b[0m, in \u001b[0;36m_engine_run_backward\u001b[0;34m(t_outputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    821\u001b[0m     unregister_hooks \u001b[38;5;241m=\u001b[39m _register_logging_hooks_on_whole_graph(t_outputs)\n\u001b[1;32m    822\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 823\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mVariable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execution_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_backward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    824\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt_outputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    825\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Calls into the C++ engine to run the backward pass\u001b[39;00m\n\u001b[1;32m    826\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    827\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m attach_logging_hooks:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_sparse_recursive(sparse_model, train_loader, val_loader, 64, metrics[0],\n",
    "                       edge_replacement_func=edge_replacement_func_new_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "44c29845",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2863])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model.fc1.weight_values[sparse_model.fc1.weight_values > 1e-8].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6162ed2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 6.2616e-09,  6.3876e-09,  1.3104e-09,  2.8574e-09, -2.1528e-01,\n",
       "         2.8560e-09,  8.8170e-09,  4.7567e-09,  4.8345e-10,  1.7017e-09,\n",
       "         9.7213e-09,  5.8228e-09,  8.6957e-09,  5.3322e-10, -2.1531e-01,\n",
       "         9.8957e-09,  5.5075e-09,  3.7054e-09,  9.4094e-10,  4.1665e-09,\n",
       "         5.9588e-09,  6.0718e-09,  9.6920e-09,  9.3723e-11, -1.7371e-01,\n",
       "         1.5218e-09,  5.7825e-09,  7.9518e-09,  4.6619e-09,  4.2538e-09,\n",
       "         5.6038e-09,  7.7219e-09,  2.7703e-09,  8.6223e-09, -1.8589e-01,\n",
       "         7.8512e-09,  1.0788e-09,  3.0154e-09,  4.4037e-09,  1.0803e-09,\n",
       "         8.7425e-09,  7.0480e-09,  4.9039e-09,  9.3589e-09,  2.0061e-01,\n",
       "         6.3386e-09,  4.6793e-09,  4.4443e-09,  4.4504e-09,  6.0459e-09,\n",
       "         5.1762e-09,  6.6578e-09,  9.6561e-09,  7.5907e-09, -1.8022e-01,\n",
       "         4.7682e-09,  4.5682e-10,  8.1985e-09,  4.1293e-10,  5.0787e-09,\n",
       "         1.5348e-09,  5.3798e-09,  5.0537e-09,  6.8203e-09, -2.2200e-01,\n",
       "         5.9968e-09,  4.7665e-09,  2.5003e-09,  9.0589e-09,  9.9195e-09,\n",
       "         9.9669e-09,  6.7938e-09,  8.9198e-09,  9.5426e-09, -2.5093e-01,\n",
       "         9.5068e-09,  1.3844e-09,  1.4195e-09,  9.1465e-09,  1.6231e-09,\n",
       "         4.2350e-09,  2.8406e-09,  1.4509e-09,  5.6555e-09, -2.6385e-01,\n",
       "         6.6431e-09,  2.4737e-09,  4.3495e-09,  7.3491e-10,  8.0125e-09,\n",
       "         7.3673e-09,  5.6145e-09,  7.4576e-09,  4.4563e-09, -2.4967e-01,\n",
       "         5.8528e-09,  1.6188e-09,  7.6322e-09,  6.6285e-09,  9.9673e-09],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model.fc1.weight_values[28*28*10 - 100:28*28*10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8ef5ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optim.Adam(sparse_model.parameters(), lr=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8111dbd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "self-expanding-nets",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
