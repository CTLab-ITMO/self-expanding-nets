{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "932f4bdded4b6539",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.334745Z",
     "start_time": "2025-01-21T14:31:20.096324Z"
    }
   },
   "outputs": [],
   "source": [
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision import datasets, transforms\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a089a23845b1066b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.350457Z",
     "start_time": "2025-01-21T14:31:25.338930Z"
    }
   },
   "outputs": [],
   "source": [
    "from senmodel.model.utils import *\n",
    "from senmodel.metrics.nonlinearity_metrics import *\n",
    "from senmodel.metrics.edge_finder import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "888ee10c0aa4d1f9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.520919Z",
     "start_time": "2025-01-21T14:31:25.513942Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(0)\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "7ab06250d4252047",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.536476Z",
     "start_time": "2025-01-21T14:31:25.528255Z"
    }
   },
   "outputs": [],
   "source": [
    "def train_sparse_recursive(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func=None,\n",
    "                           window_size=2, threshold=0.10):\n",
    "    optimizer = optim.Adam(model.parameters(), lr=5e-5)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        train_loss = 0\n",
    "        for inputs, targets in tqdm(train_loader):\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, targets)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0\n",
    "        all_preds = []\n",
    "        all_targets = []\n",
    "        with torch.no_grad():\n",
    "            for inputs, targets in val_loader:\n",
    "                inputs, targets = inputs.to(device), targets.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, targets)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                preds = torch.argmax(outputs, dim=1)\n",
    "                all_preds.extend(preds.cpu().numpy())\n",
    "                all_targets.extend(targets.cpu().numpy())\n",
    "\n",
    "        val_accuracy = accuracy_score(all_targets, all_preds)\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs} | Train Loss: {train_loss:.4f} | \"\n",
    "              f\"Val Loss: {val_loss:.4f} | Val Accuracy: {val_accuracy:.4f}\")\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Train Loss: {train_loss:.4f}, \"\n",
    "              f\"Val Loss: {val_loss:.4f}, Val Accuracy: {val_accuracy:.4f}\")\n",
    "        new_l = {}\n",
    "        # if edge_replacement_func and epoch % 8 == 0 and epoch != 0:\n",
    "        #     new_l = edge_replacement_func(model, optimizer, val_loader, metric)\n",
    "        val_losses.append(val_loss)\n",
    "        if len(val_losses) > window_size:\n",
    "            recent_changes = [abs(val_losses[i] - val_losses[i - 1]) for i in range(-window_size, 0)]\n",
    "            avg_change = sum(recent_changes) / window_size\n",
    "            print(avg_change, threshold)\n",
    "            if avg_change < threshold:\n",
    "                new_l = edge_replacement_func(model, optimizer, val_loader, metric)\n",
    "\n",
    "                if new_l[\"len_choose\"] == 0:\n",
    "                    break\n",
    "\n",
    "        wandb.log({'val loss': val_loss, 'val accuracy': val_accuracy, 'train loss': train_loss} | new_l)\n",
    "\n",
    "#     if layer.embed_linears:\n",
    "#         optim.add_param_group({'params': layer.embed_linears[-1].weight_values})\n",
    "#     else:\n",
    "#         print(\"empty metric\")\n",
    "#         dummy_param = torch.zeros_like(layer.weight_values)\n",
    "#         optim.add_param_group({'params': dummy_param})\n",
    "\n",
    "def edge_replacement_func_new_layer(model, optim, val_loader, metric):\n",
    "    layer = model.fc1\n",
    "    ef = EdgeFinder(metric, val_loader, device)\n",
    "    vals = ef.calculate_edge_metric_for_dataloader(model)\n",
    "    print(f\"{len(vals)=} {max(vals)=}  {sum(vals)=} {min(vals)=}\")\n",
    "    chosen_edges = ef.choose_edges_threshold(model, 0.15)\n",
    "    print(\"choose:\", chosen_edges, len(chosen_edges[0]))\n",
    "    layer.replace_many(*chosen_edges)\n",
    "\n",
    "    if len(chosen_edges[0]) > 0:\n",
    "        optim.add_param_group({'params': layer.embed_linears[-1].weight_values})\n",
    "    else:\n",
    "        print(\"Empty metric\")\n",
    "\n",
    "    return {'max': max(vals), 'sum': sum(vals), 'len': len(vals), 'len_choose': len(chosen_edges[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "1aff98b408abbf8d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.547124Z",
     "start_time": "2025-01-21T14:31:25.543666Z"
    }
   },
   "outputs": [],
   "source": [
    "# Define the model\n",
    "class SimpleFCN(nn.Module):\n",
    "    def __init__(self, input_size=28 * 28):\n",
    "        super(SimpleFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "90353a5a49cd1022",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:25.590348Z",
     "start_time": "2025-01-21T14:31:25.554956Z"
    }
   },
   "outputs": [],
   "source": [
    "# Dataset and Dataloader\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Lambda(lambda x: x.view(-1))\n",
    "])\n",
    "\n",
    "# Load dataset and split into train/validation sets\n",
    "dataset = datasets.MNIST(root='./data', train=True, download=True, transform=transform)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "824f8403",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:26.796856Z",
     "start_time": "2025-01-21T14:31:25.599555Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: 1179,\n",
       " 7: 1285,\n",
       " 9: 1139,\n",
       " 5: 1121,\n",
       " 3: 1193,\n",
       " 6: 1191,\n",
       " 8: 1150,\n",
       " 0: 1225,\n",
       " 1: 1353,\n",
       " 2: 1154}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict = {}\n",
    "for i in val_dataset:\n",
    "    if i[1] not in label_dict.keys():\n",
    "        label_dict[i[1]] = 0\n",
    "    else:\n",
    "        label_dict[i[1]] += 1\n",
    "label_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "dcb8129e6befdf70",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:26.821483Z",
     "start_time": "2025-01-21T14:31:26.807650Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[  0,   0,   0,  ...,   9,   9,   9],\n",
       "        [  0,   1,   2,  ..., 781, 782, 783]])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "metrics = [\n",
    "    MagnitudeL2Metric(criterion),\n",
    "    SNIPMetric(criterion),\n",
    "    # GradientMeanEdgeMetric(criterion),\n",
    "    PerturbationSensitivityEdgeMetric(criterion),\n",
    "]\n",
    "model = SimpleFCN()\n",
    "sparse_model = convert_dense_to_sparse_network(model)\n",
    "sparse_linear = deepcopy(sparse_model.fc1)\n",
    "sparse_model.fc1.weight_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "589d62a1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:27.487297Z",
     "start_time": "2025-01-21T14:31:27.429843Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
       "          0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0],\n",
       "        [ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16, 17,\n",
       "         18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35,\n",
       "         36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_model.fc1.weight_indices[:, :50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f31e8e93fc6da920",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:27.503110Z",
     "start_time": "2025-01-21T14:31:27.499789Z"
    }
   },
   "outputs": [],
   "source": [
    "# ef = EdgeFinder(metrics[0], val_loader, device)\n",
    "# print(ef.choose_edges_threshold(sparse_model, 0.3))\n",
    "\n",
    "# raise \"e\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "77e8399a",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:31:30.645772Z",
     "start_time": "2025-01-21T14:31:27.560914Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import wandb\n",
    "\n",
    "wandb.login()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "2fa60bac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'num_epochs: 50, metric: MagnitudeL2Metric, aggregation_mode: mean, choose_threshold: 0.3, window_size: 2, threshold: 0.2, lr: 0.0001, replace_all_epochs: 2'"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hyperparams = {\"num_epochs\": 50,\n",
    "               \"metric\": metrics[0],\n",
    "               \"aggregation_mode\": \"mean\",\n",
    "               \"choose_threshold\": 0.3,\n",
    "               \"window_size\": 2,\n",
    "               \"threshold\": 0.2,\n",
    "               \"lr\": 1e-4,\n",
    "               \"replace_all_epochs\": 2\n",
    "               }\n",
    "\n",
    "name = \", \".join(\n",
    "    f\"{key}: {value.__class__.__name__ if key == 'metric' else value}\"\n",
    "    for key, value in hyperparams.items()\n",
    ")\n",
    "name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "8c5fb504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<br>    <style><br>        .wandb-row {<br>            display: flex;<br>            flex-direction: row;<br>            flex-wrap: wrap;<br>            justify-content: flex-start;<br>            width: 100%;<br>        }<br>        .wandb-col {<br>            display: flex;<br>            flex-direction: column;<br>            flex-basis: 100%;<br>            flex: 1;<br>            padding: 10px;<br>        }<br>    </style><br><div class=\"wandb-row\"><div class=\"wandb-col\"><h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>█▄▂▂▂▁▁▁</td></tr><tr><td>val_accuracy</td><td>▁▄▅▆▇▇██</td></tr><tr><td>val_loss</td><td>█▄▃▂▂▁▁▁</td></tr></table><br/></div><div class=\"wandb-col\"><h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>train_loss</td><td>0.37716</td></tr><tr><td>val_accuracy</td><td>0.9</td></tr><tr><td>val_loss</td><td>70.11773</td></tr></table><br/></div></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run <strong style=\"color:#cdcd00\">mnist, num_epochs: 50, metric: MagnitudeL2Metric, aggregation_mode: mean, choose_threshold: 0.3, window_size: 2, threshold: 0.2, lr: 0.0001, replace_all_epochs: 2</strong> at: <a href='https://wandb.ai/fedornigretuk/self-expanding-nets/runs/02y8u8sj' target=\"_blank\">https://wandb.ai/fedornigretuk/self-expanding-nets/runs/02y8u8sj</a><br> View project at: <a href='https://wandb.ai/fedornigretuk/self-expanding-nets' target=\"_blank\">https://wandb.ai/fedornigretuk/self-expanding-nets</a><br>Synced 5 W&B file(s), 0 media file(s), 0 artifact file(s) and 0 other file(s)"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Find logs at: <code>.\\wandb\\run-20250303_162700-02y8u8sj\\logs</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.19.7"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>d:\\Coding\\PY\\self-expanding-nets\\experiments\\training\\wandb\\run-20250303_162909-1k5o0k3s</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/fedornigretuk/self-expanding-nets/runs/1k5o0k3s' target=\"_blank\">mnist, num_epochs: 50, metric: MagnitudeL2Metric, aggregation_mode: mean, choose_threshold: 0.3, window_size: 2, threshold: 0.2, lr: 0.0001, replace_all_epochs: 2</a></strong> to <a href='https://wandb.ai/fedornigretuk/self-expanding-nets' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/fedornigretuk/self-expanding-nets' target=\"_blank\">https://wandb.ai/fedornigretuk/self-expanding-nets</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/fedornigretuk/self-expanding-nets/runs/1k5o0k3s' target=\"_blank\">https://wandb.ai/fedornigretuk/self-expanding-nets/runs/1k5o0k3s</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:09<00:00, 82.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Train Loss: 1.4680 | Val Loss: 185.0530 | Val Accuracy: 0.8227\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:09<00:00, 82.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/50 | Train Loss: 0.7994 | Val Loss: 127.3053 | Val Accuracy: 0.8574\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [00:09<00:00, 82.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/50 | Train Loss: 0.6027 | Val Loss: 103.6949 | Val Accuracy: 0.8708\n",
      "0.024041666666666683 0.2\n",
      "len_choose=[7840]\n",
      "Edge metrics: tensor([1.1976e-04, 7.8726e-04, 3.8084e-04,  ..., 7.1845e-05, 2.8761e-04,\n",
      "        1.3723e-05], grad_fn=<DivBackward0>) tensor(0.0312, grad_fn=<UnbindBackward0>) tensor(26.1728, grad_fn=<AddBackward0>)\n",
      "Chosen edges: tensor([[  0,   0,   0,  ...,   9,   9,   9],\n",
      "        [ 68,  69,  71,  ..., 716, 717, 719]]) 834\n",
      "834 834 torch.Size([2, 331932]) torch.Size([331932])\n",
      "tensor([[  0,   0,   0,  ..., 833, 833, 833],\n",
      "        [ 65,  67,  68,  ..., 745, 746, 747]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:16<00:00,  9.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/50 | Train Loss: 0.5191 | Val Loss: 71.9215 | Val Accuracy: 0.8963\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:36<00:00,  7.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/50 | Train Loss: 0.3482 | Val Loss: 61.9030 | Val Accuracy: 0.9083\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [01:35<00:00,  7.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/50 | Train Loss: 0.3123 | Val Loss: 57.3737 | Val Accuracy: 0.9157\n",
      "0.009708333333333319 0.2\n",
      "len_choose=[7840, 834]\n",
      "Edge metrics: tensor([1.1976e-04, 7.8726e-04, 3.8084e-04,  ..., 1.2477e-18, 2.7530e-17,\n",
      "        9.6830e-03], grad_fn=<DivBackward0>) tensor(0.0312, grad_fn=<UnbindBackward0>) tensor(26.1728, grad_fn=<AddBackward0>)\n",
      "Chosen edges: tensor([[   0,    0,    0,  ...,    9,    9,    9],\n",
      "        [ 784,  785,  786,  ..., 1615, 1616, 1617]]) 834\n",
      "834 834 torch.Size([2, 695556]) torch.Size([695556])\n",
      "tensor([[   0,    0,    0,  ...,  833,  833,  833],\n",
      "        [ 784,  785,  786,  ..., 1615, 1616, 1617]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [08:17<00:00,  1.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/50 | Train Loss: 0.2766 | Val Loss: 49.2833 | Val Accuracy: 0.9233\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [08:52<00:00,  1.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/50 | Train Loss: 0.2205 | Val Loss: 40.0635 | Val Accuracy: 0.9380\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [08:56<00:00,  1.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/50 | Train Loss: 0.1802 | Val Loss: 33.3641 | Val Accuracy: 0.9468\n",
      "0.011749999999999983 0.2\n",
      "len_choose=[7840, 834, 834]\n",
      "Edge metrics: tensor([3.5717e-17, 5.0352e-19, 3.7867e-19, 1.1071e-02, 8.2497e-19, 1.5362e-18,\n",
      "        2.6330e-17, 9.6031e-18, 4.5548e-18, 1.1765e-17, 3.5050e-17, 8.2674e-21,\n",
      "        5.3735e-17, 1.1747e-02, 5.2300e-17, 5.6896e-17, 2.7420e-17, 2.4998e-17,\n",
      "        1.0095e-17, 1.5587e-17, 8.3107e-18, 4.7619e-17, 4.7238e-17, 1.7355e-02,\n",
      "        2.2979e-17, 1.2199e-18, 6.8603e-17, 9.6402e-18, 3.8528e-19, 1.0501e-17,\n",
      "        8.6679e-17, 4.0771e-17, 1.8569e-17, 1.9622e-02, 5.1766e-17, 2.2936e-18,\n",
      "        8.2648e-17, 7.6504e-17, 6.8398e-17, 5.7063e-17, 4.3181e-17, 9.8480e-17,\n",
      "        4.9506e-17, 1.7662e-02, 4.1696e-17, 4.5229e-18, 3.6166e-17, 4.9385e-18,\n",
      "        5.3975e-17, 7.6762e-17, 3.8769e-17, 4.9396e-17, 1.5036e-17, 1.4619e-02,\n",
      "        6.0122e-17, 1.4180e-18, 4.9899e-17, 8.1855e-18, 3.1263e-17, 3.7619e-17,\n",
      "        5.0611e-17, 7.5174e-17, 4.3913e-19, 1.7153e-02, 2.5605e-17, 3.4336e-18,\n",
      "        4.1513e-17, 2.9334e-19, 7.3141e-17, 1.5077e-17, 3.3114e-17, 3.6887e-17,\n",
      "        5.8151e-17, 1.0475e-02, 3.3778e-18, 7.6260e-17, 1.2210e-17, 4.6629e-17,\n",
      "        9.7251e-17, 4.5157e-17, 5.6358e-17, 8.1080e-17, 6.6948e-24, 1.3084e-02,\n",
      "        7.7117e-17, 6.0402e-17, 1.8154e-17, 6.6120e-18, 6.1671e-19, 2.0595e-17,\n",
      "        5.3417e-17, 3.3551e-19, 1.4200e-17, 1.1264e-02, 5.1017e-19, 4.5398e-17,\n",
      "        7.7122e-17, 2.5896e-17, 9.3607e-17, 3.7514e-17, 2.6165e-17, 7.4874e-17,\n",
      "        5.8459e-17, 9.6491e-03, 3.1848e-19, 1.2108e-18, 3.1613e-17, 8.9362e-17,\n",
      "        1.1156e-17, 1.1648e-17, 6.7266e-17, 1.5378e-17, 4.1768e-17, 1.0585e-02,\n",
      "        3.0249e-17, 7.9588e-17, 6.3357e-17, 2.1457e-17, 1.4194e-18, 2.4344e-17,\n",
      "        5.6911e-17, 1.9792e-17, 1.3531e-18, 1.3891e-02, 7.0202e-19, 8.1275e-17,\n",
      "        9.6825e-18, 1.6626e-17, 1.5067e-17, 8.7849e-17, 1.8303e-17, 1.4101e-17,\n",
      "        4.2131e-17, 9.9108e-03, 5.4008e-17, 3.7189e-17, 4.5318e-18, 9.4768e-17,\n",
      "        2.3852e-18, 7.1318e-18, 7.3110e-19, 3.9687e-17, 2.2547e-17, 1.9034e-02,\n",
      "        7.5255e-17, 8.6150e-17, 4.3686e-17, 2.2469e-17, 4.8383e-17, 4.7547e-17,\n",
      "        9.8395e-17, 2.1051e-17, 4.6272e-17, 1.4528e-02, 8.1356e-17, 1.4328e-17,\n",
      "        8.0102e-18, 9.1922e-17, 5.8428e-18, 1.1364e-17, 7.9869e-17, 3.3643e-17,\n",
      "        6.8365e-17, 1.7247e-02, 4.8479e-18, 1.9881e-18, 1.7736e-17, 8.3667e-18,\n",
      "        3.4406e-17, 4.8759e-17, 2.6056e-17, 1.3047e-17, 2.7040e-17, 1.6772e-02,\n",
      "        4.5071e-17, 7.3539e-17, 5.4220e-17, 3.8812e-17, 4.8850e-18, 8.1081e-17,\n",
      "        1.1051e-17, 3.4347e-17, 3.1532e-17, 1.4829e-02, 7.6777e-17, 8.8434e-20,\n",
      "        5.0403e-17, 1.1772e-19, 6.9696e-17, 7.4389e-18, 1.9012e-22, 2.7935e-17,\n",
      "        3.5929e-18, 1.1667e-02, 4.4661e-18, 7.4198e-18, 7.4361e-17, 7.2736e-18,\n",
      "        1.6714e-17, 1.1524e-17, 9.6042e-17, 5.9394e-17, 5.2292e-17, 1.0963e-02,\n",
      "        4.6908e-17, 4.0281e-17, 3.8022e-17, 9.6614e-18, 6.4153e-20, 4.4196e-17,\n",
      "        2.6174e-19, 5.3334e-17, 9.5428e-17, 1.7691e-02, 7.5926e-17, 1.4303e-17,\n",
      "        8.3803e-17, 1.4554e-17, 4.4595e-17, 7.5860e-17, 2.0808e-17, 5.7975e-17,\n",
      "        2.7627e-18, 1.3729e-02, 3.7695e-17, 2.2859e-18, 1.4722e-20, 1.1440e-18,\n",
      "        2.8437e-17, 1.8895e-17, 8.3529e-17, 1.8889e-17, 2.0452e-17, 1.1070e-02,\n",
      "        4.2238e-17, 9.7756e-17, 7.9473e-18, 1.5589e-17, 3.3952e-18, 7.9137e-17,\n",
      "        9.7387e-17, 4.7083e-17, 4.5134e-18, 1.5098e-02, 8.2330e-17, 4.1766e-17,\n",
      "        1.0254e-18, 7.0343e-18, 1.9336e-17, 8.1516e-18, 6.6705e-17, 2.8598e-17,\n",
      "        9.3944e-17, 1.2350e-02, 1.7974e-17, 5.3405e-17, 2.9824e-17, 3.8075e-18,\n",
      "        5.8540e-17, 1.0295e-17, 8.4867e-17, 1.7412e-17, 2.4133e-19, 1.1984e-02,\n",
      "        1.0582e-17, 7.0237e-17, 4.5370e-18, 3.5124e-17, 8.5963e-21, 1.8607e-17,\n",
      "        2.4300e-17, 2.5893e-17, 1.4995e-17, 1.1005e-02, 6.6615e-17, 4.3742e-17,\n",
      "        9.2405e-17, 2.2077e-17, 9.3800e-17, 3.1506e-17, 2.4458e-17, 7.7881e-17,\n",
      "        9.5112e-17, 1.7425e-02, 3.2490e-17, 5.5629e-19, 1.4132e-19, 3.8997e-17,\n",
      "        6.0954e-17, 4.4771e-18, 2.3998e-17, 4.7827e-17, 5.6212e-17, 2.3166e-02,\n",
      "        9.7476e-18, 1.2500e-17, 1.2951e-18, 4.2049e-17, 9.0995e-17, 1.5721e-19,\n",
      "        6.1157e-17, 4.7522e-18, 2.9627e-17, 1.6581e-02, 1.2315e-17, 4.5741e-17,\n",
      "        2.4026e-17, 1.2373e-17, 6.9168e-18, 1.8752e-17, 4.9582e-17, 4.0858e-18,\n",
      "        6.8583e-17, 1.0262e-02, 9.1873e-18, 8.5652e-17, 6.7034e-17, 4.8813e-18,\n",
      "        4.2109e-17, 2.6751e-17, 2.1721e-17, 5.6581e-17, 9.6660e-17, 1.7215e-02,\n",
      "        6.5960e-17, 5.5819e-17, 6.9200e-18, 5.3368e-17, 1.0742e-18, 1.6962e-17,\n",
      "        2.6445e-17, 1.2325e-17, 7.9438e-17, 1.2109e-02, 2.2644e-17, 3.0811e-17,\n",
      "        5.7958e-17, 2.9473e-17, 7.5262e-18, 9.9822e-18, 5.4979e-17, 4.1981e-17,\n",
      "        2.5193e-18, 1.7131e-02, 4.9429e-17, 7.6790e-17, 8.6874e-17, 3.2030e-17,\n",
      "        1.3201e-17, 2.2898e-17, 8.2375e-17, 5.8109e-20, 2.5059e-17, 1.6473e-02,\n",
      "        3.1204e-18, 2.1053e-19, 2.8741e-17, 3.6207e-17, 4.6493e-17, 3.7854e-17,\n",
      "        1.3959e-17, 1.3702e-18, 7.3047e-17, 1.0576e-02, 9.0071e-19, 3.9506e-18,\n",
      "        9.1607e-17, 8.5977e-17, 1.6408e-17, 9.9714e-19, 4.4309e-17, 1.7963e-18,\n",
      "        2.7075e-17, 9.4578e-03, 6.3034e-17, 3.9128e-17, 2.5763e-17, 3.1030e-18,\n",
      "        1.3935e-17, 8.6225e-17, 5.7138e-17, 8.9751e-18, 4.7470e-18, 1.4867e-02,\n",
      "        9.6720e-17, 8.3202e-17, 7.2670e-18, 1.4189e-18, 4.2370e-17, 3.0210e-17,\n",
      "        9.8665e-18, 2.3850e-17, 6.5805e-19, 1.9282e-02, 1.5499e-17, 6.9580e-17,\n",
      "        7.5200e-18, 3.2396e-17, 6.9708e-17, 9.3425e-19, 5.8706e-17, 2.4014e-18,\n",
      "        5.9988e-18, 1.4916e-02, 8.6194e-19, 4.2739e-19, 8.9208e-17, 9.2498e-17,\n",
      "        7.1078e-19, 2.1317e-17, 9.9308e-19, 5.6874e-17, 7.2179e-17, 2.1227e-02,\n",
      "        3.4555e-17, 6.0705e-17, 7.4027e-17, 6.4926e-18, 1.5602e-18, 8.9194e-17,\n",
      "        3.4989e-18, 1.2548e-17, 4.8031e-18, 9.6015e-03, 9.1404e-17, 9.5189e-18,\n",
      "        4.3163e-18, 7.3220e-17, 8.0247e-17, 1.9935e-17, 4.5194e-17, 3.1241e-20,\n",
      "        1.7954e-17, 1.0723e-02, 9.8488e-18, 7.6380e-17, 1.6445e-17, 1.2609e-18,\n",
      "        1.4744e-17, 6.6295e-17, 2.3854e-17, 4.7615e-17, 3.5442e-17, 1.2812e-02,\n",
      "        1.5998e-17, 6.7210e-17, 5.5888e-17, 1.7405e-18, 6.4417e-17, 7.8747e-17,\n",
      "        5.2552e-18, 7.8633e-18, 2.6685e-19, 1.3022e-02, 7.6914e-18, 1.0042e-17,\n",
      "        2.1954e-17, 6.7396e-17, 7.3555e-17, 3.6427e-17, 1.8023e-17, 3.5937e-19,\n",
      "        6.1066e-17, 1.3388e-02, 9.8765e-17, 2.4616e-19, 5.1181e-17, 2.0898e-17,\n",
      "        7.6338e-18, 2.9829e-17, 6.7763e-17, 2.5556e-17, 2.2600e-17, 1.6372e-02,\n",
      "        5.8113e-17, 1.7583e-17, 4.3649e-18, 6.8597e-18, 2.4990e-17, 7.0316e-17,\n",
      "        5.4127e-17, 3.7919e-18, 2.5555e-17, 1.5013e-02, 6.8859e-17, 1.6133e-19,\n",
      "        8.9434e-18, 8.3866e-17, 5.9313e-17, 5.4000e-18, 6.0803e-18, 2.7656e-17,\n",
      "        9.0368e-17, 1.0184e-02, 2.5128e-17, 1.3350e-17, 8.4501e-17, 4.6969e-17,\n",
      "        8.1692e-18, 7.2137e-17, 6.3930e-17, 1.9759e-17, 1.9341e-18, 1.5839e-02,\n",
      "        1.8093e-17, 7.2190e-18, 5.5866e-17, 7.7730e-18, 7.8780e-17, 9.6532e-18,\n",
      "        9.0607e-17, 1.3411e-17, 6.7979e-18, 9.5894e-03, 3.8839e-17, 3.1891e-17,\n",
      "        1.6658e-17, 1.9918e-17, 6.3242e-17, 5.6783e-18, 5.2210e-17, 3.0645e-17,\n",
      "        1.9534e-17, 1.3278e-02, 1.0437e-17, 1.6287e-17, 3.6999e-20, 2.8933e-17,\n",
      "        2.9818e-18, 2.5926e-19, 3.3806e-17, 2.9144e-20, 2.0019e-17, 1.1719e-02,\n",
      "        7.2045e-18, 6.8527e-17, 2.9539e-17, 4.7052e-18, 5.3277e-19, 1.2628e-17,\n",
      "        5.9367e-17, 4.6135e-17, 6.5370e-18, 1.2006e-02, 1.9757e-19, 1.5406e-17,\n",
      "        1.7170e-18, 9.3929e-18, 9.9254e-17, 4.9189e-18, 1.4353e-17, 8.8304e-18,\n",
      "        7.1415e-17, 1.1467e-02, 2.6470e-17, 6.0479e-19, 2.8996e-17, 1.2193e-21,\n",
      "        1.5577e-17, 2.9925e-17, 9.1588e-17, 1.7464e-17, 6.2004e-18, 1.0241e-02,\n",
      "        4.4154e-17, 2.7756e-17, 8.3470e-19, 3.6226e-17, 4.3672e-18, 7.1968e-18,\n",
      "        9.9531e-17, 4.9047e-17, 8.1447e-17, 1.1320e-02, 8.7685e-17, 2.2498e-17,\n",
      "        1.9830e-18, 9.5827e-19, 1.5814e-17, 8.8043e-17, 4.0361e-17, 6.8286e-17,\n",
      "        4.4275e-17, 1.3219e-02, 5.6465e-17, 3.0470e-17, 3.4002e-17, 3.9757e-17,\n",
      "        4.1085e-19, 2.9768e-17, 1.8074e-17, 3.1881e-17, 4.2496e-17, 1.4183e-02,\n",
      "        7.1204e-17, 2.5232e-17, 1.8590e-17, 5.7809e-17, 1.4922e-18, 1.2040e-18,\n",
      "        5.7857e-17, 6.7703e-18, 1.0402e-17, 1.5600e-02, 7.6197e-18, 6.4176e-17,\n",
      "        5.3956e-18, 6.9506e-17, 4.8881e-17, 4.5379e-17, 1.3283e-17, 6.0831e-18,\n",
      "        1.6894e-17, 1.2755e-02, 4.5820e-17, 1.0493e-17, 8.6238e-17, 4.9043e-17,\n",
      "        1.9698e-17, 2.1683e-17, 3.8717e-17, 5.9078e-17, 1.2492e-17, 1.3683e-02,\n",
      "        8.3204e-17, 6.9053e-20, 1.6301e-17, 4.9302e-17, 4.6976e-17, 2.4239e-19,\n",
      "        2.0490e-17, 3.0571e-18, 4.4435e-19, 9.9658e-03, 3.2474e-18, 8.2855e-18,\n",
      "        8.5662e-17, 3.5830e-17, 2.0325e-17, 4.0251e-17, 6.9544e-17, 3.1706e-19,\n",
      "        7.6428e-18, 1.1040e-02, 2.2393e-18, 9.5615e-18, 4.1604e-17, 5.0362e-18,\n",
      "        7.8277e-17, 1.9757e-17, 2.5470e-18, 9.7271e-18, 1.0234e-17, 1.1247e-02,\n",
      "        4.2263e-18, 8.9277e-17, 7.1801e-18, 6.9609e-17, 1.6466e-19, 1.1576e-18,\n",
      "        8.0493e-17, 2.1143e-17, 4.2446e-17, 1.1516e-02, 2.1923e-17, 4.7833e-18,\n",
      "        5.4893e-17, 5.7158e-18, 8.3863e-17, 7.6520e-18, 8.1043e-17, 6.6639e-17,\n",
      "        8.5497e-17, 1.7677e-02, 7.7735e-17, 9.9042e-17, 6.1325e-17, 3.3759e-18,\n",
      "        7.2824e-17, 4.6072e-18, 9.0385e-19, 3.8033e-17, 4.3045e-17, 1.8001e-02,\n",
      "        5.0631e-18, 3.5356e-20, 1.9971e-20, 1.3035e-17, 5.4515e-17, 5.8603e-18,\n",
      "        6.6275e-17, 6.0575e-17, 5.1504e-17, 1.9621e-02, 9.9469e-17, 1.2297e-17,\n",
      "        1.9000e-17, 4.8018e-22, 8.2805e-17, 6.3547e-17, 5.9317e-17, 5.9461e-18,\n",
      "        5.0658e-17, 1.2520e-02, 8.4099e-17, 1.2585e-17, 5.2921e-17, 2.8662e-17,\n",
      "        6.7713e-19, 5.4588e-18, 3.2337e-17, 3.9809e-19, 8.3359e-17, 1.9068e-02,\n",
      "        1.0325e-19, 2.1323e-17, 3.3476e-17, 6.8511e-20, 2.5387e-17, 1.7950e-18,\n",
      "        4.0196e-17, 1.6852e-17, 2.4484e-19, 9.9932e-03, 1.5493e-17, 2.7749e-18,\n",
      "        5.5799e-19, 6.6732e-18, 4.6662e-17, 1.9865e-17, 1.5515e-19, 8.5079e-17,\n",
      "        8.2903e-18, 1.7138e-02, 9.7024e-18, 1.3153e-17, 7.3097e-17, 2.3692e-18,\n",
      "        9.3616e-18, 9.8640e-17, 9.9246e-17, 1.0065e-18, 2.1180e-18, 1.1905e-02,\n",
      "        6.8329e-17, 3.6185e-17, 7.5567e-19, 2.9520e-18, 2.2482e-17, 7.8630e-18,\n",
      "        3.9924e-17, 3.0327e-18, 3.8571e-17, 9.7984e-03, 1.7267e-20, 2.9278e-18,\n",
      "        2.8509e-17, 1.4936e-17, 1.9255e-17, 6.5175e-18, 2.5859e-17, 3.6661e-18,\n",
      "        1.8608e-18, 1.2155e-02, 6.3168e-18, 6.0552e-17, 1.8836e-18, 2.7023e-17,\n",
      "        8.1127e-19, 6.3252e-18, 5.7394e-17, 7.5930e-19, 6.3083e-17, 1.3016e-02,\n",
      "        8.0678e-17, 7.5944e-18, 5.3129e-18, 7.2395e-17, 9.3735e-17, 9.9188e-17,\n",
      "        1.0960e-17, 9.7069e-17, 2.7455e-17, 9.8228e-03, 2.6099e-17, 1.0208e-18,\n",
      "        6.5309e-17, 2.6603e-17, 3.5013e-17, 3.6967e-17, 4.9614e-17, 6.3942e-17,\n",
      "        5.9775e-17, 1.0611e-02, 2.7741e-19, 9.3836e-17, 1.3066e-17, 2.8785e-17,\n",
      "        3.6513e-17, 1.0662e-17, 2.1979e-17, 1.3344e-17, 1.6379e-18, 9.4053e-03,\n",
      "        1.6909e-19, 3.5534e-18, 8.0885e-18, 5.0610e-17, 1.9321e-17, 4.7987e-17,\n",
      "        2.6250e-17, 4.9909e-17, 2.4926e-17, 9.8488e-03, 6.5664e-17, 1.2967e-17,\n",
      "        8.5213e-17, 1.2201e-17, 6.9393e-17, 5.8354e-18, 5.2662e-18, 1.4775e-17,\n",
      "        7.5744e-18, 1.3454e-02, 1.3360e-17, 5.4360e-17, 2.1338e-17, 3.7783e-17,\n",
      "        1.2941e-18, 4.1274e-17, 6.9510e-18, 9.4771e-17, 2.0384e-17, 9.6830e-03],\n",
      "       grad_fn=<DivBackward0>) tensor(0.0232, grad_fn=<UnbindBackward0>) tensor(1.1402, grad_fn=<AddBackward0>)\n",
      "Chosen edges: tensor([[  0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
      "           0,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1,   1],\n",
      "        [  3,  13,  23,  33,  43,  53,  63,  76,  86,  99, 111, 121, 131, 141,\n",
      "         151, 161, 171, 182, 192, 203, 213, 225, 235, 245, 256, 266, 276, 288,\n",
      "         298, 309, 319, 333, 343, 358, 368, 385, 395, 410, 421, 438, 448, 463,\n",
      "         474, 484, 500, 510, 523, 533, 543, 554, 564, 574, 584, 594, 605, 615,\n",
      "         625, 635, 645, 655, 665, 675, 685, 696, 706, 722, 732, 745, 755, 765,\n",
      "         775,   1,  11,  21,  31,  41,  51,  61,  71,  82,  92, 107, 117, 127]]) 84\n",
      "84 84 torch.Size([2, 7056]) torch.Size([7056])\n",
      "tensor([[  0,   0,   0,  ...,  83,  83,  83],\n",
      "        [  1,   3,  11,  ..., 755, 765, 775]])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 750/750 [09:23<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/50 | Train Loss: 0.1530 | Val Loss: 32.3544 | Val Accuracy: 0.9495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 250/750 [03:33<07:07,  1.17it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 10\u001b[39m\n\u001b[32m      3\u001b[39m wandb.finish()\n\u001b[32m      4\u001b[39m wandb.init(\n\u001b[32m      5\u001b[39m     project=\u001b[33m\"\u001b[39m\u001b[33mself-expanding-nets\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      6\u001b[39m     name=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mmnist, \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     tags=[\u001b[33m\"\u001b[39m\u001b[33mmulticlass\u001b[39m\u001b[33m\"\u001b[39m, hyperparams[\u001b[33m\"\u001b[39m\u001b[33mmetric\u001b[39m\u001b[33m\"\u001b[39m].\u001b[34m__class__\u001b[39m.\u001b[34m__name__\u001b[39m],\n\u001b[32m      8\u001b[39m )\n\u001b[32m---> \u001b[39m\u001b[32m10\u001b[39m \u001b[43mtrain_sparse_recursive\u001b[49m\u001b[43m(\u001b[49m\u001b[43msparse_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m                       \u001b[49m\u001b[43medge_replacement_func\u001b[49m\u001b[43m=\u001b[49m\u001b[43medge_replacement_func_new_layer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mhyperparams\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mtrain_sparse_recursive\u001b[39m\u001b[34m(model, train_loader, val_loader, num_epochs, metric, edge_replacement_func, window_size, threshold, lr, choose_threshold, aggregation_mode, replace_all_epochs)\u001b[39m\n\u001b[32m     75\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (inputs, targets) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(tqdm(train_loader)):\n\u001b[32m     76\u001b[39m     inputs, targets = inputs.to(device), targets.to(device)\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     outputs = \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     78\u001b[39m     loss = criterion(outputs, targets)\n\u001b[32m     79\u001b[39m     loss.backward()\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[71]\u001b[39m\u001b[32m, line 8\u001b[39m, in \u001b[36mSimpleFCN.forward\u001b[39m\u001b[34m(self, x)\u001b[39m\n\u001b[32m      7\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     x = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfc1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      9\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Coding\\PY\\self-expanding-nets\\senmodel\\model\\model.py:156\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    153\u001b[39m     for param in embed_linear.parameters():\n\u001b[32m    154\u001b[39m         param.requires_grad = True\n\u001b[32m--> \u001b[39m\u001b[32m156\u001b[39m # Разморозить все веса в weight_values\n\u001b[32m    157\u001b[39m if hasattr(self, \"weight_values\"):\n\u001b[32m    158\u001b[39m     for param in self.weight_values:\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1737\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1738\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1739\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32md:\\Coding\\PY\\self-expanding-nets\\.venv\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1745\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1746\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1747\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1748\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1749\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1750\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1752\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1753\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mD:\\Coding\\PY\\self-expanding-nets\\senmodel\\model\\model.py:71\u001b[39m, in \u001b[36mforward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     68\u001b[39m i_indices, j_indices = torch.nonzero(mask, as_tuple=True)\n\u001b[32m     69\u001b[39m zero_edges = torch.stack([i_indices, unique_parents[j_indices]], dim=1).unique(dim=0)\n\u001b[32m---> \u001b[39m\u001b[32m71\u001b[39m # Пакетное добавление нулевых ребер\n\u001b[32m     72\u001b[39m for edge in zero_edges:\n\u001b[32m     73\u001b[39m     self.add_edge(int(edge[0]), int(edge[1]), original_weight=0)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "dense_model = SimpleFCN()\n",
    "sparse_model = convert_dense_to_sparse_network(dense_model)\n",
    "wandb.finish()\n",
    "wandb.init(\n",
    "    project=\"self-expanding-nets\",\n",
    "    name=f\"mnist, {name}\",\n",
    "    tags=[\"multiclass\", hyperparams[\"metric\"].__class__.__name__],\n",
    ")\n",
    "\n",
    "train_sparse_recursive(sparse_model, train_loader, val_loader,\n",
    "                       edge_replacement_func=edge_replacement_func_new_layer, **hyperparams)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "110f89610af467b2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-21T14:56:03.800493200Z",
     "start_time": "2024-12-16T14:40:49.271871Z"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
