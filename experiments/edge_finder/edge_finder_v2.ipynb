{
 "cells": [
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:54:21.995573Z",
     "start_time": "2024-11-05T12:54:21.985856Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np"
   ],
   "id": "42bc48fef93f3563",
   "outputs": [],
   "execution_count": 13
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T12:45:45.758983Z",
     "start_time": "2024-11-05T12:45:45.748794Z"
    }
   },
   "cell_type": "code",
   "source": "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')",
   "id": "567142dbd6915542",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Создадим простую модель",
   "id": "abc05d772f5b8d80"
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-11-05T14:14:57.284872Z",
     "start_time": "2024-11-05T14:14:57.277800Z"
    }
   },
   "source": [
    "class SimpleFCN(nn.Module):\n",
    "    def __init__(self, input_size=8):\n",
    "        super(SimpleFCN, self).__init__()\n",
    "        self.fc1 = nn.Linear(input_size, 4)\n",
    "        self.fc2 = nn.Linear(4, 10)\n",
    "        self.fc3 = nn.Linear(10, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.relu(self.fc1(x))\n",
    "        x = self.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ],
   "outputs": [],
   "execution_count": 59
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T14:14:57.836193Z",
     "start_time": "2024-11-05T14:14:57.829002Z"
    }
   },
   "cell_type": "code",
   "source": [
    "input_size = 8\n",
    "simple_model = SimpleFCN(input_size)\n"
   ],
   "id": "85fa19436a95623d",
   "outputs": [],
   "execution_count": 60
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T14:14:59.169843Z",
     "start_time": "2024-11-05T14:14:59.143001Z"
    }
   },
   "cell_type": "code",
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.datasets import make_regression\n",
    "\n",
    "X, y = make_regression(n_samples=1000, n_features=input_size, n_informative=input_size, random_state=42)\n",
    "X = torch.from_numpy(X).float()\n",
    "y = torch.from_numpy(y).float()\n",
    "\n",
    "dataset = list(zip(X, y))\n",
    "train_dataset, test_dataset = train_test_split(dataset, test_size=0.2, random_state=42)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)"
   ],
   "id": "e597b4a8e7860eea",
   "outputs": [],
   "execution_count": 61
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# metrics\n",
    "Метрики для оценки нелинейности"
   ],
   "id": "95ee915b98a4312"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T14:02:42.567600Z",
     "start_time": "2024-11-05T14:02:42.561154Z"
    }
   },
   "cell_type": "code",
   "source": "criterion = nn.MSELoss()",
   "id": "aad65a7d0588c0ad",
   "outputs": [],
   "execution_count": 47
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T14:19:01.804765Z",
     "start_time": "2024-11-05T14:19:01.788328Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class NonlinearityMetric:\n",
    "    def __init__(self, loss_fn):\n",
    "        self.loss_fn = loss_fn\n",
    "\n",
    "    @staticmethod\n",
    "    def _get_last_linear_layer(model):\n",
    "        layers = [module for module in model.modules() if isinstance(module, nn.Linear)]\n",
    "        if not layers:\n",
    "            raise ValueError(\"В модели отсутствуют слои nn.Linear.\")\n",
    "        return layers[-1]\n",
    "\n",
    "    def calculate(self, model, X_arr, y_arr):\n",
    "        raise NotImplementedError()\n",
    "\n",
    "\n",
    "# Метрика 1: Средний градиент последнего слоя для каждого ребра\n",
    "class GradientMeanEdgeMetric(NonlinearityMetric):\n",
    "    def calculate(self, model, X_arr, y_arr):\n",
    "        model.eval()\n",
    "        model.zero_grad()\n",
    "        y_pred = model(X_arr).squeeze()\n",
    "        loss = self.loss_fn(y_pred, y_arr)\n",
    "        loss.backward()\n",
    "\n",
    "        last_layer = self._get_last_linear_layer(model)\n",
    "        edge_gradients = last_layer.weight.grad.abs()\n",
    "        model.zero_grad()\n",
    "        return edge_gradients\n",
    "\n",
    "    # Метрика 2: Стандартное отклонение активаций последнего слоя для каждого ребра\n",
    "\n",
    "\n",
    "class ActivationStdEdgeMetric(NonlinearityMetric):\n",
    "    def calculate(self, model, X_arr, y_arr):\n",
    "        model.eval()\n",
    "\n",
    "        # Пропуск через модель и получение активаций перед последним слоем\n",
    "        x = X_arr\n",
    "        for layer in list(model.children())[:-1]:  # Все слои, кроме последнего\n",
    "            x = layer(x)\n",
    "        activations = x  # Активации перед последним линейным слоем\n",
    "\n",
    "        last_layer = self._get_last_linear_layer(model)\n",
    "        edge_activations = activations.unsqueeze(-1) * last_layer.weight  # Активности, пропорциональные весам\n",
    "        activation_std_edges = edge_activations.std(dim=0)\n",
    "        return activation_std_edges\n",
    "\n",
    "\n",
    "# Метрика 3: Чувствительность к возмущению для каждого ребра\n",
    "class PerturbationSensitivityEdgeMetric(NonlinearityMetric):\n",
    "    def __init__(self, loss_fn, epsilon=1e-2):\n",
    "        super().__init__(loss_fn)\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def calculate(self, model, X_arr, y_arr):\n",
    "        model.eval()\n",
    "\n",
    "        # Пропуск входа через модель и получение оригинального вывода\n",
    "        original_output = model(X_arr).detach()\n",
    "\n",
    "        last_layer = self._get_last_linear_layer(model)\n",
    "        sensitivities = torch.zeros_like(last_layer.weight)\n",
    "\n",
    "        # Возмущаем каждый вес по отдельности и измеряем чувствительность\n",
    "        for i in range(last_layer.weight.size(0)):\n",
    "            for j in range(last_layer.weight.size(1)):\n",
    "                with torch.no_grad():\n",
    "                    # Возмущение только одного веса\n",
    "                    original_weight = last_layer.weight[i, j].clone()\n",
    "                    last_layer.weight[i, j] += self.epsilon\n",
    "\n",
    "                    # Пропуск с возмущением и вычисление чувствительности\n",
    "                    perturbed_output = model(X_arr)\n",
    "                    sensitivity = (perturbed_output - original_output).abs().mean().item()\n",
    "                    sensitivities[i, j] = sensitivity\n",
    "\n",
    "                    # Восстановление оригинального веса\n",
    "                    last_layer.weight[i, j] = original_weight\n",
    "\n",
    "        return sensitivities\n",
    "\n",
    "\n",
    "# Метрика 4: Косинусное расстояние между градиентами для каждого ребра\n",
    "class CosineGradientSimilarityEdgeMetric(NonlinearityMetric):\n",
    "    def calculate(self, model, X_arr, y_arr):\n",
    "        model.eval()\n",
    "        outputs = model(X_arr)\n",
    "        loss = outputs.mean()\n",
    "        loss.backward()\n",
    "\n",
    "        last_layer = self._get_last_linear_layer(model)\n",
    "        grad_last_layer = last_layer.weight.grad\n",
    "\n",
    "        # Косинусное сходство между соседними градиентами для каждого ребра\n",
    "        similarities = torch.zeros_like(grad_last_layer)\n",
    "        for i in range(grad_last_layer.size(0)):\n",
    "            for j in range(grad_last_layer.size(1) - 1):  # Для соседних элементов\n",
    "                # Убираем dim=1, поскольку каждый градиент - скаляр или одномерный тензор\n",
    "                cos_sim = F.cosine_similarity(grad_last_layer[i, j].unsqueeze(0),\n",
    "                                              grad_last_layer[i, j + 1].unsqueeze(0), dim=0)\n",
    "                similarities[i, j] = cos_sim\n",
    "\n",
    "        model.zero_grad()\n",
    "        return similarities\n",
    "\n",
    "\n",
    "\n",
    "metrics = [\n",
    "    GradientMeanEdgeMetric(criterion),\n",
    "    ActivationStdEdgeMetric(criterion),\n",
    "    PerturbationSensitivityEdgeMetric(criterion),\n",
    "    CosineGradientSimilarityEdgeMetric(criterion)\n",
    "]"
   ],
   "id": "2809973941579056",
   "outputs": [],
   "execution_count": 92
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T14:19:02.197026Z",
     "start_time": "2024-11-05T14:19:02.188306Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def calculate_edge_metric_for_dataloader(model, dataloader, edgeMetric: NonlinearityMetric):\n",
    "    accumulated_grads = None\n",
    "    for data, target in dataloader:\n",
    "        data, target = data.to(device), target.to(device)\n",
    "\n",
    "        metric = edgeMetric.calculate(model, data, target)\n",
    "        \n",
    "        if accumulated_grads is None:\n",
    "            accumulated_grads = torch.zeros_like(metric).to(device)\n",
    "\n",
    "        accumulated_grads += metric\n",
    "\n",
    "    return accumulated_grads / len(dataloader)"
   ],
   "id": "6b492735e7c85dce",
   "outputs": [],
   "execution_count": 93
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-11-05T14:19:02.581096Z",
     "start_time": "2024-11-05T14:19:02.474307Z"
    }
   },
   "cell_type": "code",
   "source": [
    "for i in metrics:\n",
    "    print(calculate_edge_metric_for_dataloader(simple_model, test_loader, i))"
   ],
   "id": "578cad9f9a87757f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.4379,  0.5358, 85.4350, 15.9770,  2.7179, 39.3903, 23.5133,  6.8977,\n",
      "         34.0691,  6.2802]])\n",
      "tensor([[0.1160, 0.0511, 0.1099, 0.0179, 0.0011, 0.0096, 0.0931, 0.1156, 0.1033,\n",
      "         0.0123]], grad_fn=<DivBackward0>)\n",
      "tensor([[7.7956e-05, 8.5412e-06, 4.8188e-03, 1.7046e-03, 3.7740e-04, 4.0245e-03,\n",
      "         3.8460e-03, 4.6285e-04, 1.3553e-03, 1.1440e-04]])\n",
      "tensor([[0.5714, 0.7143, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000, 1.0000,\n",
      "         0.0000]])\n"
     ]
    }
   ],
   "execution_count": 94
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "    ",
   "id": "57855e80c88c65f0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
